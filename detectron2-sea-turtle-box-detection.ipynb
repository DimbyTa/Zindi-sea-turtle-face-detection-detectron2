{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b046a629",
   "metadata": {
    "papermill": {
     "duration": 0.041112,
     "end_time": "2023-07-09T23:38:01.072578",
     "exception": false,
     "start_time": "2023-07-09T23:38:01.031466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Local Ocean Conservation Sea Turtle Face Detection Zindi Competition\n",
    "## Taratra D. RAHARISON\n",
    "### Notebook inspired by the Detectron2 tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9c87455",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-09T23:38:01.164773Z",
     "iopub.status.busy": "2023-07-09T23:38:01.163883Z",
     "iopub.status.idle": "2023-07-09T23:38:02.092344Z",
     "shell.execute_reply": "2023-07-09T23:38:02.091658Z",
     "shell.execute_reply.started": "2023-07-07T22:20:07.894399Z"
    },
    "papermill": {
     "duration": 0.980299,
     "end_time": "2023-07-09T23:38:02.092511",
     "exception": false,
     "start_time": "2023-07-09T23:38:01.112212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/detectron2-sea-turtle-data-loader/__results__.html\n",
      "/kaggle/input/detectron2-sea-turtle-data-loader/SampleSubmission.csv\n",
      "/kaggle/input/detectron2-sea-turtle-data-loader/IMAGES_512.zip\n",
      "/kaggle/input/detectron2-sea-turtle-data-loader/__notebook__.ipynb\n",
      "/kaggle/input/detectron2-sea-turtle-data-loader/__output__.json\n",
      "/kaggle/input/detectron2-sea-turtle-data-loader/Train.csv\n",
      "/kaggle/input/detectron2-sea-turtle-data-loader/IMAGES_1024.zip\n",
      "/kaggle/input/detectron2-sea-turtle-data-loader/custom.css\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import itertools\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb47575",
   "metadata": {
    "papermill": {
     "duration": 0.040279,
     "end_time": "2023-07-09T23:38:02.173745",
     "exception": false,
     "start_time": "2023-07-09T23:38:02.133466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installing torch 1.7.1, torchvision 0.8.2, torchaudio 0.7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a65ccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T23:38:02.265033Z",
     "iopub.status.busy": "2023-07-09T23:38:02.263170Z",
     "iopub.status.idle": "2023-07-09T23:39:36.620840Z",
     "shell.execute_reply": "2023-07-09T23:39:36.621551Z",
     "shell.execute_reply.started": "2023-07-07T22:20:11.512507Z"
    },
    "papermill": {
     "duration": 94.406201,
     "end_time": "2023-07-09T23:39:36.621769",
     "exception": false,
     "start_time": "2023-07-09T23:38:02.215568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\r\n",
      "Collecting torch==1.7.1+cu110\r\n",
      "  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8 MB)\r\n",
      "     |████████████████████████████████| 1156.8 MB 8.1 kB/s             \r\n",
      "\u001b[?25hCollecting torchvision==0.8.2+cu110\r\n",
      "  Downloading https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp37-cp37m-linux_x86_64.whl (12.9 MB)\r\n",
      "     |████████████████████████████████| 12.9 MB 38.6 MB/s            \r\n",
      "\u001b[?25hCollecting torchaudio==0.7.2\r\n",
      "  Downloading torchaudio-0.7.2-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\r\n",
      "     |████████████████████████████████| 7.6 MB 1.8 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.7.1+cu110) (4.1.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==1.7.1+cu110) (1.20.3)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.8.2+cu110) (8.2.0)\r\n",
      "Installing collected packages: torch, torchvision, torchaudio\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.9.1\r\n",
      "    Uninstalling torch-1.9.1:\r\n",
      "      Successfully uninstalled torch-1.9.1\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.10.1\r\n",
      "    Uninstalling torchvision-0.10.1:\r\n",
      "      Successfully uninstalled torchvision-0.10.1\r\n",
      "  Attempting uninstall: torchaudio\r\n",
      "    Found existing installation: torchaudio 0.9.1\r\n",
      "    Uninstalling torchaudio-0.9.1:\r\n",
      "      Successfully uninstalled torchaudio-0.9.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fairscale 0.4.5 requires torch>=1.8.0, but you have torch 1.7.1+cu110 which is incompatible.\u001b[0m\r\n",
      "Successfully installed torch-1.7.1+cu110 torchaudio-0.7.2 torchvision-0.8.2+cu110\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccf0f9d",
   "metadata": {
    "papermill": {
     "duration": 0.516778,
     "end_time": "2023-07-09T23:39:37.664889",
     "exception": false,
     "start_time": "2023-07-09T23:39:37.148111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installing pyaml 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c60698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T23:39:38.696814Z",
     "iopub.status.busy": "2023-07-09T23:39:38.695795Z",
     "iopub.status.idle": "2023-07-09T23:39:52.599014Z",
     "shell.execute_reply": "2023-07-09T23:39:52.599777Z",
     "shell.execute_reply.started": "2023-07-07T22:20:26.894285Z"
    },
    "papermill": {
     "duration": 14.417441,
     "end_time": "2023-07-09T23:39:52.599944",
     "exception": false,
     "start_time": "2023-07-09T23:39:38.182503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyyaml==5.1\r\n",
      "  Downloading PyYAML-5.1.tar.gz (274 kB)\r\n",
      "     |████████████████████████████████| 274 kB 4.2 MB/s            \r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pyyaml\r\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=a79db0d3ff44d0f44f86fd485f8bf9d0dcd044d3e91fc88e1a27b29d4c3861b7\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\r\n",
      "Successfully built pyyaml\r\n",
      "Installing collected packages: pyyaml\r\n",
      "  Attempting uninstall: pyyaml\r\n",
      "    Found existing installation: PyYAML 6.0\r\n",
      "    Uninstalling PyYAML-6.0:\r\n",
      "      Successfully uninstalled PyYAML-6.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "dask-cudf 21.10.1 requires cupy-cuda114, which is not installed.\r\n",
      "libcst 0.3.23 requires pyyaml>=5.2, but you have pyyaml 5.1 which is incompatible.\r\n",
      "kubernetes 21.7.0 requires pyyaml>=5.4.1, but you have pyyaml 5.1 which is incompatible.\r\n",
      "dask 2022.2.0 requires pyyaml>=5.3.1, but you have pyyaml 5.1 which is incompatible.\r\n",
      "dask-cudf 21.10.1 requires dask==2021.09.1, but you have dask 2022.2.0 which is incompatible.\r\n",
      "dask-cudf 21.10.1 requires distributed==2021.09.1, but you have distributed 2022.2.0 which is incompatible.\u001b[0m\r\n",
      "Successfully installed pyyaml-5.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "torch:  1.7 ; cuda:  cu110\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml==5.1\n",
    "\n",
    "import torch\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "# Install detectron2 that matches the above pytorch version\n",
    "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
    "#!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
    "# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
    "\n",
    "# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4679eaab",
   "metadata": {
    "papermill": {
     "duration": 0.511461,
     "end_time": "2023-07-09T23:39:53.628196",
     "exception": false,
     "start_time": "2023-07-09T23:39:53.116735",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installing Detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "417e6ee8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T23:39:54.668903Z",
     "iopub.status.busy": "2023-07-09T23:39:54.667585Z",
     "iopub.status.idle": "2023-07-09T23:40:47.740611Z",
     "shell.execute_reply": "2023-07-09T23:40:47.740033Z",
     "shell.execute_reply.started": "2023-07-07T22:20:49.724729Z"
    },
    "papermill": {
     "duration": 53.605593,
     "end_time": "2023-07-09T23:40:47.740767",
     "exception": false,
     "start_time": "2023-07-09T23:39:54.135174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu110/torch1.7/index.html\r\n",
      "Collecting detectron2\r\n",
      "  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu110/torch1.7/detectron2-0.5%2Bcu110-cp37-cp37m-linux_x86_64.whl (6.4 MB)\r\n",
      "     |████████████████████████████████| 6.4 MB 4.2 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.7/site-packages (from detectron2) (4.62.3)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.7/site-packages (from detectron2) (1.1.0)\r\n",
      "Collecting omegaconf>=2.1\r\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\r\n",
      "     |████████████████████████████████| 79 kB 3.3 MB/s             \r\n",
      "\u001b[?25hCollecting iopath<0.1.9,>=0.1.7\r\n",
      "  Downloading iopath-0.1.8-py3-none-any.whl (19 kB)\r\n",
      "Collecting pycocotools>=2.0.2\r\n",
      "  Downloading pycocotools-2.0.6.tar.gz (24 kB)\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from detectron2) (2.0.0)\r\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from detectron2) (2.6.0)\r\n",
      "Collecting black==21.4b2\r\n",
      "  Downloading black-21.4b2-py3-none-any.whl (130 kB)\r\n",
      "     |████████████████████████████████| 130 kB 25.6 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from detectron2) (3.5.1)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from detectron2) (0.18.2)\r\n",
      "Requirement already satisfied: yacs>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from detectron2) (0.1.8)\r\n",
      "Requirement already satisfied: pydot in /opt/conda/lib/python3.7/site-packages (from detectron2) (1.4.2)\r\n",
      "Collecting hydra-core>=1.1\r\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\r\n",
      "     |████████████████████████████████| 154 kB 55.4 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.7/site-packages (from detectron2) (8.2.0)\r\n",
      "Collecting fvcore<0.1.6,>=0.1.5\r\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\r\n",
      "     |████████████████████████████████| 50 kB 6.1 MB/s             \r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from detectron2) (0.8.9)\r\n",
      "Requirement already satisfied: regex>=2020.1.8 in /opt/conda/lib/python3.7/site-packages (from black==21.4b2->detectron2) (2021.11.10)\r\n",
      "Requirement already satisfied: pathspec<1,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from black==21.4b2->detectron2) (0.9.0)\r\n",
      "Requirement already satisfied: click>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from black==21.4b2->detectron2) (8.0.3)\r\n",
      "Requirement already satisfied: toml>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from black==21.4b2->detectron2) (0.10.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from black==21.4b2->detectron2) (4.1.1)\r\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.7/site-packages (from black==21.4b2->detectron2) (1.4.4)\r\n",
      "Requirement already satisfied: typed-ast>=1.4.2 in /opt/conda/lib/python3.7/site-packages (from black==21.4b2->detectron2) (1.5.1)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.7/site-packages (from black==21.4b2->detectron2) (0.4.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (1.20.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (5.1)\r\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from hydra-core>=1.1->detectron2) (5.4.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from hydra-core>=1.1->detectron2) (21.3)\r\n",
      "Collecting antlr4-python3-runtime==4.9.*\r\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\r\n",
      "     |████████████████████████████████| 117 kB 51.8 MB/s            \r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from iopath<0.1.9,>=0.1.7->detectron2) (2.4.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2) (0.11.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2) (1.3.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2) (3.0.6)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2) (4.28.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2) (2.8.2)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (1.8.0)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (2.26.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (0.4.6)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (0.6.1)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (1.35.0)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (1.43.0)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (2.0.2)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (59.5.0)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (0.37.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (3.3.6)\r\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (3.19.4)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (0.15.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard->detectron2) (1.16.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click>=7.1.2->black==21.4b2->detectron2) (4.11.3)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.8)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (0.2.7)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2021.10.8)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.0.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.26.7)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources->hydra-core>=1.1->detectron2) (3.6.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.1)\r\n",
      "Building wheels for collected packages: fvcore, antlr4-python3-runtime, pycocotools\r\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61433 sha256=8eb319b747c537e13fa0bc4567105abcc71840ab1c329fac31d582877f22c791\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/af/cd/23/3fb62ec8606cb08cc18abb8d67bec255baf353623be889da1e\r\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=a548f6d4b0df9cb699ff04e1a25b78b824d62759c5e86ac45a39b7ef29a43c13\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\r\n",
      "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp37-cp37m-linux_x86_64.whl size=373905 sha256=c1789ad31d64c6e50fd62470dac7dbd95d7d79f6569601d35c7205e9c710960a\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/06/f6/f9/9cc49c6de8e3cf27dfddd91bf46595a057141d4583a2adaf03\r\n",
      "Successfully built fvcore antlr4-python3-runtime pycocotools\r\n",
      "Installing collected packages: antlr4-python3-runtime, omegaconf, iopath, pycocotools, hydra-core, fvcore, black, detectron2\r\n",
      "  Attempting uninstall: black\r\n",
      "    Found existing installation: black 21.12b0\r\n",
      "    Uninstalling black-21.12b0:\r\n",
      "      Successfully uninstalled black-21.12b0\r\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 black-21.4b2 detectron2-0.5+cu110 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.8 omegaconf-2.3.0 pycocotools-2.0.6\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu110/torch1.7/index.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d25cb6",
   "metadata": {
    "papermill": {
     "duration": 0.536379,
     "end_time": "2023-07-09T23:40:48.835803",
     "exception": false,
     "start_time": "2023-07-09T23:40:48.299424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading Detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32a4467e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T23:40:50.355414Z",
     "iopub.status.busy": "2023-07-09T23:40:50.354539Z",
     "iopub.status.idle": "2023-07-09T23:40:51.132450Z",
     "shell.execute_reply": "2023-07-09T23:40:51.133143Z",
     "shell.execute_reply.started": "2023-07-07T22:22:28.903799Z"
    },
    "papermill": {
     "duration": 1.720454,
     "end_time": "2023-07-09T23:40:51.133349",
     "exception": false,
     "start_time": "2023-07-09T23:40:49.412895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "import cv2, random\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.engine.hooks import HookBase\n",
    "from detectron2.evaluation import inference_context\n",
    "from detectron2.utils.logger import log_every_n_seconds\n",
    "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
    "import detectron2.utils.comm as comm\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.checkpoint import DetectionCheckpointer,PeriodicCheckpointer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb92dda",
   "metadata": {
    "papermill": {
     "duration": 0.558138,
     "end_time": "2023-07-09T23:40:52.235000",
     "exception": false,
     "start_time": "2023-07-09T23:40:51.676862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Unzipping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e1c3650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T23:40:53.349963Z",
     "iopub.status.busy": "2023-07-09T23:40:53.348849Z",
     "iopub.status.idle": "2023-07-09T23:40:56.633294Z",
     "shell.execute_reply": "2023-07-09T23:40:56.632694Z",
     "shell.execute_reply.started": "2023-07-07T22:22:33.533962Z"
    },
    "papermill": {
     "duration": 3.850908,
     "end_time": "2023-07-09T23:40:56.633441",
     "exception": false,
     "start_time": "2023-07-09T23:40:52.782533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!unzip -q '/kaggle/input/detectron2-sea-turtle-data-loader/IMAGES_512.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f498266c",
   "metadata": {
    "papermill": {
     "duration": 0.563085,
     "end_time": "2023-07-09T23:40:57.739856",
     "exception": false,
     "start_time": "2023-07-09T23:40:57.176771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1507cf62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T23:40:58.830335Z",
     "iopub.status.busy": "2023-07-09T23:40:58.829603Z",
     "iopub.status.idle": "2023-07-09T23:40:58.867468Z",
     "shell.execute_reply": "2023-07-09T23:40:58.866844Z",
     "shell.execute_reply.started": "2023-07-07T22:30:34.265244Z"
    },
    "papermill": {
     "duration": 0.589614,
     "end_time": "2023-07-09T23:40:58.867628",
     "exception": false,
     "start_time": "2023-07-09T23:40:58.278014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/detectron2-sea-turtle-data-loader/Train.csv')\n",
    "# Splitting between train, val and test\n",
    "train, testTp = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "val, test_train = train_test_split(testTp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78e2471",
   "metadata": {
    "papermill": {
     "duration": 0.624863,
     "end_time": "2023-07-09T23:41:00.038458",
     "exception": false,
     "start_time": "2023-07-09T23:40:59.413595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## A glimpse inside train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab98ce57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T23:41:01.138711Z",
     "iopub.status.busy": "2023-07-09T23:41:01.137955Z",
     "iopub.status.idle": "2023-07-09T23:41:01.154160Z",
     "shell.execute_reply": "2023-07-09T23:41:01.154681Z",
     "shell.execute_reply.started": "2023-07-07T22:30:36.271330Z"
    },
    "papermill": {
     "duration": 0.571097,
     "end_time": "2023-07-09T23:41:01.154841",
     "exception": false,
     "start_time": "2023-07-09T23:41:00.583744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>CC029777</td>\n",
       "      <td>0.400825</td>\n",
       "      <td>0.599537</td>\n",
       "      <td>0.240668</td>\n",
       "      <td>0.282118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>4661E536</td>\n",
       "      <td>0.473524</td>\n",
       "      <td>0.275174</td>\n",
       "      <td>0.175998</td>\n",
       "      <td>0.326389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>81B7CD6B</td>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.464333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>9EC9DEC9</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.478009</td>\n",
       "      <td>0.335938</td>\n",
       "      <td>0.357928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>9C527060</td>\n",
       "      <td>0.483507</td>\n",
       "      <td>0.431713</td>\n",
       "      <td>0.289714</td>\n",
       "      <td>0.344039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Image_ID         x         y         w         h\n",
       "170  CC029777  0.400825  0.599537  0.240668  0.282118\n",
       "270  4661E536  0.473524  0.275174  0.175998  0.326389\n",
       "890  81B7CD6B  0.462500  0.241667  0.520750  0.464333\n",
       "209  9EC9DEC9  0.339844  0.478009  0.335938  0.357928\n",
       "721  9C527060  0.483507  0.431713  0.289714  0.344039"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45da1c",
   "metadata": {
    "papermill": {
     "duration": 0.554133,
     "end_time": "2023-07-09T23:41:02.249238",
     "exception": false,
     "start_time": "2023-07-09T23:41:01.695105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Getting the bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe6bb3c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T23:41:03.381044Z",
     "iopub.status.busy": "2023-07-09T23:41:03.380050Z",
     "iopub.status.idle": "2023-07-09T23:41:03.381950Z",
     "shell.execute_reply": "2023-07-09T23:41:03.382598Z",
     "shell.execute_reply.started": "2023-07-07T22:30:42.794670Z"
    },
    "papermill": {
     "duration": 0.582179,
     "end_time": "2023-07-09T23:41:03.382760",
     "exception": false,
     "start_time": "2023-07-09T23:41:02.800581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_turtle_box(img_dir, dataset):\n",
    "    \"\"\"\n",
    "    Converting from x,y,width,height boxes to x1,y1,X2,y2 boxes\n",
    "    \"\"\"\n",
    "    dataset_dicts = []\n",
    "    images = list(Path(img_dir).glob('*.JPG'))\n",
    "    for i in range(len(images)):\n",
    "        record = {}\n",
    "        filename = str(images[i])\n",
    "        #print(filename)\n",
    "        image_name = filename[len(img_dir)-1:]\n",
    "        #print(image_name)\n",
    "        img = os.path.join(img_dir, image_name)\n",
    "        #print(img)\n",
    "        height, width = cv2.imread(img).shape[:2]\n",
    "        \n",
    "        #print(height,width)\n",
    "        record[\"file_name\"] = filename\n",
    "        record[\"image_id\"] = image_name[:-4]\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        \n",
    "        objs = []\n",
    "        if any(dataset['Image_ID'] == record['image_id']):\n",
    "            x1 = dataset[dataset['Image_ID'] == record['image_id']]['x'].values[0] * width\n",
    "            y1 = dataset[dataset['Image_ID'] == record['image_id']]['y'].values[0] * height\n",
    "            x2 =  x1 + dataset[dataset['Image_ID'] == record['image_id']]['w'].values[0] * width\n",
    "            y2 = y1 + dataset[dataset['Image_ID'] == record['image_id']]['h'].values[0]* height\n",
    "            \n",
    "            obj = {\n",
    "                \"bbox\": [x1, y1, x2, y2],\n",
    "                #\"segmentation\": [poly],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"category_id\": 0,\n",
    "            }\n",
    "            objs.append(obj)\n",
    "            record[\"annotations\"] = objs\n",
    "            dataset_dicts.append(record)\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685f5824",
   "metadata": {
    "papermill": {
     "duration": 0.581255,
     "end_time": "2023-07-09T23:41:04.520074",
     "exception": false,
     "start_time": "2023-07-09T23:41:03.938819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Registring datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be286645",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T23:41:05.631792Z",
     "iopub.status.busy": "2023-07-09T23:41:05.630898Z",
     "iopub.status.idle": "2023-07-09T23:41:05.640211Z",
     "shell.execute_reply": "2023-07-09T23:41:05.639734Z",
     "shell.execute_reply.started": "2023-07-07T22:30:45.533324Z"
    },
    "papermill": {
     "duration": 0.56178,
     "end_time": "2023-07-09T23:41:05.640355",
     "exception": false,
     "start_time": "2023-07-09T23:41:05.078575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(name='turtle_val', thing_classes=['turtle'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_folder = \"./IMAGES_512\"\n",
    "d = 'train'\n",
    "DatasetCatalog.register(\"turtle_\" + d, lambda d=d: get_turtle_box(image_folder,train))\n",
    "MetadataCatalog.get(\"turtle_\" + d).set(thing_classes=[\"turtle\"])\n",
    "d = 'val'\n",
    "DatasetCatalog.register(\"turtle_\" + d, lambda d=d: get_turtle_box(image_folder,val))\n",
    "MetadataCatalog.get(\"turtle_\" + d).set(thing_classes=[\"turtle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d2dd9e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T23:41:06.716370Z",
     "iopub.status.busy": "2023-07-09T23:41:06.715466Z",
     "iopub.status.idle": "2023-07-09T23:41:23.621269Z",
     "shell.execute_reply": "2023-07-09T23:41:23.620712Z",
     "shell.execute_reply.started": "2023-07-07T22:30:48.242790Z"
    },
    "papermill": {
     "duration": 17.444824,
     "end_time": "2023-07-09T23:41:23.621432",
     "exception": false,
     "start_time": "2023-07-09T23:41:06.176608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_dicts = get_turtle_box(image_folder,train)\n",
    "val_set_dicts = get_turtle_box(image_folder,val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc35aeb0",
   "metadata": {
    "papermill": {
     "duration": 0.544829,
     "end_time": "2023-07-09T23:41:24.718042",
     "exception": false,
     "start_time": "2023-07-09T23:41:24.173213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training and validation inspired by https://eidos-ai.medium.com/training-on-detectron2-with-a-validation-set-and-plot-loss-on-it-to-avoid-overfitting-6449418fbf4e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea444f",
   "metadata": {
    "papermill": {
     "duration": 0.537997,
     "end_time": "2023-07-09T23:41:25.791594",
     "exception": false,
     "start_time": "2023-07-09T23:41:25.253597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Early stopping mechanism\n",
    "\n",
    "HookBase is a class in Detectron2 that makes it possible to customize the training process. By subclassing Hookbase, we can extend the training process without changing the core training code of Detectron2.\n",
    "\n",
    "The key methods defined in HookBase include:\n",
    "* before_step(): This method is called before each training step.\n",
    "* after_step(): This method is called after each training step.\n",
    "* before_train(): This method is called before the training starts.\n",
    "* after_train(): This method is called after the training ends.\n",
    "\n",
    "Here, we want after each step to evaluate the model, see if the performance improved. If it is the case, save the new best model. If not, first check if we did not exceeded the patience parameter, if it is not the case, continue the training, if not, stop it.\n",
    "\n",
    "We will implement those process inside after_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ecfddeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T23:41:26.902765Z",
     "iopub.status.busy": "2023-07-09T23:41:26.893121Z",
     "iopub.status.idle": "2023-07-09T23:41:26.905814Z",
     "shell.execute_reply": "2023-07-09T23:41:26.905129Z"
    },
    "papermill": {
     "duration": 0.571464,
     "end_time": "2023-07-09T23:41:26.905952",
     "exception": false,
     "start_time": "2023-07-09T23:41:26.334488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class EarlyStoppingAndLossEvalHook(HookBase):\n",
    "    def __init__(self, patience, validation_evaluator, validation_loss_key, eval_period, model, data_loader, output_dir):\n",
    "        super().__init__()\n",
    "        self.patience = patience\n",
    "        self.validation_evaluator = validation_evaluator\n",
    "        self.validation_loss_key = validation_loss_key\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.eval_period = eval_period\n",
    "        self.model = model\n",
    "        self.data_loader = data_loader\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "    def after_step(self):\n",
    "        \"\"\"\n",
    "        Defines the behavior after each step of the gradient descent\n",
    "        Implements the early stopping mechanism\n",
    "        \"\"\"\n",
    "        if (self.trainer.iter + 1) % self.trainer.cfg.SOLVER.CHECKPOINT_PERIOD != 0:\n",
    "            return\n",
    "\n",
    "        # Perform loss evaluation\n",
    "        losses = self._do_loss_eval()\n",
    "\n",
    "        # Get the segmentation loss from the evaluation results\n",
    "        segmentation_loss = np.mean(losses)\n",
    "\n",
    "        if segmentation_loss < self.best_loss:\n",
    "            self.best_loss = segmentation_loss\n",
    "            self.counter = 0\n",
    "            # Save the best model\n",
    "            self._save_best_model()\n",
    "        else:\n",
    "            self.counter += 1\n",
    "\n",
    "        if self.counter >= self.patience:\n",
    "            print(f\"Early stopping triggered after {self.counter} steps without improvement.\")\n",
    "            self.trainer.should_stop = True\n",
    "            # Load the best model\n",
    "            self._load_best_model()\n",
    "\n",
    "    def _do_loss_eval(self):\n",
    "        total = len(self.data_loader)\n",
    "        num_warmup = min(5, total - 1)\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        total_compute_time = 0\n",
    "        losses = []\n",
    "        for idx, inputs in enumerate(self.data_loader):\n",
    "            if idx == num_warmup:\n",
    "                start_time = time.perf_counter()\n",
    "                total_compute_time = 0\n",
    "            start_compute_time = time.perf_counter()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            total_compute_time += time.perf_counter() - start_compute_time\n",
    "            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n",
    "            seconds_per_img = total_compute_time / iters_after_start\n",
    "            if idx >= num_warmup * 2 or seconds_per_img > 5:\n",
    "                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n",
    "                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n",
    "                log_every_n_seconds(\n",
    "                    logging.INFO,\n",
    "                    \"Loss on Validation done {}/{}. {:.4f} s / img. ETA={}\".format(\n",
    "                        idx + 1, total, seconds_per_img, str(eta)\n",
    "                    ),\n",
    "                    n=5,\n",
    "                )\n",
    "            loss_batch = self._get_loss(inputs)\n",
    "            losses.append(loss_batch)\n",
    "        self.trainer.storage.put_scalar('validation_loss', np.mean(losses))\n",
    "        comm.synchronize()\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def _get_loss(self, data):\n",
    "        # How loss is calculated on train_loop \n",
    "        metrics_dict = self.model(data)\n",
    "        metrics_dict = {\n",
    "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
    "            for k, v in metrics_dict.items()\n",
    "        }\n",
    "        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n",
    "        return total_losses_reduced\n",
    "\n",
    "    def _save_best_model(self):\n",
    "        save_path = os.path.join(self.output_dir, \"best_model.pth\")\n",
    "        torch.save(self.model.state_dict(), save_path)\n",
    "        print(f\"Best model saved at {save_path}\")\n",
    "\n",
    "    def _load_best_model(self):\n",
    "        load_path = os.path.join(self.output_dir, \"best_model.pth\")\n",
    "        if os.path.exists(load_path):\n",
    "            self.model.load_state_dict(torch.load(load_path))\n",
    "            print(f\"Best model loaded from {load_path}\")\n",
    "        else:\n",
    "            print(\"Best model checkpoint not found, training will continue with the current model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67313897",
   "metadata": {
    "papermill": {
     "duration": 0.544961,
     "end_time": "2023-07-09T23:41:28.092130",
     "exception": false,
     "start_time": "2023-07-09T23:41:27.547169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DefaultTrainer\n",
    "\n",
    "DefaultTrainer is a class in Detectron2 that provides a default implementation of the training loop. It encapsulates the core logic for training object detection and instance segmentation models. We usually extend this class when we use custom hooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "607fea5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T23:41:29.235939Z",
     "iopub.status.busy": "2023-07-09T23:41:29.234563Z",
     "iopub.status.idle": "2023-07-09T23:41:29.239766Z",
     "shell.execute_reply": "2023-07-09T23:41:29.240326Z",
     "shell.execute_reply.started": "2023-07-07T00:23:07.257569Z"
    },
    "papermill": {
     "duration": 0.589624,
     "end_time": "2023-07-09T23:41:29.240793",
     "exception": false,
     "start_time": "2023-07-09T23:41:28.651169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyTrainer(DefaultTrainer):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__(cfg)\n",
    "        #self.output_dir = output_dir\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        early_stopping_hook = EarlyStoppingAndLossEvalHook(\n",
    "            patience=5,\n",
    "            validation_evaluator=self.build_evaluator(self.cfg, self.cfg.DATASETS.TEST[0]),\n",
    "            validation_loss_key=\"validation_loss\",\n",
    "            eval_period=cfg.TEST.EVAL_PERIOD,\n",
    "            model=self.model,\n",
    "            data_loader=build_detection_test_loader(\n",
    "                self.cfg,\n",
    "                self.cfg.DATASETS.TEST[0],\n",
    "                DatasetMapper(self.cfg, True)\n",
    "            ),\n",
    "            output_dir=self.cfg.OUTPUT_DIR\n",
    "        )\n",
    "\n",
    "        # Insert the new hooks\n",
    "        hooks.insert(-1, early_stopping_hook)\n",
    "\n",
    "        return hooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19dd2a5",
   "metadata": {
    "papermill": {
     "duration": 0.567575,
     "end_time": "2023-07-09T23:41:30.450216",
     "exception": false,
     "start_time": "2023-07-09T23:41:29.882641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Getting configuration file and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e7c17cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T23:41:31.563665Z",
     "iopub.status.busy": "2023-07-09T23:41:31.562750Z",
     "iopub.status.idle": "2023-07-10T00:21:48.070214Z",
     "shell.execute_reply": "2023-07-10T00:21:48.070851Z"
    },
    "papermill": {
     "duration": 2417.069764,
     "end_time": "2023-07-10T00:21:48.071045",
     "exception": false,
     "start_time": "2023-07-09T23:41:31.001281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/09 23:41:31 d2.engine.defaults]: \u001b[0mAuto-scaling the config to batch_size=2, learning_rate=0.0005, max_iter=700, warmup=2000.\n",
      "\u001b[32m[07/09 23:41:37 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[07/09 23:41:47 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1060 images left.\n",
      "\u001b[32m[07/09 23:41:47 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   turtle   | 1060         |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[07/09 23:41:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/09 23:41:47 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/09 23:41:47 d2.data.common]: \u001b[0mSerializing 1060 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/09 23:41:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.37 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 23:41:51 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/09 23:41:51 d2.evaluation.coco_evaluation]: \u001b[0m'turtle_val' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n",
      "\u001b[32m[07/09 23:41:51 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'turtle_val' to COCO format ...)\n",
      "\u001b[32m[07/09 23:41:58 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[07/09 23:41:58 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 133, #annotations: 133\n",
      "\u001b[32m[07/09 23:41:58 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output/inference/turtle_val_coco_format.json' ...\n",
      "\u001b[32m[07/09 23:41:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/09 23:42:05 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   turtle   | 133          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[07/09 23:42:05 d2.data.common]: \u001b[0mSerializing 133 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/09 23:42:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.05 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_68b088.pkl: 421MB [00:03, 116MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/09 23:42:11 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:103: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  num_fg = fg_inds.nonzero().numel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/09 23:43:00 d2.utils.events]: \u001b[0m eta: 0:26:31  iter: 19  total_loss: 1.079  loss_cls: 0.7121  loss_box_reg: 0.2953  loss_rpn_cls: 0.0369  loss_rpn_loc: 0.009739  time: 2.4548  data_time: 0.0257  lr: 1.4058e-05  max_mem: 6049M\n",
      "\u001b[32m[07/09 23:43:51 d2.utils.events]: \u001b[0m eta: 0:27:11  iter: 39  total_loss: 0.8502  loss_cls: 0.5385  loss_box_reg: 0.2811  loss_rpn_cls: 0.04396  loss_rpn_loc: 0.009119  time: 2.5144  data_time: 0.0060  lr: 2.8329e-05  max_mem: 6049M\n",
      "\u001b[32m[07/09 23:44:45 d2.utils.events]: \u001b[0m eta: 0:26:42  iter: 59  total_loss: 0.8527  loss_cls: 0.399  loss_box_reg: 0.4593  loss_rpn_cls: 0.02766  loss_rpn_loc: 0.006943  time: 2.5717  data_time: 0.0072  lr: 4.2601e-05  max_mem: 6049M\n",
      "\u001b[32m[07/09 23:45:36 d2.utils.events]: \u001b[0m eta: 0:25:57  iter: 79  total_loss: 0.66  loss_cls: 0.2913  loss_box_reg: 0.3013  loss_rpn_cls: 0.02032  loss_rpn_loc: 0.00696  time: 2.5692  data_time: 0.0067  lr: 5.6872e-05  max_mem: 6049M\n",
      "\u001b[32m[07/09 23:46:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/09 23:46:33 d2.data.common]: \u001b[0mSerializing 133 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/09 23:46:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.05 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 23:46:33 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/09 23:46:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 133 batches\n",
      "\u001b[32m[07/09 23:46:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/133. Dataloading: 0.0016 s/iter. Inference: 0.2916 s/iter. Eval: 0.0004 s/iter. Total: 0.2936 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/09 23:46:42 d2.evaluation.evaluator]: \u001b[0mInference done 29/133. Dataloading: 0.0018 s/iter. Inference: 0.2813 s/iter. Eval: 0.0005 s/iter. Total: 0.2837 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/09 23:46:47 d2.evaluation.evaluator]: \u001b[0mInference done 47/133. Dataloading: 0.0018 s/iter. Inference: 0.2799 s/iter. Eval: 0.0005 s/iter. Total: 0.2823 s/iter. ETA=0:00:24\n",
      "\u001b[32m[07/09 23:46:52 d2.evaluation.evaluator]: \u001b[0mInference done 65/133. Dataloading: 0.0018 s/iter. Inference: 0.2810 s/iter. Eval: 0.0004 s/iter. Total: 0.2834 s/iter. ETA=0:00:19\n",
      "\u001b[32m[07/09 23:46:57 d2.evaluation.evaluator]: \u001b[0mInference done 83/133. Dataloading: 0.0018 s/iter. Inference: 0.2821 s/iter. Eval: 0.0004 s/iter. Total: 0.2844 s/iter. ETA=0:00:14\n",
      "\u001b[32m[07/09 23:47:02 d2.evaluation.evaluator]: \u001b[0mInference done 101/133. Dataloading: 0.0018 s/iter. Inference: 0.2821 s/iter. Eval: 0.0004 s/iter. Total: 0.2844 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/09 23:47:07 d2.evaluation.evaluator]: \u001b[0mInference done 119/133. Dataloading: 0.0018 s/iter. Inference: 0.2824 s/iter. Eval: 0.0004 s/iter. Total: 0.2847 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/09 23:47:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.510358 (0.285237 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/09 23:47:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.282074 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/09 23:47:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/09 23:47:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
      "\u001b[32m[07/09 23:47:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[07/09 23:47:11 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[07/09 23:47:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.14 seconds.\n",
      "\u001b[32m[07/09 23:47:12 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[07/09 23:47:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.539\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.332\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.512\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.538\n",
      "\u001b[32m[07/09 23:47:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 25.586 | 53.855 | 17.326 |  nan  | 0.861 | 28.438 |\n",
      "\u001b[32m[07/09 23:47:12 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[07/09 23:47:12 d2.engine.defaults]: \u001b[0mEvaluation results for turtle_val in csv format:\n",
      "\u001b[32m[07/09 23:47:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[07/09 23:47:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[07/09 23:47:12 d2.evaluation.testing]: \u001b[0mcopypaste: 25.5862,53.8549,17.3258,nan,0.8609,28.4377\n",
      "\u001b[32m[07/09 23:47:15 detectron2]: \u001b[0mLoss on Validation done 11/133. 0.0001 s / img. ETA=0:00:25\n",
      "\u001b[32m[07/09 23:47:20 detectron2]: \u001b[0mLoss on Validation done 31/133. 0.0001 s / img. ETA=0:00:24\n",
      "\u001b[32m[07/09 23:47:25 detectron2]: \u001b[0mLoss on Validation done 53/133. 0.0001 s / img. ETA=0:00:18\n",
      "\u001b[32m[07/09 23:47:30 detectron2]: \u001b[0mLoss on Validation done 76/133. 0.0001 s / img. ETA=0:00:13\n",
      "\u001b[32m[07/09 23:47:35 detectron2]: \u001b[0mLoss on Validation done 98/133. 0.0001 s / img. ETA=0:00:08\n",
      "\u001b[32m[07/09 23:47:40 detectron2]: \u001b[0mLoss on Validation done 119/133. 0.0001 s / img. ETA=0:00:03\n",
      "Best model saved at ./output/best_model.pth\n",
      "\u001b[32m[07/09 23:47:45 d2.utils.events]: \u001b[0m eta: 0:25:02  iter: 99  total_loss: 0.8012  loss_cls: 0.296  loss_box_reg: 0.4921  loss_rpn_cls: 0.007005  loss_rpn_loc: 0.00473  validation_loss: 0.8149  time: 2.5415  data_time: 0.0062  lr: 7.1144e-05  max_mem: 6049M\n",
      "\u001b[32m[07/09 23:48:38 d2.utils.events]: \u001b[0m eta: 0:24:17  iter: 119  total_loss: 0.8607  loss_cls: 0.2724  loss_box_reg: 0.5787  loss_rpn_cls: 0.004551  loss_rpn_loc: 0.005731  validation_loss: 0.8149  time: 2.5616  data_time: 0.0060  lr: 8.5415e-05  max_mem: 6049M\n",
      "\u001b[32m[07/09 23:49:29 d2.utils.events]: \u001b[0m eta: 0:23:43  iter: 139  total_loss: 0.8172  loss_cls: 0.2249  loss_box_reg: 0.5796  loss_rpn_cls: 0.005688  loss_rpn_loc: 0.003899  validation_loss: 0.8149  time: 2.5606  data_time: 0.0064  lr: 9.9686e-05  max_mem: 6049M\n",
      "\u001b[32m[07/09 23:50:19 d2.utils.events]: \u001b[0m eta: 0:22:52  iter: 159  total_loss: 0.7468  loss_cls: 0.1794  loss_box_reg: 0.5515  loss_rpn_cls: 0.002291  loss_rpn_loc: 0.002697  validation_loss: 0.8149  time: 2.5563  data_time: 0.0079  lr: 0.00011396  max_mem: 6049M\n",
      "\u001b[32m[07/09 23:51:10 d2.utils.events]: \u001b[0m eta: 0:22:04  iter: 179  total_loss: 0.6527  loss_cls: 0.1312  loss_box_reg: 0.5279  loss_rpn_cls: 0.001858  loss_rpn_loc: 0.002779  validation_loss: 0.8149  time: 2.5526  data_time: 0.0061  lr: 0.00012823  max_mem: 6049M\n",
      "\u001b[32m[07/09 23:52:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/09 23:52:10 d2.data.common]: \u001b[0mSerializing 133 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/09 23:52:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.05 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 23:52:10 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/09 23:52:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 133 batches\n",
      "\u001b[32m[07/09 23:52:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/133. Dataloading: 0.0015 s/iter. Inference: 0.2900 s/iter. Eval: 0.0003 s/iter. Total: 0.2918 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/09 23:52:19 d2.evaluation.evaluator]: \u001b[0mInference done 30/133. Dataloading: 0.0016 s/iter. Inference: 0.2803 s/iter. Eval: 0.0003 s/iter. Total: 0.2824 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/09 23:52:24 d2.evaluation.evaluator]: \u001b[0mInference done 49/133. Dataloading: 0.0017 s/iter. Inference: 0.2777 s/iter. Eval: 0.0003 s/iter. Total: 0.2799 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/09 23:52:30 d2.evaluation.evaluator]: \u001b[0mInference done 67/133. Dataloading: 0.0017 s/iter. Inference: 0.2792 s/iter. Eval: 0.0003 s/iter. Total: 0.2814 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/09 23:52:35 d2.evaluation.evaluator]: \u001b[0mInference done 85/133. Dataloading: 0.0018 s/iter. Inference: 0.2809 s/iter. Eval: 0.0003 s/iter. Total: 0.2831 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/09 23:52:40 d2.evaluation.evaluator]: \u001b[0mInference done 103/133. Dataloading: 0.0018 s/iter. Inference: 0.2811 s/iter. Eval: 0.0003 s/iter. Total: 0.2833 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/09 23:52:45 d2.evaluation.evaluator]: \u001b[0mInference done 121/133. Dataloading: 0.0018 s/iter. Inference: 0.2816 s/iter. Eval: 0.0003 s/iter. Total: 0.2838 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/09 23:52:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.405155 (0.284415 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/09 23:52:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.281376 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/09 23:52:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/09 23:52:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
      "\u001b[32m[07/09 23:52:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[07/09 23:52:49 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[07/09 23:52:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "\u001b[32m[07/09 23:52:49 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[07/09 23:52:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.569\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.963\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.572\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.465\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.578\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.658\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.663\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.663\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.511\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.674\n",
      "\u001b[32m[07/09 23:52:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 56.930 | 96.274 | 57.200 |  nan  | 46.460 | 57.847 |\n",
      "\u001b[32m[07/09 23:52:49 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[07/09 23:52:49 d2.engine.defaults]: \u001b[0mEvaluation results for turtle_val in csv format:\n",
      "\u001b[32m[07/09 23:52:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[07/09 23:52:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[07/09 23:52:49 d2.evaluation.testing]: \u001b[0mcopypaste: 56.9299,96.2736,57.2003,nan,46.4596,57.8465\n",
      "\u001b[32m[07/09 23:52:51 detectron2]: \u001b[0mLoss on Validation done 11/133. 0.0001 s / img. ETA=0:00:26\n",
      "\u001b[32m[07/09 23:52:57 detectron2]: \u001b[0mLoss on Validation done 31/133. 0.0001 s / img. ETA=0:00:24\n",
      "\u001b[32m[07/09 23:53:02 detectron2]: \u001b[0mLoss on Validation done 53/133. 0.0001 s / img. ETA=0:00:19\n",
      "\u001b[32m[07/09 23:53:07 detectron2]: \u001b[0mLoss on Validation done 76/133. 0.0001 s / img. ETA=0:00:13\n",
      "\u001b[32m[07/09 23:53:12 detectron2]: \u001b[0mLoss on Validation done 97/133. 0.0001 s / img. ETA=0:00:08\n",
      "\u001b[32m[07/09 23:53:17 detectron2]: \u001b[0mLoss on Validation done 118/133. 0.0001 s / img. ETA=0:00:03\n",
      "Best model saved at ./output/best_model.pth\n",
      "\u001b[32m[07/09 23:53:22 d2.utils.events]: \u001b[0m eta: 0:21:13  iter: 199  total_loss: 0.5651  loss_cls: 0.1068  loss_box_reg: 0.4604  loss_rpn_cls: 0.002664  loss_rpn_loc: 0.002651  validation_loss: 0.6892  time: 2.5606  data_time: 0.0072  lr: 0.0001425  max_mem: 6130M\n",
      "\u001b[32m[07/09 23:54:15 d2.utils.events]: \u001b[0m eta: 0:20:23  iter: 219  total_loss: 0.4688  loss_cls: 0.074  loss_box_reg: 0.3907  loss_rpn_cls: 0.0001403  loss_rpn_loc: 0.004953  validation_loss: 0.6892  time: 2.5618  data_time: 0.0067  lr: 0.00015677  max_mem: 6130M\n",
      "\u001b[32m[07/09 23:55:06 d2.utils.events]: \u001b[0m eta: 0:19:32  iter: 239  total_loss: 0.359  loss_cls: 0.05731  loss_box_reg: 0.2946  loss_rpn_cls: 0.0001172  loss_rpn_loc: 0.005246  validation_loss: 0.6892  time: 2.5628  data_time: 0.0063  lr: 0.00017104  max_mem: 6130M\n",
      "\u001b[32m[07/09 23:55:57 d2.utils.events]: \u001b[0m eta: 0:18:42  iter: 259  total_loss: 0.3143  loss_cls: 0.05426  loss_box_reg: 0.2641  loss_rpn_cls: 0.0004808  loss_rpn_loc: 0.004248  validation_loss: 0.6892  time: 2.5617  data_time: 0.0069  lr: 0.00018532  max_mem: 6130M\n",
      "\u001b[32m[07/09 23:56:50 d2.utils.events]: \u001b[0m eta: 0:17:51  iter: 279  total_loss: 0.2377  loss_cls: 0.04082  loss_box_reg: 0.1796  loss_rpn_cls: 9.625e-05  loss_rpn_loc: 0.003618  validation_loss: 0.6892  time: 2.5683  data_time: 0.0065  lr: 0.00019959  max_mem: 6130M\n",
      "\u001b[32m[07/09 23:57:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/09 23:57:49 d2.data.common]: \u001b[0mSerializing 133 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/09 23:57:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.05 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/09 23:57:49 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/09 23:57:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 133 batches\n",
      "\u001b[32m[07/09 23:57:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/133. Dataloading: 0.0014 s/iter. Inference: 0.2898 s/iter. Eval: 0.0003 s/iter. Total: 0.2915 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/09 23:57:58 d2.evaluation.evaluator]: \u001b[0mInference done 30/133. Dataloading: 0.0017 s/iter. Inference: 0.2796 s/iter. Eval: 0.0002 s/iter. Total: 0.2817 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/09 23:58:03 d2.evaluation.evaluator]: \u001b[0mInference done 49/133. Dataloading: 0.0018 s/iter. Inference: 0.2771 s/iter. Eval: 0.0003 s/iter. Total: 0.2794 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/09 23:58:08 d2.evaluation.evaluator]: \u001b[0mInference done 67/133. Dataloading: 0.0018 s/iter. Inference: 0.2784 s/iter. Eval: 0.0003 s/iter. Total: 0.2806 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/09 23:58:14 d2.evaluation.evaluator]: \u001b[0mInference done 85/133. Dataloading: 0.0018 s/iter. Inference: 0.2798 s/iter. Eval: 0.0003 s/iter. Total: 0.2820 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/09 23:58:19 d2.evaluation.evaluator]: \u001b[0mInference done 103/133. Dataloading: 0.0018 s/iter. Inference: 0.2802 s/iter. Eval: 0.0003 s/iter. Total: 0.2824 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/09 23:58:24 d2.evaluation.evaluator]: \u001b[0mInference done 121/133. Dataloading: 0.0018 s/iter. Inference: 0.2809 s/iter. Eval: 0.0003 s/iter. Total: 0.2831 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/09 23:58:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.330659 (0.283833 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/09 23:58:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:35 (0.280770 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/09 23:58:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/09 23:58:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
      "\u001b[32m[07/09 23:58:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[07/09 23:58:27 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[07/09 23:58:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[07/09 23:58:27 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[07/09 23:58:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.734\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.997\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.961\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.648\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.738\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.778\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.778\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.778\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.784\n",
      "\u001b[32m[07/09 23:58:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 73.381 | 99.713 | 96.128 |  nan  | 64.774 | 73.842 |\n",
      "\u001b[32m[07/09 23:58:27 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[07/09 23:58:27 d2.engine.defaults]: \u001b[0mEvaluation results for turtle_val in csv format:\n",
      "\u001b[32m[07/09 23:58:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[07/09 23:58:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[07/09 23:58:27 d2.evaluation.testing]: \u001b[0mcopypaste: 73.3810,99.7128,96.1284,nan,64.7736,73.8422\n",
      "\u001b[32m[07/09 23:58:30 detectron2]: \u001b[0mLoss on Validation done 11/133. 0.0001 s / img. ETA=0:00:25\n",
      "\u001b[32m[07/09 23:58:35 detectron2]: \u001b[0mLoss on Validation done 31/133. 0.0001 s / img. ETA=0:00:24\n",
      "\u001b[32m[07/09 23:58:40 detectron2]: \u001b[0mLoss on Validation done 53/133. 0.0001 s / img. ETA=0:00:18\n",
      "\u001b[32m[07/09 23:58:45 detectron2]: \u001b[0mLoss on Validation done 76/133. 0.0001 s / img. ETA=0:00:13\n",
      "\u001b[32m[07/09 23:58:50 detectron2]: \u001b[0mLoss on Validation done 98/133. 0.0001 s / img. ETA=0:00:08\n",
      "\u001b[32m[07/09 23:58:56 detectron2]: \u001b[0mLoss on Validation done 119/133. 0.0001 s / img. ETA=0:00:03\n",
      "Best model saved at ./output/best_model.pth\n",
      "\u001b[32m[07/09 23:59:00 d2.utils.events]: \u001b[0m eta: 0:17:00  iter: 299  total_loss: 0.2306  loss_cls: 0.04078  loss_box_reg: 0.1852  loss_rpn_cls: 3.186e-05  loss_rpn_loc: 0.003238  validation_loss: 0.5635  time: 2.5679  data_time: 0.0072  lr: 0.00021386  max_mem: 6130M\n",
      "\u001b[32m[07/09 23:59:53 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 319  total_loss: 0.2204  loss_cls: 0.03646  loss_box_reg: 0.1761  loss_rpn_cls: 6.175e-06  loss_rpn_loc: 0.003283  validation_loss: 0.5635  time: 2.5659  data_time: 0.0066  lr: 0.00022813  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:00:47 d2.utils.events]: \u001b[0m eta: 0:15:18  iter: 339  total_loss: 0.2267  loss_cls: 0.03643  loss_box_reg: 0.177  loss_rpn_cls: 5.49e-05  loss_rpn_loc: 0.002431  validation_loss: 0.5635  time: 2.5756  data_time: 0.0080  lr: 0.0002424  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:01:38 d2.utils.events]: \u001b[0m eta: 0:14:28  iter: 359  total_loss: 0.2016  loss_cls: 0.0451  loss_box_reg: 0.1498  loss_rpn_cls: 6.953e-06  loss_rpn_loc: 0.0022  validation_loss: 0.5635  time: 2.5744  data_time: 0.0066  lr: 0.00025667  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:02:30 d2.utils.events]: \u001b[0m eta: 0:13:37  iter: 379  total_loss: 0.2192  loss_cls: 0.04008  loss_box_reg: 0.1779  loss_rpn_cls: 3.147e-05  loss_rpn_loc: 0.003772  validation_loss: 0.5635  time: 2.5750  data_time: 0.0064  lr: 0.00027094  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:03:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/10 00:03:30 d2.data.common]: \u001b[0mSerializing 133 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/10 00:03:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.05 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/10 00:03:30 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/10 00:03:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 133 batches\n",
      "\u001b[32m[07/10 00:03:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/133. Dataloading: 0.0014 s/iter. Inference: 0.2875 s/iter. Eval: 0.0002 s/iter. Total: 0.2891 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/10 00:03:39 d2.evaluation.evaluator]: \u001b[0mInference done 30/133. Dataloading: 0.0016 s/iter. Inference: 0.2788 s/iter. Eval: 0.0002 s/iter. Total: 0.2808 s/iter. ETA=0:00:28\n",
      "\u001b[32m[07/10 00:03:44 d2.evaluation.evaluator]: \u001b[0mInference done 48/133. Dataloading: 0.0018 s/iter. Inference: 0.2778 s/iter. Eval: 0.0003 s/iter. Total: 0.2799 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/10 00:03:49 d2.evaluation.evaluator]: \u001b[0mInference done 66/133. Dataloading: 0.0018 s/iter. Inference: 0.2794 s/iter. Eval: 0.0003 s/iter. Total: 0.2816 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/10 00:03:54 d2.evaluation.evaluator]: \u001b[0mInference done 84/133. Dataloading: 0.0018 s/iter. Inference: 0.2808 s/iter. Eval: 0.0003 s/iter. Total: 0.2830 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/10 00:03:59 d2.evaluation.evaluator]: \u001b[0mInference done 102/133. Dataloading: 0.0018 s/iter. Inference: 0.2810 s/iter. Eval: 0.0003 s/iter. Total: 0.2832 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/10 00:04:04 d2.evaluation.evaluator]: \u001b[0mInference done 120/133. Dataloading: 0.0018 s/iter. Inference: 0.2817 s/iter. Eval: 0.0003 s/iter. Total: 0.2839 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/10 00:04:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.419678 (0.284529 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/10 00:04:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.281457 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/10 00:04:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/10 00:04:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
      "\u001b[32m[07/10 00:04:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[07/10 00:04:08 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[07/10 00:04:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[07/10 00:04:08 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[07/10 00:04:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.796\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.996\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.938\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.671\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.846\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.846\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.846\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.722\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.855\n",
      "\u001b[32m[07/10 00:04:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 79.604 | 99.609 | 93.763 |  nan  | 67.105 | 80.538 |\n",
      "\u001b[32m[07/10 00:04:08 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[07/10 00:04:08 d2.engine.defaults]: \u001b[0mEvaluation results for turtle_val in csv format:\n",
      "\u001b[32m[07/10 00:04:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[07/10 00:04:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[07/10 00:04:08 d2.evaluation.testing]: \u001b[0mcopypaste: 79.6042,99.6091,93.7629,nan,67.1047,80.5375\n",
      "\u001b[32m[07/10 00:04:11 detectron2]: \u001b[0mLoss on Validation done 11/133. 0.0001 s / img. ETA=0:00:26\n",
      "\u001b[32m[07/10 00:04:16 detectron2]: \u001b[0mLoss on Validation done 31/133. 0.0001 s / img. ETA=0:00:25\n",
      "\u001b[32m[07/10 00:04:21 detectron2]: \u001b[0mLoss on Validation done 53/133. 0.0001 s / img. ETA=0:00:19\n",
      "\u001b[32m[07/10 00:04:26 detectron2]: \u001b[0mLoss on Validation done 76/133. 0.0001 s / img. ETA=0:00:13\n",
      "\u001b[32m[07/10 00:04:31 detectron2]: \u001b[0mLoss on Validation done 98/133. 0.0001 s / img. ETA=0:00:08\n",
      "\u001b[32m[07/10 00:04:36 detectron2]: \u001b[0mLoss on Validation done 119/133. 0.0001 s / img. ETA=0:00:03\n",
      "Best model saved at ./output/best_model.pth\n",
      "\u001b[32m[07/10 00:04:41 d2.utils.events]: \u001b[0m eta: 0:12:45  iter: 399  total_loss: 0.1722  loss_cls: 0.03962  loss_box_reg: 0.1248  loss_rpn_cls: 4.035e-06  loss_rpn_loc: 0.002138  validation_loss: 0.4031  time: 2.5769  data_time: 0.0073  lr: 0.00028522  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:05:35 d2.utils.events]: \u001b[0m eta: 0:11:54  iter: 419  total_loss: 0.1983  loss_cls: 0.03914  loss_box_reg: 0.1575  loss_rpn_cls: 5.815e-06  loss_rpn_loc: 0.003237  validation_loss: 0.4031  time: 2.5799  data_time: 0.0071  lr: 0.00029949  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:06:27 d2.utils.events]: \u001b[0m eta: 0:11:03  iter: 439  total_loss: 0.2132  loss_cls: 0.04625  loss_box_reg: 0.1325  loss_rpn_cls: 3.424e-06  loss_rpn_loc: 0.002606  validation_loss: 0.4031  time: 2.5804  data_time: 0.0063  lr: 0.00031376  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:07:18 d2.utils.events]: \u001b[0m eta: 0:10:12  iter: 459  total_loss: 0.1838  loss_cls: 0.0352  loss_box_reg: 0.1288  loss_rpn_cls: 1.083e-05  loss_rpn_loc: 0.002311  validation_loss: 0.4031  time: 2.5787  data_time: 0.0071  lr: 0.00032803  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:08:11 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 479  total_loss: 0.1743  loss_cls: 0.03415  loss_box_reg: 0.1246  loss_rpn_cls: 1.27e-05  loss_rpn_loc: 0.002768  validation_loss: 0.4031  time: 2.5816  data_time: 0.0079  lr: 0.0003423  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:09:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/10 00:09:08 d2.data.common]: \u001b[0mSerializing 133 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/10 00:09:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.05 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/10 00:09:08 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/10 00:09:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 133 batches\n",
      "\u001b[32m[07/10 00:09:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/133. Dataloading: 0.0014 s/iter. Inference: 0.2879 s/iter. Eval: 0.0002 s/iter. Total: 0.2895 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/10 00:09:17 d2.evaluation.evaluator]: \u001b[0mInference done 30/133. Dataloading: 0.0016 s/iter. Inference: 0.2799 s/iter. Eval: 0.0002 s/iter. Total: 0.2819 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/10 00:09:23 d2.evaluation.evaluator]: \u001b[0mInference done 49/133. Dataloading: 0.0017 s/iter. Inference: 0.2779 s/iter. Eval: 0.0003 s/iter. Total: 0.2800 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/10 00:09:28 d2.evaluation.evaluator]: \u001b[0mInference done 67/133. Dataloading: 0.0017 s/iter. Inference: 0.2794 s/iter. Eval: 0.0003 s/iter. Total: 0.2816 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/10 00:09:33 d2.evaluation.evaluator]: \u001b[0mInference done 85/133. Dataloading: 0.0018 s/iter. Inference: 0.2811 s/iter. Eval: 0.0003 s/iter. Total: 0.2833 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/10 00:09:38 d2.evaluation.evaluator]: \u001b[0mInference done 103/133. Dataloading: 0.0018 s/iter. Inference: 0.2812 s/iter. Eval: 0.0003 s/iter. Total: 0.2834 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/10 00:09:43 d2.evaluation.evaluator]: \u001b[0mInference done 121/133. Dataloading: 0.0018 s/iter. Inference: 0.2817 s/iter. Eval: 0.0003 s/iter. Total: 0.2839 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/10 00:09:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.429107 (0.284602 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/10 00:09:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.281597 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/10 00:09:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/10 00:09:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
      "\u001b[32m[07/10 00:09:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[07/10 00:09:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[07/10 00:09:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[07/10 00:09:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[07/10 00:09:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.838\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.949\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.730\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.846\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.877\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.877\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.877\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.744\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.886\n",
      "\u001b[32m[07/10 00:09:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 83.845 | 99.970 | 94.867 |  nan  | 73.050 | 84.633 |\n",
      "\u001b[32m[07/10 00:09:47 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[07/10 00:09:47 d2.engine.defaults]: \u001b[0mEvaluation results for turtle_val in csv format:\n",
      "\u001b[32m[07/10 00:09:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[07/10 00:09:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[07/10 00:09:47 d2.evaluation.testing]: \u001b[0mcopypaste: 83.8447,99.9704,94.8673,nan,73.0495,84.6333\n",
      "\u001b[32m[07/10 00:09:50 detectron2]: \u001b[0mLoss on Validation done 11/133. 0.0001 s / img. ETA=0:00:26\n",
      "\u001b[32m[07/10 00:09:55 detectron2]: \u001b[0mLoss on Validation done 31/133. 0.0001 s / img. ETA=0:00:24\n",
      "\u001b[32m[07/10 00:10:00 detectron2]: \u001b[0mLoss on Validation done 53/133. 0.0001 s / img. ETA=0:00:18\n",
      "\u001b[32m[07/10 00:10:05 detectron2]: \u001b[0mLoss on Validation done 76/133. 0.0001 s / img. ETA=0:00:13\n",
      "\u001b[32m[07/10 00:10:10 detectron2]: \u001b[0mLoss on Validation done 98/133. 0.0001 s / img. ETA=0:00:08\n",
      "\u001b[32m[07/10 00:10:15 detectron2]: \u001b[0mLoss on Validation done 119/133. 0.0001 s / img. ETA=0:00:03\n",
      "Best model saved at ./output/best_model.pth\n",
      "\u001b[32m[07/10 00:10:20 d2.utils.events]: \u001b[0m eta: 0:08:30  iter: 499  total_loss: 0.151  loss_cls: 0.03057  loss_box_reg: 0.112  loss_rpn_cls: 1.269e-05  loss_rpn_loc: 0.00184  validation_loss: 0.2428  time: 2.5778  data_time: 0.0082  lr: 0.00035657  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:11:17 d2.utils.events]: \u001b[0m eta: 0:07:39  iter: 519  total_loss: 0.1657  loss_cls: 0.02816  loss_box_reg: 0.1239  loss_rpn_cls: 3.971e-05  loss_rpn_loc: 0.001948  validation_loss: 0.2428  time: 2.5863  data_time: 0.0068  lr: 0.00037084  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:12:09 d2.utils.events]: \u001b[0m eta: 0:06:48  iter: 539  total_loss: 0.1461  loss_cls: 0.03193  loss_box_reg: 0.1179  loss_rpn_cls: 3.031e-05  loss_rpn_loc: 0.002075  validation_loss: 0.2428  time: 2.5860  data_time: 0.0065  lr: 0.00038512  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:13:00 d2.utils.events]: \u001b[0m eta: 0:05:57  iter: 559  total_loss: 0.1551  loss_cls: 0.03071  loss_box_reg: 0.1214  loss_rpn_cls: 3.295e-05  loss_rpn_loc: 0.001726  validation_loss: 0.2428  time: 2.5843  data_time: 0.0066  lr: 0.00039939  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:13:53 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 579  total_loss: 0.1588  loss_cls: 0.02696  loss_box_reg: 0.1149  loss_rpn_cls: 7.422e-06  loss_rpn_loc: 0.002091  validation_loss: 0.2428  time: 2.5866  data_time: 0.0069  lr: 0.00041366  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:14:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/10 00:14:54 d2.data.common]: \u001b[0mSerializing 133 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/10 00:14:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.05 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/10 00:14:54 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/10 00:14:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 133 batches\n",
      "\u001b[32m[07/10 00:14:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/133. Dataloading: 0.0015 s/iter. Inference: 0.2883 s/iter. Eval: 0.0002 s/iter. Total: 0.2901 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/10 00:15:03 d2.evaluation.evaluator]: \u001b[0mInference done 30/133. Dataloading: 0.0018 s/iter. Inference: 0.2797 s/iter. Eval: 0.0003 s/iter. Total: 0.2818 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/10 00:15:08 d2.evaluation.evaluator]: \u001b[0mInference done 49/133. Dataloading: 0.0018 s/iter. Inference: 0.2777 s/iter. Eval: 0.0003 s/iter. Total: 0.2798 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/10 00:15:14 d2.evaluation.evaluator]: \u001b[0mInference done 67/133. Dataloading: 0.0018 s/iter. Inference: 0.2792 s/iter. Eval: 0.0003 s/iter. Total: 0.2814 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/10 00:15:19 d2.evaluation.evaluator]: \u001b[0mInference done 85/133. Dataloading: 0.0018 s/iter. Inference: 0.2808 s/iter. Eval: 0.0003 s/iter. Total: 0.2830 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/10 00:15:24 d2.evaluation.evaluator]: \u001b[0mInference done 103/133. Dataloading: 0.0018 s/iter. Inference: 0.2815 s/iter. Eval: 0.0003 s/iter. Total: 0.2837 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/10 00:15:29 d2.evaluation.evaluator]: \u001b[0mInference done 121/133. Dataloading: 0.0018 s/iter. Inference: 0.2820 s/iter. Eval: 0.0003 s/iter. Total: 0.2843 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/10 00:15:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.455452 (0.284808 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/10 00:15:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.281678 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/10 00:15:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/10 00:15:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
      "\u001b[32m[07/10 00:15:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[07/10 00:15:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[07/10 00:15:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[07/10 00:15:33 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[07/10 00:15:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.828\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.997\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.956\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.710\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.842\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.866\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.874\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.874\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.884\n",
      "\u001b[32m[07/10 00:15:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 82.768 | 99.653 | 95.630 |  nan  | 70.958 | 84.179 |\n",
      "\u001b[32m[07/10 00:15:33 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[07/10 00:15:33 d2.engine.defaults]: \u001b[0mEvaluation results for turtle_val in csv format:\n",
      "\u001b[32m[07/10 00:15:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[07/10 00:15:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[07/10 00:15:33 d2.evaluation.testing]: \u001b[0mcopypaste: 82.7680,99.6527,95.6304,nan,70.9583,84.1792\n",
      "\u001b[32m[07/10 00:15:35 detectron2]: \u001b[0mLoss on Validation done 11/133. 0.0001 s / img. ETA=0:00:25\n",
      "\u001b[32m[07/10 00:15:41 detectron2]: \u001b[0mLoss on Validation done 31/133. 0.0001 s / img. ETA=0:00:24\n",
      "\u001b[32m[07/10 00:15:46 detectron2]: \u001b[0mLoss on Validation done 53/133. 0.0001 s / img. ETA=0:00:18\n",
      "\u001b[32m[07/10 00:15:51 detectron2]: \u001b[0mLoss on Validation done 77/133. 0.0001 s / img. ETA=0:00:12\n",
      "\u001b[32m[07/10 00:15:56 detectron2]: \u001b[0mLoss on Validation done 99/133. 0.0001 s / img. ETA=0:00:07\n",
      "\u001b[32m[07/10 00:16:01 detectron2]: \u001b[0mLoss on Validation done 120/133. 0.0001 s / img. ETA=0:00:03\n",
      "\u001b[32m[07/10 00:16:04 d2.utils.events]: \u001b[0m eta: 0:04:15  iter: 599  total_loss: 0.125  loss_cls: 0.02323  loss_box_reg: 0.0984  loss_rpn_cls: 6.072e-06  loss_rpn_loc: 0.001974  validation_loss: 0.2254  time: 2.5897  data_time: 0.0067  lr: 0.00042793  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:16:55 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 619  total_loss: 0.156  loss_cls: 0.0276  loss_box_reg: 0.1281  loss_rpn_cls: 4.515e-06  loss_rpn_loc: 0.002002  validation_loss: 0.2254  time: 2.5883  data_time: 0.0061  lr: 0.0004422  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:17:48 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 639  total_loss: 0.1438  loss_cls: 0.02611  loss_box_reg: 0.1111  loss_rpn_cls: 3.974e-06  loss_rpn_loc: 0.001834  validation_loss: 0.2254  time: 2.5896  data_time: 0.0067  lr: 0.00045647  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:18:39 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 659  total_loss: 0.1366  loss_cls: 0.02413  loss_box_reg: 0.09918  loss_rpn_cls: 9.549e-06  loss_rpn_loc: 0.001891  validation_loss: 0.2254  time: 2.5882  data_time: 0.0062  lr: 0.00047074  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:19:31 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 679  total_loss: 0.1408  loss_cls: 0.02871  loss_box_reg: 0.1123  loss_rpn_cls: 1.047e-05  loss_rpn_loc: 0.001912  validation_loss: 0.2254  time: 2.5887  data_time: 0.0070  lr: 0.00048501  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:20:28 detectron2]: \u001b[0mLoss on Validation done 11/133. 0.0001 s / img. ETA=0:00:26\n",
      "\u001b[32m[07/10 00:20:34 detectron2]: \u001b[0mLoss on Validation done 31/133. 0.0001 s / img. ETA=0:00:25\n",
      "\u001b[32m[07/10 00:20:39 detectron2]: \u001b[0mLoss on Validation done 53/133. 0.0001 s / img. ETA=0:00:19\n",
      "\u001b[32m[07/10 00:20:44 detectron2]: \u001b[0mLoss on Validation done 76/133. 0.0001 s / img. ETA=0:00:13\n",
      "\u001b[32m[07/10 00:20:49 detectron2]: \u001b[0mLoss on Validation done 98/133. 0.0001 s / img. ETA=0:00:08\n",
      "\u001b[32m[07/10 00:20:54 detectron2]: \u001b[0mLoss on Validation done 119/133. 0.0001 s / img. ETA=0:00:03\n",
      "Best model saved at ./output/best_model.pth\n",
      "\u001b[32m[07/10 00:20:59 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 699  total_loss: 0.1939  loss_cls: 0.03326  loss_box_reg: 0.1638  loss_rpn_cls: 1.447e-05  loss_rpn_loc: 0.001834  validation_loss: 0.208  time: 2.5906  data_time: 0.0063  lr: 0.00049929  max_mem: 6130M\n",
      "\u001b[32m[07/10 00:21:01 d2.engine.hooks]: \u001b[0mOverall training speed: 698 iterations in 0:30:08 (2.5906 s / it)\n",
      "\u001b[32m[07/10 00:21:01 d2.engine.hooks]: \u001b[0mTotal training time: 0:38:44 (0:08:36 on hooks)\n",
      "\u001b[32m[07/10 00:21:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/10 00:21:09 d2.data.common]: \u001b[0mSerializing 133 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/10 00:21:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.05 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/10 00:21:09 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[07/10 00:21:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 133 batches\n",
      "\u001b[32m[07/10 00:21:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/133. Dataloading: 0.0014 s/iter. Inference: 0.2875 s/iter. Eval: 0.0003 s/iter. Total: 0.2892 s/iter. ETA=0:00:35\n",
      "\u001b[32m[07/10 00:21:18 d2.evaluation.evaluator]: \u001b[0mInference done 30/133. Dataloading: 0.0017 s/iter. Inference: 0.2793 s/iter. Eval: 0.0003 s/iter. Total: 0.2817 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/10 00:21:23 d2.evaluation.evaluator]: \u001b[0mInference done 49/133. Dataloading: 0.0017 s/iter. Inference: 0.2776 s/iter. Eval: 0.0003 s/iter. Total: 0.2799 s/iter. ETA=0:00:23\n",
      "\u001b[32m[07/10 00:21:28 d2.evaluation.evaluator]: \u001b[0mInference done 67/133. Dataloading: 0.0017 s/iter. Inference: 0.2797 s/iter. Eval: 0.0003 s/iter. Total: 0.2819 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/10 00:21:34 d2.evaluation.evaluator]: \u001b[0mInference done 85/133. Dataloading: 0.0017 s/iter. Inference: 0.2810 s/iter. Eval: 0.0002 s/iter. Total: 0.2832 s/iter. ETA=0:00:13\n",
      "\u001b[32m[07/10 00:21:39 d2.evaluation.evaluator]: \u001b[0mInference done 103/133. Dataloading: 0.0017 s/iter. Inference: 0.2821 s/iter. Eval: 0.0003 s/iter. Total: 0.2843 s/iter. ETA=0:00:08\n",
      "\u001b[32m[07/10 00:21:44 d2.evaluation.evaluator]: \u001b[0mInference done 121/133. Dataloading: 0.0017 s/iter. Inference: 0.2828 s/iter. Eval: 0.0003 s/iter. Total: 0.2850 s/iter. ETA=0:00:03\n",
      "\u001b[32m[07/10 00:21:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.599443 (0.285933 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/10 00:21:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.282900 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/10 00:21:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/10 00:21:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n",
      "\u001b[32m[07/10 00:21:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[07/10 00:21:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[07/10 00:21:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[07/10 00:21:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[07/10 00:21:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.839\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.999\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.939\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.722\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.854\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.878\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.878\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.878\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.744\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.888\n",
      "\u001b[32m[07/10 00:21:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 83.873 | 99.874 | 93.872 |  nan  | 72.167 | 85.390 |\n",
      "\u001b[32m[07/10 00:21:48 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[07/10 00:21:48 d2.engine.defaults]: \u001b[0mEvaluation results for turtle_val in csv format:\n",
      "\u001b[32m[07/10 00:21:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[07/10 00:21:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[07/10 00:21:48 d2.evaluation.testing]: \u001b[0mcopypaste: 83.8727,99.8744,93.8723,nan,72.1669,85.3898\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cfg = get_cfg()\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"turtle_train\",)\n",
    "cfg.DATASETS.TEST = (\"turtle_val\",)\n",
    "cfg.TEST.EVAL_PERIOD = 50\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
    "# Let training initialize from model zoo\n",
    "# Early stopping and checkpoint\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 50\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.REFERENCE_WORLD_SIZE = 2\n",
    "cfg.SOLVER.BASE_LR = 0.001  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 350    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (turtle). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "#trainer = DefaultTrainer(cfg)\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dab32c4",
   "metadata": {
    "papermill": {
     "duration": 0.711276,
     "end_time": "2023-07-10T00:21:49.446181",
     "exception": false,
     "start_time": "2023-07-10T00:21:48.734905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87e0b9f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T00:21:50.835777Z",
     "iopub.status.busy": "2023-07-10T00:21:50.834728Z",
     "iopub.status.idle": "2023-07-10T00:21:53.226789Z",
     "shell.execute_reply": "2023-07-10T00:21:53.226197Z",
     "shell.execute_reply.started": "2023-07-07T00:30:52.376845Z"
    },
    "papermill": {
     "duration": 3.066184,
     "end_time": "2023-07-10T00:21:53.226940",
     "exception": false,
     "start_time": "2023-07-10T00:21:50.160756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.35   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b673145e",
   "metadata": {
    "papermill": {
     "duration": 0.668662,
     "end_time": "2023-07-10T00:21:54.573343",
     "exception": false,
     "start_time": "2023-07-10T00:21:53.904681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading the test dataset and registring it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6738903",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T00:21:55.912567Z",
     "iopub.status.busy": "2023-07-10T00:21:55.911913Z",
     "iopub.status.idle": "2023-07-10T00:21:55.932336Z",
     "shell.execute_reply": "2023-07-10T00:21:55.931755Z",
     "shell.execute_reply.started": "2023-07-07T00:30:52.379104Z"
    },
    "papermill": {
     "duration": 0.692821,
     "end_time": "2023-07-10T00:21:55.932486",
     "exception": false,
     "start_time": "2023-07-10T00:21:55.239665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/detectron2-sea-turtle-data-loader/SampleSubmission.csv')\n",
    "d = 'test'\n",
    "DatasetCatalog.register(\"turtle_\" + d, lambda d=d: get_turtle_box(image_folder,test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7a54ddc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T00:21:57.307612Z",
     "iopub.status.busy": "2023-07-10T00:21:57.306704Z",
     "iopub.status.idle": "2023-07-10T00:22:05.640707Z",
     "shell.execute_reply": "2023-07-10T00:22:05.639689Z",
     "shell.execute_reply.started": "2023-07-07T00:30:52.381112Z"
    },
    "papermill": {
     "duration": 9.043682,
     "end_time": "2023-07-10T00:22:05.640869",
     "exception": false,
     "start_time": "2023-07-10T00:21:56.597187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "testset_dicts = get_turtle_box(image_folder,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a062b0a",
   "metadata": {
    "papermill": {
     "duration": 0.679969,
     "end_time": "2023-07-10T00:22:06.979983",
     "exception": false,
     "start_time": "2023-07-10T00:22:06.300014",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b25462d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T00:22:08.303128Z",
     "iopub.status.busy": "2023-07-10T00:22:08.302232Z",
     "iopub.status.idle": "2023-07-10T00:25:32.907344Z",
     "shell.execute_reply": "2023-07-10T00:25:32.906787Z",
     "shell.execute_reply.started": "2023-07-07T00:30:52.383014Z"
    },
    "papermill": {
     "duration": 205.281506,
     "end_time": "2023-07-10T00:25:32.907504",
     "exception": false,
     "start_time": "2023-07-10T00:22:07.625998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGES_512/E02ABB6C.JPG\n",
      "E02ABB6C\n",
      "Boxes(tensor([[173.1180, 203.9915, 383.3274, 365.9210]], device='cuda:0'))\n",
      "IMAGES_512/9CA35CC5.JPG\n",
      "9CA35CC5\n",
      "Boxes(tensor([[221.0568, 238.7551, 353.0796, 340.1317]], device='cuda:0'))\n",
      "IMAGES_512/F5B0AB72.JPG\n",
      "F5B0AB72\n",
      "Boxes(tensor([[226.9574, 140.5882, 305.1251, 256.4944]], device='cuda:0'))\n",
      "IMAGES_512/58AE1466.JPG\n",
      "58AE1466\n",
      "Boxes(tensor([[203.5870, 182.9815, 323.8069, 360.2692]], device='cuda:0'))\n",
      "IMAGES_512/B4982B53.JPG\n",
      "B4982B53\n",
      "Boxes(tensor([[ 93.5213,  46.0124, 467.1386, 383.1892]], device='cuda:0'))\n",
      "IMAGES_512/387683D3.JPG\n",
      "387683D3\n",
      "Boxes(tensor([[141.1955, 132.4845, 306.7370, 241.7528],\n",
      "        [258.5742,  31.6292, 469.5852, 201.5803]], device='cuda:0'))\n",
      "IMAGES_512/8F46E061.JPG\n",
      "8F46E061\n",
      "Boxes(tensor([[227.0079, 152.8911, 376.0995, 261.4165]], device='cuda:0'))\n",
      "IMAGES_512/CF944985.JPG\n",
      "CF944985\n",
      "Boxes(tensor([[287.7787, 111.1601, 452.0949, 301.2548]], device='cuda:0'))\n",
      "IMAGES_512/72A118D0.JPG\n",
      "72A118D0\n",
      "Boxes(tensor([[296.5618, 106.2188, 411.7884, 242.0674]], device='cuda:0'))\n",
      "IMAGES_512/FA9307D6.JPG\n",
      "FA9307D6\n",
      "Boxes(tensor([[344.9867, 236.1604, 459.3163, 313.1413]], device='cuda:0'))\n",
      "IMAGES_512/A6503EE8.JPG\n",
      "A6503EE8\n",
      "Boxes(tensor([[196.5607, 176.9450, 305.9422, 270.4895],\n",
      "        [283.7967, 122.1700, 339.9097, 171.3326]], device='cuda:0'))\n",
      "IMAGES_512/9D3A22E8.JPG\n",
      "9D3A22E8\n",
      "Boxes(tensor([[258.3094, 118.7409, 411.3771, 301.5722]], device='cuda:0'))\n",
      "IMAGES_512/6257B821.JPG\n",
      "6257B821\n",
      "Boxes(tensor([[208.3288,  25.3985, 349.7274, 140.6916]], device='cuda:0'))\n",
      "IMAGES_512/BE6F8E77.JPG\n",
      "BE6F8E77\n",
      "Boxes(tensor([[209.5835, 234.7845, 282.9873, 318.0244]], device='cuda:0'))\n",
      "IMAGES_512/BC97CBC3.JPG\n",
      "BC97CBC3\n",
      "Boxes(tensor([[206.6624, 224.4036, 296.4554, 381.7201]], device='cuda:0'))\n",
      "IMAGES_512/C7AF779D.JPG\n",
      "C7AF779D\n",
      "Boxes(tensor([[146.1593, 169.6331, 359.8037, 364.9341]], device='cuda:0'))\n",
      "IMAGES_512/BB6ADC65.JPG\n",
      "BB6ADC65\n",
      "Boxes(tensor([[241.4559, 239.1768, 364.4621, 339.8249]], device='cuda:0'))\n",
      "IMAGES_512/39F99202.JPG\n",
      "39F99202\n",
      "Boxes(tensor([[276.1367, 159.4406, 454.3433, 309.5290]], device='cuda:0'))\n",
      "IMAGES_512/D7AB8120.JPG\n",
      "D7AB8120\n",
      "Boxes(tensor([[234.3506, 165.8878, 400.1560, 298.3193]], device='cuda:0'))\n",
      "IMAGES_512/29785033.JPG\n",
      "29785033\n",
      "Boxes(tensor([[211.5583, 187.7825, 330.3456, 377.9135]], device='cuda:0'))\n",
      "IMAGES_512/1EEEAF38.JPG\n",
      "1EEEAF38\n",
      "Boxes(tensor([[ 68.3553, 151.3653, 275.0679, 344.6532]], device='cuda:0'))\n",
      "IMAGES_512/41F65E33.JPG\n",
      "41F65E33\n",
      "Boxes(tensor([[240.2771, 188.6654, 356.4035, 326.3736]], device='cuda:0'))\n",
      "IMAGES_512/CFB9DB9D.JPG\n",
      "CFB9DB9D\n",
      "Boxes(tensor([[178.2291, 192.8230, 344.0261, 381.1744]], device='cuda:0'))\n",
      "IMAGES_512/899B6B9D.JPG\n",
      "899B6B9D\n",
      "Boxes(tensor([[226.8079, 115.1395, 379.0171, 229.4796]], device='cuda:0'))\n",
      "IMAGES_512/293F4108.JPG\n",
      "293F4108\n",
      "Boxes(tensor([[210.3776, 127.3723, 355.5693, 228.4615],\n",
      "        [298.4527, 202.1013, 512.0000, 383.1502],\n",
      "        [400.1741,   4.5424, 453.4695,  60.7433]], device='cuda:0'))\n",
      "IMAGES_512/C480414F.JPG\n",
      "C480414F\n",
      "Boxes(tensor([[263.5372, 153.6082, 346.4810, 232.2671]], device='cuda:0'))\n",
      "IMAGES_512/96B64C97.JPG\n",
      "96B64C97\n",
      "Boxes(tensor([[240.3654, 245.8443, 312.7159, 362.3908]], device='cuda:0'))\n",
      "IMAGES_512/27BB17CB.JPG\n",
      "27BB17CB\n",
      "Boxes(tensor([[257.8873, 244.9361, 345.6531, 318.7351]], device='cuda:0'))\n",
      "IMAGES_512/5BEAAECC.JPG\n",
      "5BEAAECC\n",
      "Boxes(tensor([[245.5311, 162.4561, 331.9918, 253.2296]], device='cuda:0'))\n",
      "IMAGES_512/080287D3.JPG\n",
      "080287D3\n",
      "Boxes(tensor([[232.9525, 117.4337, 341.0966, 298.2823]], device='cuda:0'))\n",
      "IMAGES_512/390F7618.JPG\n",
      "390F7618\n",
      "Boxes(tensor([[250.7839, 132.7382, 385.8865, 252.6858]], device='cuda:0'))\n",
      "IMAGES_512/3DCCEEB7.JPG\n",
      "3DCCEEB7\n",
      "Boxes(tensor([[137.5381, 152.4120, 332.1698, 322.4913]], device='cuda:0'))\n",
      "IMAGES_512/D6919A2A.JPG\n",
      "D6919A2A\n",
      "Boxes(tensor([[149.5636, 198.7617, 370.0329, 336.3625]], device='cuda:0'))\n",
      "IMAGES_512/0FC03BC0.JPG\n",
      "0FC03BC0\n",
      "Boxes(tensor([[210.1158, 234.4934, 333.4513, 375.9201],\n",
      "        [471.6168, 125.9103, 511.5856, 156.3149]], device='cuda:0'))\n",
      "IMAGES_512/98D7E09C.JPG\n",
      "98D7E09C\n",
      "Boxes(tensor([[233.5106, 213.9169, 346.9889, 380.6957],\n",
      "        [173.1983,  25.1413, 448.8925, 242.1717]], device='cuda:0'))\n",
      "IMAGES_512/52EF8628.JPG\n",
      "52EF8628\n",
      "Boxes(tensor([[174.5362, 175.1472, 315.0109, 321.2946]], device='cuda:0'))\n",
      "IMAGES_512/C9B74E21.JPG\n",
      "C9B74E21\n",
      "Boxes(tensor([[183.2773, 125.2499, 358.3687, 281.3531]], device='cuda:0'))\n",
      "IMAGES_512/78ACE9DA.JPG\n",
      "78ACE9DA\n",
      "Boxes(tensor([[170.1348, 167.4795, 290.1662, 291.2505]], device='cuda:0'))\n",
      "IMAGES_512/BA75D17B.JPG\n",
      "BA75D17B\n",
      "Boxes(tensor([[187.5718, 145.0563, 353.5148, 358.7507]], device='cuda:0'))\n",
      "IMAGES_512/1D10F37D.JPG\n",
      "1D10F37D\n",
      "Boxes(tensor([[280.3109, 233.1591, 411.3927, 330.0706]], device='cuda:0'))\n",
      "IMAGES_512/E8DC4D6A.JPG\n",
      "E8DC4D6A\n",
      "Boxes(tensor([[189.1191, 206.7102, 411.6028, 368.4830]], device='cuda:0'))\n",
      "IMAGES_512/28C5A728.JPG\n",
      "28C5A728\n",
      "Boxes(tensor([[208.2581, 101.1512, 357.6119, 249.1509],\n",
      "        [  0.0000, 138.8406, 200.8696, 382.7067]], device='cuda:0'))\n",
      "IMAGES_512/FBE3CCCA.JPG\n",
      "FBE3CCCA\n",
      "Boxes(tensor([[179.9632, 190.4932, 303.7783, 358.6299]], device='cuda:0'))\n",
      "IMAGES_512/8AEE18D5.JPG\n",
      "8AEE18D5\n",
      "Boxes(tensor([[244.2231, 175.3354, 319.2319, 292.5857]], device='cuda:0'))\n",
      "IMAGES_512/BF745478.JPG\n",
      "BF745478\n",
      "Boxes(tensor([[169.6130, 159.9101, 308.9101, 284.7757],\n",
      "        [367.5349, 195.3840, 512.0000, 370.8256]], device='cuda:0'))\n",
      "IMAGES_512/7C6977E8.JPG\n",
      "7C6977E8\n",
      "Boxes(tensor([[306.9468, 133.2713, 415.9659, 291.1723]], device='cuda:0'))\n",
      "IMAGES_512/9D668D45.JPG\n",
      "9D668D45\n",
      "Boxes(tensor([[236.2499, 198.2410, 360.3968, 319.5147]], device='cuda:0'))\n",
      "IMAGES_512/D3C59C12.JPG\n",
      "D3C59C12\n",
      "Boxes(tensor([[ 89.0416,  43.1287, 410.2972, 332.6973]], device='cuda:0'))\n",
      "IMAGES_512/C8C695BD.JPG\n",
      "C8C695BD\n",
      "Boxes(tensor([[108.5799, 179.5924, 293.2305, 303.8609]], device='cuda:0'))\n",
      "IMAGES_512/B88CA671.JPG\n",
      "B88CA671\n",
      "Boxes(tensor([[136.5031, 163.7698, 313.1102, 338.1841]], device='cuda:0'))\n",
      "IMAGES_512/EB7B79CC.JPG\n",
      "EB7B79CC\n",
      "Boxes(tensor([[162.2045, 127.8167, 377.3592, 311.5244]], device='cuda:0'))\n",
      "IMAGES_512/F8E76836.JPG\n",
      "F8E76836\n",
      "Boxes(tensor([[220.8260,  84.9934, 326.2588, 185.8762]], device='cuda:0'))\n",
      "IMAGES_512/1674884D.JPG\n",
      "1674884D\n",
      "Boxes(tensor([[198.1631, 200.8821, 353.6482, 339.3145]], device='cuda:0'))\n",
      "IMAGES_512/7A8D69D4.JPG\n",
      "7A8D69D4\n",
      "Boxes(tensor([[254.8563, 209.1503, 459.3574, 345.8995]], device='cuda:0'))\n",
      "IMAGES_512/9A27639C.JPG\n",
      "9A27639C\n",
      "Boxes(tensor([[194.6464, 201.6977, 291.7225, 319.7827]], device='cuda:0'))\n",
      "IMAGES_512/102B4CAA.JPG\n",
      "102B4CAA\n",
      "Boxes(tensor([[197.9771, 167.3078, 309.0490, 263.1799]], device='cuda:0'))\n",
      "IMAGES_512/C2BDF256.JPG\n",
      "C2BDF256\n",
      "Boxes(tensor([[276.3352, 180.3909, 368.3010, 259.9145]], device='cuda:0'))\n",
      "IMAGES_512/F8057916.JPG\n",
      "F8057916\n",
      "Boxes(tensor([[242.4767, 202.5590, 346.1947, 283.7868]], device='cuda:0'))\n",
      "IMAGES_512/810DE043.JPG\n",
      "810DE043\n",
      "Boxes(tensor([[223.0430, 225.5647, 323.2217, 294.8518]], device='cuda:0'))\n",
      "IMAGES_512/807C2B90.JPG\n",
      "807C2B90\n",
      "Boxes(tensor([[152.5164, 194.9990, 304.3011, 315.8536]], device='cuda:0'))\n",
      "IMAGES_512/C9138871.JPG\n",
      "C9138871\n",
      "Boxes(tensor([[204.8372, 237.6257, 318.3727, 360.6885]], device='cuda:0'))\n",
      "IMAGES_512/EC174B2A.JPG\n",
      "EC174B2A\n",
      "Boxes(tensor([[175.1516, 183.0520, 298.5933, 284.1499]], device='cuda:0'))\n",
      "IMAGES_512/53FEAF96.JPG\n",
      "53FEAF96\n",
      "Boxes(tensor([[1.7352e+02, 1.4713e+02, 2.7224e+02, 2.7321e+02],\n",
      "        [3.0225e+02, 2.6711e-01, 5.1200e+02, 2.4490e+02]], device='cuda:0'))\n",
      "IMAGES_512/0F8696DB.JPG\n",
      "0F8696DB\n",
      "Boxes(tensor([[174.3548, 227.9005, 289.3792, 327.1814]], device='cuda:0'))\n",
      "IMAGES_512/18A4725E.JPG\n",
      "18A4725E\n",
      "Boxes(tensor([[141.8302, 188.2834, 312.1401, 319.3177]], device='cuda:0'))\n",
      "IMAGES_512/846134F3.JPG\n",
      "846134F3\n",
      "Boxes(tensor([[359.9525, 203.8885, 390.5171, 246.8819],\n",
      "        [195.1726, 207.9386, 275.6898, 260.3949]], device='cuda:0'))\n",
      "IMAGES_512/00D2330B.JPG\n",
      "00D2330B\n",
      "Boxes(tensor([[104.4223, 157.7841, 336.0434, 336.2668]], device='cuda:0'))\n",
      "IMAGES_512/446B852B.JPG\n",
      "446B852B\n",
      "Boxes(tensor([[247.2194, 179.5955, 343.3556, 334.7998]], device='cuda:0'))\n",
      "IMAGES_512/9B6ADE47.JPG\n",
      "9B6ADE47\n",
      "Boxes(tensor([[245.2095, 149.0269, 320.1354, 220.5875]], device='cuda:0'))\n",
      "IMAGES_512/F46313D3.JPG\n",
      "F46313D3\n",
      "Boxes(tensor([[ 83.2291, 227.1841, 207.4512, 382.4099]], device='cuda:0'))\n",
      "IMAGES_512/91009A03.JPG\n",
      "91009A03\n",
      "Boxes(tensor([[192.2509, 123.9208, 268.1771, 206.7139]], device='cuda:0'))\n",
      "IMAGES_512/7F0A3567.JPG\n",
      "7F0A3567\n",
      "Boxes(tensor([[221.5241, 116.8342, 292.8296, 183.9055]], device='cuda:0'))\n",
      "IMAGES_512/FB03C6EC.JPG\n",
      "FB03C6EC\n",
      "Boxes(tensor([[309.0223, 180.9378, 389.6292, 305.4105]], device='cuda:0'))\n",
      "IMAGES_512/53DBD9AD.JPG\n",
      "53DBD9AD\n",
      "Boxes(tensor([[220.3334, 167.2610, 420.4539, 300.4465]], device='cuda:0'))\n",
      "IMAGES_512/AD18625B.JPG\n",
      "AD18625B\n",
      "Boxes(tensor([[131.0814, 170.1658, 348.2952, 315.6641]], device='cuda:0'))\n",
      "IMAGES_512/3107F6C8.JPG\n",
      "3107F6C8\n",
      "Boxes(tensor([[152.3079, 146.1488, 279.2797, 281.5448]], device='cuda:0'))\n",
      "IMAGES_512/6EED856E.JPG\n",
      "6EED856E\n",
      "Boxes(tensor([[257.0724, 211.9365, 348.1836, 292.8618]], device='cuda:0'))\n",
      "IMAGES_512/98A4B666.JPG\n",
      "98A4B666\n",
      "Boxes(tensor([[225.2213, 178.3132, 350.0852, 266.5081]], device='cuda:0'))\n",
      "IMAGES_512/56D19D87.JPG\n",
      "56D19D87\n",
      "Boxes(tensor([[303.1424, 219.8699, 390.0688, 318.4638]], device='cuda:0'))\n",
      "IMAGES_512/CF0370A6.JPG\n",
      "CF0370A6\n",
      "Boxes(tensor([[204.4872, 181.7594, 373.6034, 313.6243]], device='cuda:0'))\n",
      "IMAGES_512/AA39E182.JPG\n",
      "AA39E182\n",
      "Boxes(tensor([[294.6169, 155.8095, 415.1776, 247.3193]], device='cuda:0'))\n",
      "IMAGES_512/4863D911.JPG\n",
      "4863D911\n",
      "Boxes(tensor([[ 92.6049, 117.7841, 390.7105, 317.5123]], device='cuda:0'))\n",
      "IMAGES_512/0380861A.JPG\n",
      "0380861A\n",
      "Boxes(tensor([[283.0786, 222.6120, 380.5128, 381.6253]], device='cuda:0'))\n",
      "IMAGES_512/3D42B555.JPG\n",
      "3D42B555\n",
      "Boxes(tensor([[278.8584, 187.6511, 360.4328, 324.0684]], device='cuda:0'))\n",
      "IMAGES_512/5C8D4687.JPG\n",
      "5C8D4687\n",
      "Boxes(tensor([[251.6721, 230.8171, 349.6611, 316.0462]], device='cuda:0'))\n",
      "IMAGES_512/5D02A4E6.JPG\n",
      "5D02A4E6\n",
      "Boxes(tensor([[246.0771, 159.5390, 319.0160, 258.0401]], device='cuda:0'))\n",
      "IMAGES_512/D64AB456.JPG\n",
      "D64AB456\n",
      "Boxes(tensor([[215.5723, 133.7381, 316.1010, 206.1195]], device='cuda:0'))\n",
      "IMAGES_512/212B1A07.JPG\n",
      "212B1A07\n",
      "Boxes(tensor([[235.6595, 155.1995, 358.1687, 252.1469]], device='cuda:0'))\n",
      "IMAGES_512/75850123.JPG\n",
      "75850123\n",
      "Boxes(tensor([[192.0813, 128.7738, 418.4618, 302.0785]], device='cuda:0'))\n",
      "IMAGES_512/ED970E5B.JPG\n",
      "ED970E5B\n",
      "Boxes(tensor([[166.3537, 186.0586, 371.3413, 335.7805]], device='cuda:0'))\n",
      "IMAGES_512/53FAC2BB.JPG\n",
      "53FAC2BB\n",
      "Boxes(tensor([[199.3186, 212.2242, 319.6297, 352.5319]], device='cuda:0'))\n",
      "IMAGES_512/ED100406.JPG\n",
      "ED100406\n",
      "Boxes(tensor([[163.7421, 189.8771, 295.0322, 304.5760]], device='cuda:0'))\n",
      "IMAGES_512/10D787DF.JPG\n",
      "10D787DF\n",
      "Boxes(tensor([[216.6393, 240.6879, 293.8283, 349.9119]], device='cuda:0'))\n",
      "IMAGES_512/DD4463FC.JPG\n",
      "DD4463FC\n",
      "Boxes(tensor([[265.3361, 232.5015, 343.2514, 369.5027]], device='cuda:0'))\n",
      "IMAGES_512/B3E6AACC.JPG\n",
      "B3E6AACC\n",
      "Boxes(tensor([[219.8227, 258.2765, 290.0213, 374.2826]], device='cuda:0'))\n",
      "IMAGES_512/025B967E.JPG\n",
      "025B967E\n",
      "Boxes(tensor([[292.7027, 156.7015, 394.4047, 258.1449]], device='cuda:0'))\n",
      "IMAGES_512/384CCA4C.JPG\n",
      "384CCA4C\n",
      "Boxes(tensor([[184.5977,  53.2354, 490.3558, 328.2079]], device='cuda:0'))\n",
      "IMAGES_512/2396A0F0.JPG\n",
      "2396A0F0\n",
      "Boxes(tensor([[257.8710, 220.9412, 376.5136, 350.4758]], device='cuda:0'))\n",
      "IMAGES_512/ACDC5125.JPG\n",
      "ACDC5125\n",
      "Boxes(tensor([[208.9420, 128.4635, 408.3465, 270.3384]], device='cuda:0'))\n",
      "IMAGES_512/58BEBA5F.JPG\n",
      "58BEBA5F\n",
      "Boxes(tensor([[236.5477, 170.5421, 370.4692, 373.0569],\n",
      "        [159.4618, 173.8845, 228.3185, 234.7369]], device='cuda:0'))\n",
      "IMAGES_512/C6E390ED.JPG\n",
      "C6E390ED\n",
      "Boxes(tensor([[228.3190,  25.1953, 429.8784, 250.1837]], device='cuda:0'))\n",
      "IMAGES_512/92299E39.JPG\n",
      "92299E39\n",
      "Boxes(tensor([[197.1517, 187.2906, 267.7097, 246.7227]], device='cuda:0'))\n",
      "IMAGES_512/E6088555.JPG\n",
      "E6088555\n",
      "Boxes(tensor([[125.3278,  97.5965, 287.3618, 255.8546]], device='cuda:0'))\n",
      "IMAGES_512/8498E2BE.JPG\n",
      "8498E2BE\n",
      "Boxes(tensor([[179.5206, 240.8273, 303.7529, 320.3253],\n",
      "        [161.2227,  62.0791, 430.5274, 231.9446]], device='cuda:0'))\n",
      "IMAGES_512/37ABCFD7.JPG\n",
      "37ABCFD7\n",
      "Boxes(tensor([[230.1180, 116.8690, 421.3059, 273.2487]], device='cuda:0'))\n",
      "IMAGES_512/FA78C187.JPG\n",
      "FA78C187\n",
      "Boxes(tensor([[211.6173, 203.1503, 328.2155, 310.9718]], device='cuda:0'))\n",
      "IMAGES_512/7A4853E0.JPG\n",
      "7A4853E0\n",
      "Boxes(tensor([[200.7658,  94.6067, 451.3003, 340.8202]], device='cuda:0'))\n",
      "IMAGES_512/575B15C7.JPG\n",
      "575B15C7\n",
      "Boxes(tensor([[201.4114, 136.6580, 361.4796, 266.5996]], device='cuda:0'))\n",
      "IMAGES_512/86D3C289.JPG\n",
      "86D3C289\n",
      "Boxes(tensor([[209.9102, 134.7644, 316.8870, 231.7104]], device='cuda:0'))\n",
      "IMAGES_512/124D4882.JPG\n",
      "124D4882\n",
      "Boxes(tensor([[228.5621, 138.1935, 389.5426, 265.6694]], device='cuda:0'))\n",
      "IMAGES_512/3A04887A.JPG\n",
      "3A04887A\n",
      "Boxes(tensor([[200.0716, 151.3017, 323.1081, 362.5305]], device='cuda:0'))\n",
      "IMAGES_512/46C50897.JPG\n",
      "46C50897\n",
      "Boxes(tensor([[159.1570, 163.7218, 329.3560, 310.1250]], device='cuda:0'))\n",
      "IMAGES_512/261D6D22.JPG\n",
      "261D6D22\n",
      "Boxes(tensor([[174.8313, 148.4928, 306.8895, 280.2044]], device='cuda:0'))\n",
      "IMAGES_512/C59215A7.JPG\n",
      "C59215A7\n",
      "Boxes(tensor([[242.0382, 182.5401, 322.9472, 316.6990]], device='cuda:0'))\n",
      "IMAGES_512/4BBFA623.JPG\n",
      "4BBFA623\n",
      "Boxes(tensor([[207.8486, 161.0119, 340.3961, 275.3885]], device='cuda:0'))\n",
      "IMAGES_512/C6B23110.JPG\n",
      "C6B23110\n",
      "Boxes(tensor([[227.5049, 115.2627, 305.6302, 194.3616],\n",
      "        [113.8798, 117.3864, 309.7108, 271.3882],\n",
      "        [340.8408,  62.7393, 427.3971, 161.2966]], device='cuda:0'))\n",
      "IMAGES_512/0A0ADA58.JPG\n",
      "0A0ADA58\n",
      "Boxes(tensor([[148.5547, 120.5954, 356.6666, 260.2523]], device='cuda:0'))\n",
      "IMAGES_512/0C2A5299.JPG\n",
      "0C2A5299\n",
      "Boxes(tensor([[288.5421, 105.3726, 468.0315, 273.9001]], device='cuda:0'))\n",
      "IMAGES_512/617F00E3.JPG\n",
      "617F00E3\n",
      "Boxes(tensor([[216.9245, 135.7876, 353.6738, 253.8076]], device='cuda:0'))\n",
      "IMAGES_512/E971C5CF.JPG\n",
      "E971C5CF\n",
      "Boxes(tensor([[132.5786, 194.5005, 260.3865, 294.1142]], device='cuda:0'))\n",
      "IMAGES_512/8CFDE8A5.JPG\n",
      "8CFDE8A5\n",
      "Boxes(tensor([[198.6899,  90.9879, 415.4647, 246.5249]], device='cuda:0'))\n",
      "IMAGES_512/BF520C3D.JPG\n",
      "BF520C3D\n",
      "Boxes(tensor([[ 94.2288,  95.8225, 262.9867, 239.9653]], device='cuda:0'))\n",
      "IMAGES_512/3B76E5E3.JPG\n",
      "3B76E5E3\n",
      "Boxes(tensor([[192.6017, 183.6823, 297.7836, 321.7466]], device='cuda:0'))\n",
      "IMAGES_512/0209DE5C.JPG\n",
      "0209DE5C\n",
      "Boxes(tensor([[177.5715, 123.6348, 278.1862, 187.8680]], device='cuda:0'))\n",
      "IMAGES_512/E6E29AED.JPG\n",
      "E6E29AED\n",
      "Boxes(tensor([[186.9379,  93.3363, 505.7940, 347.8241]], device='cuda:0'))\n",
      "IMAGES_512/E741F8D5.JPG\n",
      "E741F8D5\n",
      "Boxes(tensor([[223.5869, 153.1727, 382.4199, 329.6728]], device='cuda:0'))\n",
      "IMAGES_512/D9C365EF.JPG\n",
      "D9C365EF\n",
      "Boxes(tensor([[165.2759,  84.8259, 365.8154, 215.7661],\n",
      "        [326.7162, 217.5680, 499.5144, 379.7648]], device='cuda:0'))\n",
      "IMAGES_512/9A35C300.JPG\n",
      "9A35C300\n",
      "Boxes(tensor([[239.3372, 161.6539, 295.6274, 251.9580]], device='cuda:0'))\n",
      "IMAGES_512/C91383EA.JPG\n",
      "C91383EA\n",
      "Boxes(tensor([[168.1407, 108.5649, 323.6898, 223.8001]], device='cuda:0'))\n",
      "IMAGES_512/36529F94.JPG\n",
      "36529F94\n",
      "Boxes(tensor([[ 38.6036, 205.8914, 205.9102, 340.0749]], device='cuda:0'))\n",
      "IMAGES_512/4CBFE052.JPG\n",
      "4CBFE052\n",
      "Boxes(tensor([[182.8671, 109.3362, 366.9544, 280.6854],\n",
      "        [  6.1272, 150.2057, 199.8889, 383.1750]], device='cuda:0'))\n",
      "IMAGES_512/875C19F4.JPG\n",
      "875C19F4\n",
      "Boxes(tensor([[185.4888, 174.9886, 398.3068, 349.8301]], device='cuda:0'))\n",
      "IMAGES_512/4EFBBC6B.JPG\n",
      "4EFBBC6B\n",
      "Boxes(tensor([[184.9609, 104.7655, 303.9852, 235.9637]], device='cuda:0'))\n",
      "IMAGES_512/0454B658.JPG\n",
      "0454B658\n",
      "Boxes(tensor([[269.6831, 212.3989, 368.2218, 367.7563]], device='cuda:0'))\n",
      "IMAGES_512/6BF55E58.JPG\n",
      "6BF55E58\n",
      "Boxes(tensor([[209.7032, 257.8264, 298.7917, 344.2103]], device='cuda:0'))\n",
      "IMAGES_512/0B4929A8.JPG\n",
      "0B4929A8\n",
      "Boxes(tensor([[197.4526, 228.7600, 284.3009, 341.6340]], device='cuda:0'))\n",
      "IMAGES_512/A8934ACC.JPG\n",
      "A8934ACC\n",
      "Boxes(tensor([[199.4072, 195.7084, 332.2188, 349.2625]], device='cuda:0'))\n",
      "IMAGES_512/78C06885.JPG\n",
      "78C06885\n",
      "Boxes(tensor([[200.2522, 167.3104, 304.8878, 261.2054]], device='cuda:0'))\n",
      "IMAGES_512/16A6F770.JPG\n",
      "16A6F770\n",
      "Boxes(tensor([[ 33.6866, 185.1376, 263.3587, 329.4616]], device='cuda:0'))\n",
      "IMAGES_512/E0545AD0.JPG\n",
      "E0545AD0\n",
      "Boxes(tensor([[207.9879, 187.4205, 312.0081, 312.7358]], device='cuda:0'))\n",
      "IMAGES_512/1E0DEBE1.JPG\n",
      "1E0DEBE1\n",
      "Boxes(tensor([[215.9834, 138.8670, 297.2817, 271.3071]], device='cuda:0'))\n",
      "IMAGES_512/9953F529.JPG\n",
      "9953F529\n",
      "Boxes(tensor([[256.7504, 188.2787, 325.6617, 248.5659]], device='cuda:0'))\n",
      "IMAGES_512/98F28C19.JPG\n",
      "98F28C19\n",
      "Boxes(tensor([[116.8104, 206.2973, 278.8347, 337.4672]], device='cuda:0'))\n",
      "IMAGES_512/2A24B9AE.JPG\n",
      "2A24B9AE\n",
      "Boxes(tensor([[273.4070, 204.8271, 375.6356, 284.9355]], device='cuda:0'))\n",
      "IMAGES_512/94D3313A.JPG\n",
      "94D3313A\n",
      "Boxes(tensor([[190.9587, 174.4740, 277.9034, 269.3256]], device='cuda:0'))\n",
      "IMAGES_512/45F9D6E1.JPG\n",
      "45F9D6E1\n",
      "Boxes(tensor([[231.4317, 238.5980, 309.0979, 375.9237]], device='cuda:0'))\n",
      "IMAGES_512/CFDDCFAE.JPG\n",
      "CFDDCFAE\n",
      "Boxes(tensor([[255.4150, 181.8416, 344.6938, 289.3021]], device='cuda:0'))\n",
      "IMAGES_512/1484E921.JPG\n",
      "1484E921\n",
      "Boxes(tensor([[283.6830, 170.4098, 461.1306, 313.4221]], device='cuda:0'))\n",
      "IMAGES_512/3A4FD2A1.JPG\n",
      "3A4FD2A1\n",
      "Boxes(tensor([[116.8919, 133.4346, 287.4425, 265.0324],\n",
      "        [  0.0000, 255.1206, 122.8418, 383.0887]], device='cuda:0'))\n",
      "IMAGES_512/305757A8.JPG\n",
      "305757A8\n",
      "Boxes(tensor([[167.0773, 151.6930, 227.2636, 208.4605]], device='cuda:0'))\n",
      "IMAGES_512/23CD810A.JPG\n",
      "23CD810A\n",
      "Boxes(tensor([[214.5376, 171.8902, 306.2757, 263.7978]], device='cuda:0'))\n",
      "IMAGES_512/7463392A.JPG\n",
      "7463392A\n",
      "Boxes(tensor([[263.0541, 180.0840, 429.6873, 292.3845]], device='cuda:0'))\n",
      "IMAGES_512/72BFFA57.JPG\n",
      "72BFFA57\n",
      "Boxes(tensor([[283.8857, 120.5797, 399.1035, 240.1351]], device='cuda:0'))\n",
      "IMAGES_512/D93C47B5.JPG\n",
      "D93C47B5\n",
      "Boxes(tensor([[233.0691, 219.7220, 312.1105, 336.2089]], device='cuda:0'))\n",
      "IMAGES_512/E8538C05.JPG\n",
      "E8538C05\n",
      "Boxes(tensor([[156.0594, 128.5940, 273.3903, 246.6585]], device='cuda:0'))\n",
      "IMAGES_512/CC38D318.JPG\n",
      "CC38D318\n",
      "Boxes(tensor([[180.0494,  86.2224, 384.3603, 217.0614]], device='cuda:0'))\n",
      "IMAGES_512/9D248BE4.JPG\n",
      "9D248BE4\n",
      "Boxes(tensor([[201.3312, 182.9599, 391.4635, 338.3217]], device='cuda:0'))\n",
      "IMAGES_512/26A34A9C.JPG\n",
      "26A34A9C\n",
      "Boxes(tensor([[161.9711, 184.2814, 285.8620, 307.8550]], device='cuda:0'))\n",
      "IMAGES_512/BA484FD6.JPG\n",
      "BA484FD6\n",
      "Boxes(tensor([[231.7800, 171.8445, 329.5462, 319.0680]], device='cuda:0'))\n",
      "IMAGES_512/AD9FCD41.JPG\n",
      "AD9FCD41\n",
      "Boxes(tensor([[292.5613, 194.3560, 437.1277, 307.9189]], device='cuda:0'))\n",
      "IMAGES_512/F03531EA.JPG\n",
      "F03531EA\n",
      "Boxes(tensor([[280.1619, 146.2950, 426.7909, 335.0298]], device='cuda:0'))\n",
      "IMAGES_512/6DE171C8.JPG\n",
      "6DE171C8\n",
      "Boxes(tensor([[ 26.0588, 143.8813, 262.9861, 365.5030]], device='cuda:0'))\n",
      "IMAGES_512/A94BA02F.JPG\n",
      "A94BA02F\n",
      "Boxes(tensor([[159.1418,  99.2207, 262.4199, 240.6876]], device='cuda:0'))\n",
      "IMAGES_512/339A38E2.JPG\n",
      "339A38E2\n",
      "Boxes(tensor([[232.8336, 194.2307, 330.8420, 283.3934],\n",
      "        [417.6202,  16.6687, 511.2745,  45.9571]], device='cuda:0'))\n",
      "IMAGES_512/4C1CD725.JPG\n",
      "4C1CD725\n",
      "Boxes(tensor([[218.7441, 181.2973, 321.3748, 341.5823],\n",
      "        [114.1343, 150.4326, 179.6033, 261.9968]], device='cuda:0'))\n",
      "IMAGES_512/17F6EBC0.JPG\n",
      "17F6EBC0\n",
      "Boxes(tensor([[240.3036, 229.5482, 330.2773, 375.9875]], device='cuda:0'))\n",
      "IMAGES_512/CCD2C54F.JPG\n",
      "CCD2C54F\n",
      "Boxes(tensor([[204.2678, 153.9906, 328.9386, 343.3499]], device='cuda:0'))\n",
      "IMAGES_512/C83830A0.JPG\n",
      "C83830A0\n",
      "Boxes(tensor([[329.4199, 150.4864, 459.7446, 273.9984],\n",
      "        [273.1107,  84.2662, 330.5180, 163.4828],\n",
      "        [313.6369,  60.4718, 511.4666, 218.8925]], device='cuda:0'))\n",
      "IMAGES_512/74F3AE65.JPG\n",
      "74F3AE65\n",
      "Boxes(tensor([[192.7731, 173.8782, 432.7174, 365.4763]], device='cuda:0'))\n",
      "IMAGES_512/EA8630F7.JPG\n",
      "EA8630F7\n",
      "Boxes(tensor([[206.8445, 188.7750, 374.9684, 312.1740]], device='cuda:0'))\n",
      "IMAGES_512/1E9E94E9.JPG\n",
      "1E9E94E9\n",
      "Boxes(tensor([[284.7356, 142.0306, 341.5942, 227.7200]], device='cuda:0'))\n",
      "IMAGES_512/3FFB881C.JPG\n",
      "3FFB881C\n",
      "Boxes(tensor([[269.2214, 135.0296, 336.9164, 221.9836]], device='cuda:0'))\n",
      "IMAGES_512/BB709F9F.JPG\n",
      "BB709F9F\n",
      "Boxes(tensor([[252.6930, 185.4176, 371.2260, 318.0363]], device='cuda:0'))\n",
      "IMAGES_512/F05C9067.JPG\n",
      "F05C9067\n",
      "Boxes(tensor([[261.4137, 149.9148, 423.4948, 271.1818]], device='cuda:0'))\n",
      "IMAGES_512/5018DBF4.JPG\n",
      "5018DBF4\n",
      "Boxes(tensor([[209.7656, 161.4201, 323.0636, 371.0766]], device='cuda:0'))\n",
      "IMAGES_512/9D1F841B.JPG\n",
      "9D1F841B\n",
      "Boxes(tensor([[143.4397,  61.0395, 314.4511, 192.0235]], device='cuda:0'))\n",
      "IMAGES_512/C09E25FD.JPG\n",
      "C09E25FD\n",
      "Boxes(tensor([[303.7275, 230.9375, 385.2522, 330.8361],\n",
      "        [222.9237,  21.9180, 496.3687, 219.7005]], device='cuda:0'))\n",
      "IMAGES_512/2CF5B603.JPG\n",
      "2CF5B603\n",
      "Boxes(tensor([[204.6748, 191.5405, 292.1154, 343.4028]], device='cuda:0'))\n",
      "IMAGES_512/A8487D43.JPG\n",
      "A8487D43\n",
      "Boxes(tensor([[186.8502, 112.0492, 274.4299, 185.7612]], device='cuda:0'))\n",
      "IMAGES_512/699D7428.JPG\n",
      "699D7428\n",
      "Boxes(tensor([[247.1252, 191.6097, 379.1562, 309.6125]], device='cuda:0'))\n",
      "IMAGES_512/94ACB84D.JPG\n",
      "94ACB84D\n",
      "Boxes(tensor([[238.0779, 169.5494, 322.2020, 256.5434]], device='cuda:0'))\n",
      "IMAGES_512/5FE5C0D0.JPG\n",
      "5FE5C0D0\n",
      "Boxes(tensor([[227.1228, 137.3434, 457.7318, 309.1203]], device='cuda:0'))\n",
      "IMAGES_512/F583D09E.JPG\n",
      "F583D09E\n",
      "Boxes(tensor([[ 82.3226, 162.6230, 301.0179, 339.3253]], device='cuda:0'))\n",
      "IMAGES_512/CF18869B.JPG\n",
      "CF18869B\n",
      "Boxes(tensor([[257.0869, 208.0178, 410.9954, 332.5997]], device='cuda:0'))\n",
      "IMAGES_512/5721F61E.JPG\n",
      "5721F61E\n",
      "Boxes(tensor([[170.0996, 151.8092, 284.3216, 250.4285]], device='cuda:0'))\n",
      "IMAGES_512/CDE4A1E3.JPG\n",
      "CDE4A1E3\n",
      "Boxes(tensor([[205.3734, 103.8399, 424.4380, 326.2443]], device='cuda:0'))\n",
      "IMAGES_512/0F6834B4.JPG\n",
      "0F6834B4\n",
      "Boxes(tensor([[254.7632, 188.7124, 385.1640, 320.7415]], device='cuda:0'))\n",
      "IMAGES_512/B545FC68.JPG\n",
      "B545FC68\n",
      "Boxes(tensor([[223.0352, 184.8912, 350.2000, 351.2397]], device='cuda:0'))\n",
      "IMAGES_512/39E49293.JPG\n",
      "39E49293\n",
      "Boxes(tensor([[258.8390, 183.8647, 449.0556, 322.0827]], device='cuda:0'))\n",
      "IMAGES_512/4915A329.JPG\n",
      "4915A329\n",
      "Boxes(tensor([[239.4259, 172.1880, 400.5398, 275.3728]], device='cuda:0'))\n",
      "IMAGES_512/C8B64404.JPG\n",
      "C8B64404\n",
      "Boxes(tensor([[290.1251, 177.7863, 403.8014, 284.2043]], device='cuda:0'))\n",
      "IMAGES_512/0EC294FB.JPG\n",
      "0EC294FB\n",
      "Boxes(tensor([[269.4614, 248.7763, 348.8568, 381.3867]], device='cuda:0'))\n",
      "IMAGES_512/9B84D8B9.JPG\n",
      "9B84D8B9\n",
      "Boxes(tensor([[194.3792, 129.8911, 344.5883, 353.8323]], device='cuda:0'))\n",
      "IMAGES_512/27EDFA41.JPG\n",
      "27EDFA41\n",
      "Boxes(tensor([[231.4077, 197.9823, 366.2228, 308.1871]], device='cuda:0'))\n",
      "IMAGES_512/15BCF70C.JPG\n",
      "15BCF70C\n",
      "Boxes(tensor([[233.5246, 124.8247, 427.1977, 265.7721]], device='cuda:0'))\n",
      "IMAGES_512/CA49AC74.JPG\n",
      "CA49AC74\n",
      "Boxes(tensor([[265.6250, 158.6954, 510.8074, 314.4046]], device='cuda:0'))\n",
      "IMAGES_512/91D49144.JPG\n",
      "91D49144\n",
      "Boxes(tensor([[217.3427,  66.8464, 290.4784, 156.4724]], device='cuda:0'))\n",
      "IMAGES_512/082EFA1B.JPG\n",
      "082EFA1B\n",
      "Boxes(tensor([[214.8672, 296.6425, 347.6831, 384.0000]], device='cuda:0'))\n",
      "IMAGES_512/5B0A8D03.JPG\n",
      "5B0A8D03\n",
      "Boxes(tensor([[198.3925, 228.9972, 274.9904, 359.9385]], device='cuda:0'))\n",
      "IMAGES_512/26C328A6.JPG\n",
      "26C328A6\n",
      "Boxes(tensor([[234.7261, 272.8521, 335.3424, 348.7311],\n",
      "        [465.2414,  25.2036, 511.3821, 135.1196]], device='cuda:0'))\n",
      "IMAGES_512/90B25E25.JPG\n",
      "90B25E25\n",
      "Boxes(tensor([[250.7952, 151.2468, 370.1714, 273.9077]], device='cuda:0'))\n",
      "IMAGES_512/896C3367.JPG\n",
      "896C3367\n",
      "Boxes(tensor([[236.8084, 175.4335, 363.1336, 306.9872]], device='cuda:0'))\n",
      "IMAGES_512/0A70547B.JPG\n",
      "0A70547B\n",
      "Boxes(tensor([[214.4653, 205.4697, 300.3220, 294.7097]], device='cuda:0'))\n",
      "IMAGES_512/7E235EAB.JPG\n",
      "7E235EAB\n",
      "Boxes(tensor([[161.9843, 183.1443, 321.4780, 312.7747]], device='cuda:0'))\n",
      "IMAGES_512/D4D078C2.JPG\n",
      "D4D078C2\n",
      "Boxes(tensor([[228.3140, 172.3320, 324.7770, 256.2974]], device='cuda:0'))\n",
      "IMAGES_512/5178E42F.JPG\n",
      "5178E42F\n",
      "Boxes(tensor([[304.3467, 187.3812, 423.7570, 270.0958]], device='cuda:0'))\n",
      "IMAGES_512/678A0DB3.JPG\n",
      "678A0DB3\n",
      "Boxes(tensor([[178.8560, 157.0938, 421.1437, 327.0760]], device='cuda:0'))\n",
      "IMAGES_512/888F7FF4.JPG\n",
      "888F7FF4\n",
      "Boxes(tensor([[243.3859, 189.8895, 341.4980, 353.9846]], device='cuda:0'))\n",
      "IMAGES_512/A64941A2.JPG\n",
      "A64941A2\n",
      "Boxes(tensor([[221.5291, 195.0070, 377.0613, 341.7751]], device='cuda:0'))\n",
      "IMAGES_512/A76651FA.JPG\n",
      "A76651FA\n",
      "Boxes(tensor([[244.0091, 108.1568, 305.5870, 168.9683]], device='cuda:0'))\n",
      "IMAGES_512/924C745C.JPG\n",
      "924C745C\n",
      "Boxes(tensor([[106.2252,  43.7986, 402.1616, 279.9990]], device='cuda:0'))\n",
      "IMAGES_512/1046578D.JPG\n",
      "1046578D\n",
      "Boxes(tensor([[199.8938,  75.0863, 429.1100, 304.2728]], device='cuda:0'))\n",
      "IMAGES_512/4333583F.JPG\n",
      "4333583F\n",
      "Boxes(tensor([[244.7475, 191.1201, 382.5997, 303.5883]], device='cuda:0'))\n",
      "IMAGES_512/471C0C9E.JPG\n",
      "471C0C9E\n",
      "Boxes(tensor([[249.1917, 218.1513, 319.1786, 273.2484],\n",
      "        [175.8897, 103.1502, 286.4728, 205.8252]], device='cuda:0'))\n",
      "IMAGES_512/66840CCC.JPG\n",
      "66840CCC\n",
      "Boxes(tensor([[192.1150, 189.8544, 363.1320, 337.3398]], device='cuda:0'))\n",
      "IMAGES_512/F3C3F00F.JPG\n",
      "F3C3F00F\n",
      "Boxes(tensor([[208.8930, 104.9521, 327.5615, 231.7512]], device='cuda:0'))\n",
      "IMAGES_512/967EE875.JPG\n",
      "967EE875\n",
      "Boxes(tensor([[235.0830, 177.4450, 375.9312, 317.4215]], device='cuda:0'))\n",
      "IMAGES_512/5F0AEB90.JPG\n",
      "5F0AEB90\n",
      "Boxes(tensor([[206.3390, 153.0996, 318.6737, 250.3869]], device='cuda:0'))\n",
      "IMAGES_512/5704648A.JPG\n",
      "5704648A\n",
      "Boxes(tensor([[303.5236, 150.8997, 389.5467, 292.3852]], device='cuda:0'))\n",
      "IMAGES_512/B42615F1.JPG\n",
      "B42615F1\n",
      "Boxes(tensor([[272.5896, 175.7957, 406.4824, 277.9724]], device='cuda:0'))\n",
      "IMAGES_512/3774E27D.JPG\n",
      "3774E27D\n",
      "Boxes(tensor([[267.1723, 245.2324, 369.9973, 355.1443],\n",
      "        [ 15.8208,  27.1731, 386.2269, 351.6571]], device='cuda:0'))\n",
      "IMAGES_512/BDAEA3E3.JPG\n",
      "BDAEA3E3\n",
      "Boxes(tensor([[281.5191, 202.8681, 391.1229, 370.6893],\n",
      "        [420.9571, 229.4918, 511.5046, 315.9757],\n",
      "        [132.9004, 209.2223, 269.5840, 320.2483]], device='cuda:0'))\n",
      "IMAGES_512/11C79B4A.JPG\n",
      "11C79B4A\n",
      "Boxes(tensor([[248.4698, 206.5889, 343.2738, 383.0564]], device='cuda:0'))\n",
      "IMAGES_512/2D51B43B.JPG\n",
      "2D51B43B\n",
      "Boxes(tensor([[247.1538, 118.5107, 294.7693, 197.1752],\n",
      "        [112.3842, 144.5564, 227.7740, 198.2529],\n",
      "        [246.8078, 119.0982, 293.9290, 276.6394]], device='cuda:0'))\n",
      "IMAGES_512/E20C6AC2.JPG\n",
      "E20C6AC2\n",
      "Boxes(tensor([[239.6525, 141.1473, 320.6018, 245.6679]], device='cuda:0'))\n",
      "IMAGES_512/DA9A91F5.JPG\n",
      "DA9A91F5\n",
      "Boxes(tensor([[288.7238, 166.0301, 370.6458, 246.7851]], device='cuda:0'))\n",
      "IMAGES_512/9912F421.JPG\n",
      "9912F421\n",
      "Boxes(tensor([[317.4467, 217.9977, 491.0921, 355.2755]], device='cuda:0'))\n",
      "IMAGES_512/B7B1560F.JPG\n",
      "B7B1560F\n",
      "Boxes(tensor([[210.0614, 171.2475, 373.9272, 289.0080]], device='cuda:0'))\n",
      "IMAGES_512/1F33F1F4.JPG\n",
      "1F33F1F4\n",
      "Boxes(tensor([[212.5959, 194.1427, 355.3783, 329.1965]], device='cuda:0'))\n",
      "IMAGES_512/C8082767.JPG\n",
      "C8082767\n",
      "Boxes(tensor([[206.5388, 108.2950, 316.9655, 189.7018]], device='cuda:0'))\n",
      "IMAGES_512/E22E3E61.JPG\n",
      "E22E3E61\n",
      "Boxes(tensor([[244.3270, 146.0133, 410.9656, 285.4230]], device='cuda:0'))\n",
      "IMAGES_512/97A43E31.JPG\n",
      "97A43E31\n",
      "Boxes(tensor([[251.4787, 182.1402, 345.9340, 338.8313],\n",
      "        [367.0601, 250.8617, 454.7887, 324.7710]], device='cuda:0'))\n",
      "IMAGES_512/0A9117FD.JPG\n",
      "0A9117FD\n",
      "Boxes(tensor([[165.6958, 120.5411, 352.5207, 315.9623]], device='cuda:0'))\n",
      "IMAGES_512/23D00BDD.JPG\n",
      "23D00BDD\n",
      "Boxes(tensor([[173.4318, 195.3192, 303.0615, 293.7146],\n",
      "        [372.6521, 315.1255, 509.8382, 383.6856]], device='cuda:0'))\n",
      "IMAGES_512/42C0786A.JPG\n",
      "42C0786A\n",
      "Boxes(tensor([[186.8687, 239.9966, 250.1474, 348.9120],\n",
      "        [  2.6169,  83.1544,  76.9629,  97.0939]], device='cuda:0'))\n",
      "IMAGES_512/16DC3EEC.JPG\n",
      "16DC3EEC\n",
      "Boxes(tensor([[201.7714, 167.3989, 402.4070, 286.2538]], device='cuda:0'))\n",
      "IMAGES_512/8445F765.JPG\n",
      "8445F765\n",
      "Boxes(tensor([[239.7695, 240.5824, 343.0317, 332.8027]], device='cuda:0'))\n",
      "IMAGES_512/5A63FD0E.JPG\n",
      "5A63FD0E\n",
      "Boxes(tensor([[226.9697, 242.7782, 387.2576, 367.9958]], device='cuda:0'))\n",
      "IMAGES_512/85AD507D.JPG\n",
      "85AD507D\n",
      "Boxes(tensor([[225.6994,  92.4804, 480.0548, 265.4637]], device='cuda:0'))\n",
      "IMAGES_512/E6B63467.JPG\n",
      "E6B63467\n",
      "Boxes(tensor([[261.3362, 223.2721, 328.2604, 335.3879]], device='cuda:0'))\n",
      "IMAGES_512/38F85274.JPG\n",
      "38F85274\n",
      "Boxes(tensor([[255.7975, 170.8486, 397.2730, 329.5337]], device='cuda:0'))\n",
      "IMAGES_512/791487A4.JPG\n",
      "791487A4\n",
      "Boxes(tensor([[108.2903,  85.7456, 265.3260, 232.0557]], device='cuda:0'))\n",
      "IMAGES_512/AF3652CD.JPG\n",
      "AF3652CD\n",
      "Boxes(tensor([[235.4080, 175.3102, 397.6511, 346.6637]], device='cuda:0'))\n",
      "IMAGES_512/3C8EEA70.JPG\n",
      "3C8EEA70\n",
      "Boxes(tensor([[191.7854, 173.3403, 354.7651, 365.7685]], device='cuda:0'))\n",
      "IMAGES_512/0B271797.JPG\n",
      "0B271797\n",
      "Boxes(tensor([[221.8773, 147.7294, 305.8490, 289.4326]], device='cuda:0'))\n",
      "IMAGES_512/A078B0EE.JPG\n",
      "A078B0EE\n",
      "Boxes(tensor([[180.6034, 206.7409, 283.5691, 295.2876]], device='cuda:0'))\n",
      "IMAGES_512/E830C326.JPG\n",
      "E830C326\n",
      "Boxes(tensor([[222.4067, 196.5453, 356.8270, 336.7542]], device='cuda:0'))\n",
      "IMAGES_512/51ACD6F6.JPG\n",
      "51ACD6F6\n",
      "Boxes(tensor([[195.2540, 155.4945, 392.3701, 285.3621]], device='cuda:0'))\n",
      "IMAGES_512/B92AE8B2.JPG\n",
      "B92AE8B2\n",
      "Boxes(tensor([[198.2499, 192.8866, 303.6037, 286.3973]], device='cuda:0'))\n",
      "IMAGES_512/CEB4E6A0.JPG\n",
      "CEB4E6A0\n",
      "Boxes(tensor([[208.1204, 197.9115, 340.7462, 318.6984]], device='cuda:0'))\n",
      "IMAGES_512/B195B030.JPG\n",
      "B195B030\n",
      "Boxes(tensor([[260.4954, 219.0982, 316.0310, 300.0778]], device='cuda:0'))\n",
      "IMAGES_512/0B2AD637.JPG\n",
      "0B2AD637\n",
      "Boxes(tensor([[231.6073, 129.1723, 367.5066, 240.0054],\n",
      "        [ 10.9449, 211.8265, 238.3157, 380.4913]], device='cuda:0'))\n",
      "IMAGES_512/57B39A9D.JPG\n",
      "57B39A9D\n",
      "Boxes(tensor([[188.6211, 196.4817, 277.2576, 273.3846]], device='cuda:0'))\n",
      "IMAGES_512/A91316FD.JPG\n",
      "A91316FD\n",
      "Boxes(tensor([[312.2103, 169.6312, 431.1157, 268.5520]], device='cuda:0'))\n",
      "IMAGES_512/0461F61E.JPG\n",
      "0461F61E\n",
      "Boxes(tensor([[237.2291, 235.3933, 321.0998, 383.8423]], device='cuda:0'))\n",
      "IMAGES_512/BFC0CE96.JPG\n",
      "BFC0CE96\n",
      "Boxes(tensor([[217.5358, 166.3248, 416.2893, 311.1725]], device='cuda:0'))\n",
      "IMAGES_512/BCD586EB.JPG\n",
      "BCD586EB\n",
      "Boxes(tensor([[254.7272, 214.1717, 340.9997, 311.6756],\n",
      "        [166.0162, 300.0620, 228.8826, 374.3941]], device='cuda:0'))\n",
      "IMAGES_512/827A3490.JPG\n",
      "827A3490\n",
      "Boxes(tensor([[306.9791, 199.1619, 460.4100, 338.5370]], device='cuda:0'))\n",
      "IMAGES_512/0BC8982B.JPG\n",
      "0BC8982B\n",
      "Boxes(tensor([[202.8543, 147.7475, 298.7871, 244.1017]], device='cuda:0'))\n",
      "IMAGES_512/187D768F.JPG\n",
      "187D768F\n",
      "Boxes(tensor([[ 85.5003, 187.0491, 198.4380, 372.9916]], device='cuda:0'))\n",
      "IMAGES_512/179373F3.JPG\n",
      "179373F3\n",
      "Boxes(tensor([[283.9683, 142.0090, 505.6018, 292.5627]], device='cuda:0'))\n",
      "IMAGES_512/FA59EEE2.JPG\n",
      "FA59EEE2\n",
      "Boxes(tensor([[206.8725, 204.1204, 317.4938, 331.2035]], device='cuda:0'))\n",
      "IMAGES_512/AF66193A.JPG\n",
      "AF66193A\n",
      "Boxes(tensor([[223.7923, 175.0829, 308.6023, 253.3214]], device='cuda:0'))\n",
      "IMAGES_512/64D802AD.JPG\n",
      "64D802AD\n",
      "Boxes(tensor([[219.3025, 201.3970, 328.3146, 315.3859],\n",
      "        [144.2523,  90.7911, 329.2886, 268.6797]], device='cuda:0'))\n",
      "IMAGES_512/B04A7438.JPG\n",
      "B04A7438\n",
      "Boxes(tensor([[277.4191, 188.9357, 381.9568, 278.9577]], device='cuda:0'))\n",
      "IMAGES_512/08C8E445.JPG\n",
      "08C8E445\n",
      "Boxes(tensor([[162.8415, 158.9826, 398.8589, 347.8660]], device='cuda:0'))\n",
      "IMAGES_512/7A4F060A.JPG\n",
      "7A4F060A\n",
      "Boxes(tensor([[312.0602, 170.5860, 512.0000, 348.7326]], device='cuda:0'))\n",
      "IMAGES_512/D0D55C30.JPG\n",
      "D0D55C30\n",
      "Boxes(tensor([[324.5540, 115.9307, 512.0000, 241.0714]], device='cuda:0'))\n",
      "IMAGES_512/9E148E59.JPG\n",
      "9E148E59\n",
      "Boxes(tensor([[217.2418, 195.8739, 331.3727, 371.8887],\n",
      "        [ 86.9128, 225.0895, 222.7884, 314.8560]], device='cuda:0'))\n",
      "IMAGES_512/162535E0.JPG\n",
      "162535E0\n",
      "Boxes(tensor([[197.6475, 144.4116, 339.5858, 320.8098]], device='cuda:0'))\n",
      "IMAGES_512/1C45EE64.JPG\n",
      "1C45EE64\n",
      "Boxes(tensor([[278.5431, 179.3835, 421.5527, 313.1697]], device='cuda:0'))\n",
      "IMAGES_512/DA6A2C27.JPG\n",
      "DA6A2C27\n",
      "Boxes(tensor([[171.0055, 136.1210, 447.2354, 350.5935]], device='cuda:0'))\n",
      "IMAGES_512/5EDC1E40.JPG\n",
      "5EDC1E40\n",
      "Boxes(tensor([[267.2617, 203.4259, 329.3255, 261.3379]], device='cuda:0'))\n",
      "IMAGES_512/8EE9A1F6.JPG\n",
      "8EE9A1F6\n",
      "Boxes(tensor([[239.8976, 147.6758, 399.7502, 287.2325]], device='cuda:0'))\n",
      "IMAGES_512/CD8765AE.JPG\n",
      "CD8765AE\n",
      "Boxes(tensor([[257.5606, 200.7088, 361.4830, 364.5115]], device='cuda:0'))\n",
      "IMAGES_512/1AE6A4CD.JPG\n",
      "1AE6A4CD\n",
      "Boxes(tensor([[257.3620, 216.0194, 406.7568, 327.1280]], device='cuda:0'))\n",
      "IMAGES_512/9431AB66.JPG\n",
      "9431AB66\n",
      "Boxes(tensor([[223.8304, 116.8739, 461.6038, 325.8292]], device='cuda:0'))\n",
      "IMAGES_512/A522801E.JPG\n",
      "A522801E\n",
      "Boxes(tensor([[189.5860, 179.5426, 340.8051, 318.8690]], device='cuda:0'))\n",
      "IMAGES_512/447B37DE.JPG\n",
      "447B37DE\n",
      "Boxes(tensor([[156.6976, 211.3983, 376.3612, 367.6528]], device='cuda:0'))\n",
      "IMAGES_512/5B7CBD42.JPG\n",
      "5B7CBD42\n",
      "Boxes(tensor([[240.6535, 212.4663, 302.7154, 266.7340]], device='cuda:0'))\n",
      "IMAGES_512/3400B7F4.JPG\n",
      "3400B7F4\n",
      "Boxes(tensor([[ 96.7830, 152.8980, 284.3198, 315.1425]], device='cuda:0'))\n",
      "IMAGES_512/C92B26AF.JPG\n",
      "C92B26AF\n",
      "Boxes(tensor([[187.2109, 162.9908, 365.5159, 310.2176]], device='cuda:0'))\n",
      "IMAGES_512/5C1BABE7.JPG\n",
      "5C1BABE7\n",
      "Boxes(tensor([[125.8968, 109.2535, 289.2869, 242.6147]], device='cuda:0'))\n",
      "IMAGES_512/736EDDD5.JPG\n",
      "736EDDD5\n",
      "Boxes(tensor([[242.4768, 266.4244, 395.3772, 382.6334]], device='cuda:0'))\n",
      "IMAGES_512/F094DA63.JPG\n",
      "F094DA63\n",
      "Boxes(tensor([[226.1648, 147.6868, 301.6509, 250.5520]], device='cuda:0'))\n",
      "IMAGES_512/D9295E38.JPG\n",
      "D9295E38\n",
      "Boxes(tensor([[241.4940, 128.4913, 292.1272, 207.9808]], device='cuda:0'))\n",
      "IMAGES_512/9EAD9589.JPG\n",
      "9EAD9589\n",
      "Boxes(tensor([[247.2361, 213.2797, 384.3638, 345.4601]], device='cuda:0'))\n",
      "IMAGES_512/71BA1685.JPG\n",
      "71BA1685\n",
      "Boxes(tensor([[217.2419, 113.2583, 407.0615, 236.5477],\n",
      "        [216.8435, 114.2264, 338.0842, 207.1131]], device='cuda:0'))\n",
      "IMAGES_512/7749880F.JPG\n",
      "7749880F\n",
      "Boxes(tensor([[244.1169, 242.5743, 366.5514, 370.6019]], device='cuda:0'))\n",
      "IMAGES_512/BEB6920C.JPG\n",
      "BEB6920C\n",
      "Boxes(tensor([[172.6061, 188.0684, 309.7262, 326.9691]], device='cuda:0'))\n",
      "IMAGES_512/A0B89ABF.JPG\n",
      "A0B89ABF\n",
      "Boxes(tensor([[105.7981, 137.0052, 324.0019, 301.9435],\n",
      "        [318.3825,  45.0779, 369.9086, 102.2457]], device='cuda:0'))\n",
      "IMAGES_512/3F66FC65.JPG\n",
      "3F66FC65\n",
      "Boxes(tensor([[226.8898, 213.2203, 414.5866, 334.1360]], device='cuda:0'))\n",
      "IMAGES_512/956688BC.JPG\n",
      "956688BC\n",
      "Boxes(tensor([[224.4841, 144.9258, 406.5810, 299.5688]], device='cuda:0'))\n",
      "IMAGES_512/15C8CD20.JPG\n",
      "15C8CD20\n",
      "Boxes(tensor([[197.9220, 263.5242, 371.1721, 379.3408],\n",
      "        [ 12.5169, 151.3178, 254.1340, 377.9372]], device='cuda:0'))\n",
      "IMAGES_512/6F99D028.JPG\n",
      "6F99D028\n",
      "Boxes(tensor([[167.7663,  26.7747, 375.6932, 199.8116]], device='cuda:0'))\n",
      "IMAGES_512/936419FC.JPG\n",
      "936419FC\n",
      "Boxes(tensor([[246.4431, 193.4043, 358.1512, 299.3906]], device='cuda:0'))\n",
      "IMAGES_512/57C8BA59.JPG\n",
      "57C8BA59\n",
      "Boxes(tensor([[186.4639, 140.0463, 419.5261, 363.2877]], device='cuda:0'))\n",
      "IMAGES_512/34832B98.JPG\n",
      "34832B98\n",
      "Boxes(tensor([[170.5827, 160.9582, 305.7393, 283.8169]], device='cuda:0'))\n",
      "IMAGES_512/F94F600C.JPG\n",
      "F94F600C\n",
      "Boxes(tensor([[118.8936, 116.7009, 296.6764, 258.7323]], device='cuda:0'))\n",
      "IMAGES_512/BA5CBF2B.JPG\n",
      "BA5CBF2B\n",
      "Boxes(tensor([[141.3740, 230.9779, 256.0603, 348.0859]], device='cuda:0'))\n",
      "IMAGES_512/7CEF5B3D.JPG\n",
      "7CEF5B3D\n",
      "Boxes(tensor([[172.1215, 125.7174, 304.8502, 234.2201]], device='cuda:0'))\n",
      "IMAGES_512/C5044605.JPG\n",
      "C5044605\n",
      "Boxes(tensor([[128.8940, 203.0550, 286.6206, 333.4204]], device='cuda:0'))\n",
      "IMAGES_512/4F61C9B6.JPG\n",
      "4F61C9B6\n",
      "Boxes(tensor([[233.0708,  98.8667, 308.2834, 199.6758]], device='cuda:0'))\n",
      "IMAGES_512/05B50F1A.JPG\n",
      "05B50F1A\n",
      "Boxes(tensor([[176.6913, 149.9710, 399.0497, 301.7353]], device='cuda:0'))\n",
      "IMAGES_512/AADE75CB.JPG\n",
      "AADE75CB\n",
      "Boxes(tensor([[194.3370, 156.6783, 338.4011, 273.0118],\n",
      "        [  0.0000, 168.6996, 177.8906, 341.7689]], device='cuda:0'))\n",
      "IMAGES_512/C6117E16.JPG\n",
      "C6117E16\n",
      "Boxes(tensor([[260.0085, 125.1544, 327.1711, 237.8820],\n",
      "        [ 29.4581,  84.5619, 179.6286, 202.1122]], device='cuda:0'))\n",
      "IMAGES_512/FFC41FD8.JPG\n",
      "FFC41FD8\n",
      "Boxes(tensor([[264.3384, 213.2653, 360.7379, 336.5836]], device='cuda:0'))\n",
      "IMAGES_512/E4EAC4AC.JPG\n",
      "E4EAC4AC\n",
      "Boxes(tensor([[202.2622, 173.1153, 283.2866, 239.2661]], device='cuda:0'))\n",
      "IMAGES_512/123D7BB3.JPG\n",
      "123D7BB3\n",
      "Boxes(tensor([[212.5997, 177.5976, 325.3036, 356.7753]], device='cuda:0'))\n",
      "IMAGES_512/AD30E9B2.JPG\n",
      "AD30E9B2\n",
      "Boxes(tensor([[213.4422, 210.9229, 326.5570, 360.1375]], device='cuda:0'))\n",
      "IMAGES_512/90861BD2.JPG\n",
      "90861BD2\n",
      "Boxes(tensor([[339.8991, 183.0001, 465.4298, 283.6651]], device='cuda:0'))\n",
      "IMAGES_512/9362F0D5.JPG\n",
      "9362F0D5\n",
      "Boxes(tensor([[ 76.5774, 129.7112, 249.6961, 238.2899]], device='cuda:0'))\n",
      "IMAGES_512/8AC80DF4.JPG\n",
      "8AC80DF4\n",
      "Boxes(tensor([[199.0317, 202.6275, 303.1054, 310.5042]], device='cuda:0'))\n",
      "IMAGES_512/6206899E.JPG\n",
      "6206899E\n",
      "Boxes(tensor([[123.9174, 203.6178, 279.7770, 323.6786],\n",
      "        [129.1467, 198.5712, 370.7959, 352.2658]], device='cuda:0'))\n",
      "IMAGES_512/C3A69832.JPG\n",
      "C3A69832\n",
      "Boxes(tensor([[194.1325, 191.5602, 299.9371, 360.7343]], device='cuda:0'))\n",
      "IMAGES_512/72DB0A23.JPG\n",
      "72DB0A23\n",
      "Boxes(tensor([[170.4233, 103.9909, 299.0673, 230.5841]], device='cuda:0'))\n",
      "IMAGES_512/6411A5CA.JPG\n",
      "6411A5CA\n",
      "Boxes(tensor([[222.2060, 166.9956, 432.3624, 312.0613]], device='cuda:0'))\n",
      "IMAGES_512/874669EC.JPG\n",
      "874669EC\n",
      "Boxes(tensor([[2.7271e+02, 1.3488e+02, 4.1796e+02, 2.5214e+02],\n",
      "        [1.6656e+02, 3.5586e-01, 3.0537e+02, 4.4945e+01]], device='cuda:0'))\n",
      "IMAGES_512/C1758763.JPG\n",
      "C1758763\n",
      "Boxes(tensor([[235.2666, 147.4039, 475.0361, 291.6165]], device='cuda:0'))\n",
      "IMAGES_512/2302940F.JPG\n",
      "2302940F\n",
      "Boxes(tensor([[300.6089, 134.4445, 359.2416, 179.5551]], device='cuda:0'))\n",
      "IMAGES_512/6DD8E3DE.JPG\n",
      "6DD8E3DE\n",
      "Boxes(tensor([[220.4177, 167.9990, 318.6589, 341.7535],\n",
      "        [ 87.2298, 128.8626, 188.4741, 238.9059],\n",
      "        [359.2375, 180.3670, 439.9240, 265.0861]], device='cuda:0'))\n",
      "IMAGES_512/293852ED.JPG\n",
      "293852ED\n",
      "Boxes(tensor([[117.2065, 180.4637, 311.5153, 326.2234]], device='cuda:0'))\n",
      "IMAGES_512/5DF01EA4.JPG\n",
      "5DF01EA4\n",
      "Boxes(tensor([[313.9771, 199.5074, 442.6664, 290.9324]], device='cuda:0'))\n",
      "IMAGES_512/B4D62501.JPG\n",
      "B4D62501\n",
      "Boxes(tensor([[205.2614, 182.3186, 318.7336, 299.1798]], device='cuda:0'))\n",
      "IMAGES_512/834A7A1C.JPG\n",
      "834A7A1C\n",
      "Boxes(tensor([[223.6184, 145.4905, 302.2963, 222.2659]], device='cuda:0'))\n",
      "IMAGES_512/7D4EEEC0.JPG\n",
      "7D4EEEC0\n",
      "Boxes(tensor([[161.8357,  72.1856, 343.7349, 203.4289]], device='cuda:0'))\n",
      "IMAGES_512/95811221.JPG\n",
      "95811221\n",
      "Boxes(tensor([[238.5708, 157.2103, 315.3627, 284.1858]], device='cuda:0'))\n",
      "IMAGES_512/E918FEAF.JPG\n",
      "E918FEAF\n",
      "Boxes(tensor([[234.3217, 132.3223, 287.4283, 186.3407]], device='cuda:0'))\n",
      "IMAGES_512/2B9EE9A5.JPG\n",
      "2B9EE9A5\n",
      "Boxes(tensor([[248.0940, 174.9807, 454.3360, 328.5780]], device='cuda:0'))\n",
      "IMAGES_512/DBCFF711.JPG\n",
      "DBCFF711\n",
      "Boxes(tensor([[242.4979, 166.1994, 364.0480, 268.5677]], device='cuda:0'))\n",
      "IMAGES_512/558036F6.JPG\n",
      "558036F6\n",
      "Boxes(tensor([[206.0336,  91.1871, 498.7674, 362.5889]], device='cuda:0'))\n",
      "IMAGES_512/6C81604C.JPG\n",
      "6C81604C\n",
      "Boxes(tensor([[223.3384, 157.8406, 295.4277, 280.9104],\n",
      "        [102.1479, 134.9994, 193.8844, 236.2431]], device='cuda:0'))\n",
      "IMAGES_512/745B68A6.JPG\n",
      "745B68A6\n",
      "Boxes(tensor([[145.4150, 125.4863, 285.6902, 333.7031]], device='cuda:0'))\n",
      "IMAGES_512/1EE3CEAB.JPG\n",
      "1EE3CEAB\n",
      "Boxes(tensor([[204.7691, 191.5681, 289.1056, 272.3399]], device='cuda:0'))\n",
      "IMAGES_512/E4E50C49.JPG\n",
      "E4E50C49\n",
      "Boxes(tensor([[245.4470, 164.6194, 291.6006, 233.2341]], device='cuda:0'))\n",
      "IMAGES_512/979BA305.JPG\n",
      "979BA305\n",
      "Boxes(tensor([[205.9305, 250.6225, 313.7814, 372.8964],\n",
      "        [ 58.1459, 229.8311, 198.5757, 328.4146]], device='cuda:0'))\n",
      "IMAGES_512/5A374E30.JPG\n",
      "5A374E30\n",
      "Boxes(tensor([[215.8547, 201.0446, 395.1456, 318.1107]], device='cuda:0'))\n",
      "IMAGES_512/454D6DD3.JPG\n",
      "454D6DD3\n",
      "Boxes(tensor([[180.7012, 167.2896, 280.3058, 352.0869]], device='cuda:0'))\n",
      "IMAGES_512/DE5F432E.JPG\n",
      "DE5F432E\n",
      "Boxes(tensor([[205.7214, 242.0240, 320.7999, 381.6448]], device='cuda:0'))\n",
      "IMAGES_512/0641B435.JPG\n",
      "0641B435\n",
      "Boxes(tensor([[210.6309, 209.0679, 346.7235, 335.3477]], device='cuda:0'))\n",
      "IMAGES_512/2F89E39A.JPG\n",
      "2F89E39A\n",
      "Boxes(tensor([[159.0897, 281.4741, 266.5826, 358.7462]], device='cuda:0'))\n",
      "IMAGES_512/9C384598.JPG\n",
      "9C384598\n",
      "Boxes(tensor([[162.2517, 163.9945, 352.0261, 359.2907]], device='cuda:0'))\n",
      "IMAGES_512/C9428B86.JPG\n",
      "C9428B86\n",
      "Boxes(tensor([[199.8563, 168.6541, 371.5427, 298.5703]], device='cuda:0'))\n",
      "IMAGES_512/2C31F3A0.JPG\n",
      "2C31F3A0\n",
      "Boxes(tensor([[223.2784, 157.7546, 283.2107, 219.9240],\n",
      "        [  0.4156,   9.0928, 230.5998, 331.2661]], device='cuda:0'))\n",
      "IMAGES_512/ED90878F.JPG\n",
      "ED90878F\n",
      "Boxes(tensor([[210.4397, 246.9392, 317.8410, 351.9220]], device='cuda:0'))\n",
      "IMAGES_512/A79140B3.JPG\n",
      "A79140B3\n",
      "Boxes(tensor([[169.9130, 201.8987, 327.7251, 320.2429]], device='cuda:0'))\n",
      "IMAGES_512/5430597D.JPG\n",
      "5430597D\n",
      "Boxes(tensor([[ 57.1675, 156.6273, 246.7805, 321.0339]], device='cuda:0'))\n",
      "IMAGES_512/BC1B525D.JPG\n",
      "BC1B525D\n",
      "Boxes(tensor([[166.0098, 154.7160, 289.3578, 250.9529]], device='cuda:0'))\n",
      "IMAGES_512/BB77572A.JPG\n",
      "BB77572A\n",
      "Boxes(tensor([[232.1715, 225.5409, 353.1601, 370.4766]], device='cuda:0'))\n",
      "IMAGES_512/51BCE471.JPG\n",
      "51BCE471\n",
      "Boxes(tensor([[202.3948, 127.7182, 318.0760, 234.0007]], device='cuda:0'))\n",
      "IMAGES_512/3D6EC5C8.JPG\n",
      "3D6EC5C8\n",
      "Boxes(tensor([[188.9942, 209.1847, 337.3631, 326.0428]], device='cuda:0'))\n",
      "IMAGES_512/92D823B0.JPG\n",
      "92D823B0\n",
      "Boxes(tensor([[217.2686, 172.8582, 343.4739, 256.1283]], device='cuda:0'))\n",
      "IMAGES_512/205A9067.JPG\n",
      "205A9067\n",
      "Boxes(tensor([[192.2146, 199.5523, 366.2897, 332.8686]], device='cuda:0'))\n",
      "IMAGES_512/37F652AE.JPG\n",
      "37F652AE\n",
      "Boxes(tensor([[227.8719, 169.2854, 289.4987, 245.6141]], device='cuda:0'))\n",
      "IMAGES_512/21CF1373.JPG\n",
      "21CF1373\n",
      "Boxes(tensor([[256.8533, 154.0073, 412.3692, 302.9659]], device='cuda:0'))\n",
      "IMAGES_512/65436876.JPG\n",
      "65436876\n",
      "Boxes(tensor([[223.1453, 158.9917, 334.6315, 282.0859]], device='cuda:0'))\n",
      "IMAGES_512/84F86E8C.JPG\n",
      "84F86E8C\n",
      "Boxes(tensor([[192.8548, 112.1790, 357.1139, 251.7108]], device='cuda:0'))\n",
      "IMAGES_512/78D30FDD.JPG\n",
      "78D30FDD\n",
      "Boxes(tensor([[261.3188, 226.9868, 390.9405, 383.1308]], device='cuda:0'))\n",
      "IMAGES_512/F43CA434.JPG\n",
      "F43CA434\n",
      "Boxes(tensor([[118.2210, 192.8770, 307.0003, 335.5153],\n",
      "        [  1.4157, 239.3695,  97.7020, 371.9651]], device='cuda:0'))\n",
      "IMAGES_512/B2EDC52B.JPG\n",
      "B2EDC52B\n",
      "Boxes(tensor([[182.4621, 172.0099, 394.2506, 331.7565]], device='cuda:0'))\n",
      "IMAGES_512/044AA7A8.JPG\n",
      "044AA7A8\n",
      "Boxes(tensor([[213.0738, 232.1868, 331.0336, 374.5332]], device='cuda:0'))\n",
      "IMAGES_512/FF06175B.JPG\n",
      "FF06175B\n",
      "Boxes(tensor([[267.2644, 185.7032, 350.2894, 331.8660]], device='cuda:0'))\n",
      "IMAGES_512/05EDF063.JPG\n",
      "05EDF063\n",
      "Boxes(tensor([[250.3126, 191.2233, 325.3386, 312.7425],\n",
      "        [333.1994, 174.7958, 432.6472, 254.8511]], device='cuda:0'))\n",
      "IMAGES_512/4D8262AC.JPG\n",
      "4D8262AC\n",
      "Boxes(tensor([[231.2919, 177.1891, 354.0883, 307.4822]], device='cuda:0'))\n",
      "IMAGES_512/8D3AD910.JPG\n",
      "8D3AD910\n",
      "Boxes(tensor([[128.8617, 192.2155, 303.4124, 321.0442]], device='cuda:0'))\n",
      "IMAGES_512/07E10706.JPG\n",
      "07E10706\n",
      "Boxes(tensor([[135.0204, 208.6033, 321.9574, 362.7346]], device='cuda:0'))\n",
      "IMAGES_512/D883CF8F.JPG\n",
      "D883CF8F\n",
      "Boxes(tensor([[259.8205, 177.1539, 402.2222, 316.0992]], device='cuda:0'))\n",
      "IMAGES_512/2D392742.JPG\n",
      "2D392742\n",
      "Boxes(tensor([[284.0430, 185.2871, 375.0684, 323.5637]], device='cuda:0'))\n",
      "IMAGES_512/5BE831AD.JPG\n",
      "5BE831AD\n",
      "Boxes(tensor([[230.7853, 212.6379, 310.5689, 339.8264]], device='cuda:0'))\n",
      "IMAGES_512/530BD155.JPG\n",
      "530BD155\n",
      "Boxes(tensor([[221.3842,  94.0365, 407.1242, 269.9395]], device='cuda:0'))\n",
      "IMAGES_512/7077D642.JPG\n",
      "7077D642\n",
      "Boxes(tensor([[233.0058, 175.6587, 293.3216, 239.1726]], device='cuda:0'))\n",
      "IMAGES_512/918E18F8.JPG\n",
      "918E18F8\n",
      "Boxes(tensor([[288.9575, 167.0457, 388.9166, 305.1569]], device='cuda:0'))\n",
      "IMAGES_512/C34BE0FD.JPG\n",
      "C34BE0FD\n",
      "Boxes(tensor([[153.6220, 135.9151, 334.7039, 318.5825]], device='cuda:0'))\n",
      "IMAGES_512/05116E1E.JPG\n",
      "05116E1E\n",
      "Boxes(tensor([[286.2437, 206.2654, 391.6629, 326.6177]], device='cuda:0'))\n",
      "IMAGES_512/7DC2F3DE.JPG\n",
      "7DC2F3DE\n",
      "Boxes(tensor([[238.3280, 136.1224, 296.4899, 234.2293]], device='cuda:0'))\n",
      "IMAGES_512/10CA4D5F.JPG\n",
      "10CA4D5F\n",
      "Boxes(tensor([[192.2113, 183.8751, 430.1324, 342.5875]], device='cuda:0'))\n",
      "IMAGES_512/E8741DDA.JPG\n",
      "E8741DDA\n",
      "Boxes(tensor([[294.9150, 160.2173, 463.1740, 310.8665]], device='cuda:0'))\n",
      "IMAGES_512/F23479AC.JPG\n",
      "F23479AC\n",
      "Boxes(tensor([[152.6838, 134.1007, 306.2146, 281.0355]], device='cuda:0'))\n",
      "IMAGES_512/931CE08C.JPG\n",
      "931CE08C\n",
      "Boxes(tensor([[181.0072, 224.8581, 315.7409, 368.7639]], device='cuda:0'))\n",
      "IMAGES_512/A15F1C40.JPG\n",
      "A15F1C40\n",
      "Boxes(tensor([[198.3768, 168.7637, 274.5062, 281.6379]], device='cuda:0'))\n",
      "IMAGES_512/5BBABE3D.JPG\n",
      "5BBABE3D\n",
      "Boxes(tensor([[212.8313, 105.4650, 434.3584, 270.1957]], device='cuda:0'))\n",
      "IMAGES_512/BCAEE9AD.JPG\n",
      "BCAEE9AD\n",
      "Boxes(tensor([[216.7576, 146.1206, 374.8771, 296.9771]], device='cuda:0'))\n",
      "IMAGES_512/60E1C18A.JPG\n",
      "60E1C18A\n",
      "Boxes(tensor([[260.9716, 144.8576, 331.8963, 223.9822]], device='cuda:0'))\n",
      "IMAGES_512/E13AD7D3.JPG\n",
      "E13AD7D3\n",
      "Boxes(tensor([[ 33.8173, 114.4936, 208.3989, 277.9983]], device='cuda:0'))\n",
      "IMAGES_512/407D6F70.JPG\n",
      "407D6F70\n",
      "Boxes(tensor([[234.2444, 161.6352, 302.6253, 215.4577]], device='cuda:0'))\n",
      "IMAGES_512/3DDC169F.JPG\n",
      "3DDC169F\n",
      "Boxes(tensor([[218.1185, 164.4913, 323.3859, 353.4571]], device='cuda:0'))\n",
      "IMAGES_512/36FB049C.JPG\n",
      "36FB049C\n",
      "Boxes(tensor([[212.4729, 111.2179, 389.7564, 242.5766],\n",
      "        [ 91.6044, 239.4449, 177.2707, 284.3447],\n",
      "        [364.5175,   1.3601, 433.5327,  45.0311]], device='cuda:0'))\n",
      "IMAGES_512/978381D9.JPG\n",
      "978381D9\n",
      "Boxes(tensor([[221.1403, 151.2132, 396.4993, 317.9404],\n",
      "        [391.5483, 260.3588, 511.8043, 382.7767]], device='cuda:0'))\n",
      "IMAGES_512/B3722282.JPG\n",
      "B3722282\n",
      "Boxes(tensor([[165.7031, 232.3602, 303.0298, 334.9270]], device='cuda:0'))\n",
      "IMAGES_512/94DD5337.JPG\n",
      "94DD5337\n",
      "Boxes(tensor([[193.0202, 233.7650, 314.2260, 376.0043]], device='cuda:0'))\n",
      "IMAGES_512/A759F482.JPG\n",
      "A759F482\n",
      "Boxes(tensor([[185.2417, 165.1923, 305.5540, 333.4807]], device='cuda:0'))\n",
      "IMAGES_512/CD3D98E5.JPG\n",
      "CD3D98E5\n",
      "Boxes(tensor([[269.9212, 193.7477, 322.9826, 275.1774]], device='cuda:0'))\n",
      "IMAGES_512/608BE568.JPG\n",
      "608BE568\n",
      "Boxes(tensor([[290.2957, 180.8013, 353.3028, 251.7818]], device='cuda:0'))\n",
      "IMAGES_512/BF73D855.JPG\n",
      "BF73D855\n",
      "Boxes(tensor([[231.2974, 240.7690, 352.4553, 334.7902]], device='cuda:0'))\n",
      "IMAGES_512/230DFF08.JPG\n",
      "230DFF08\n",
      "Boxes(tensor([[212.2260, 183.1513, 388.4852, 353.4475]], device='cuda:0'))\n",
      "IMAGES_512/11A03506.JPG\n",
      "11A03506\n",
      "Boxes(tensor([[249.8833, 203.6574, 291.6542, 269.0134]], device='cuda:0'))\n",
      "IMAGES_512/38B678B7.JPG\n",
      "38B678B7\n",
      "Boxes(tensor([[236.1402, 213.8440, 306.7150, 274.3763]], device='cuda:0'))\n",
      "IMAGES_512/6226584D.JPG\n",
      "6226584D\n",
      "Boxes(tensor([[159.5006, 150.5105, 300.6809, 302.3913],\n",
      "        [242.2193,  51.5006, 505.9950, 240.3306]], device='cuda:0'))\n",
      "IMAGES_512/0FB88B75.JPG\n",
      "0FB88B75\n",
      "Boxes(tensor([[254.2310, 187.5282, 340.1273, 345.5979]], device='cuda:0'))\n",
      "IMAGES_512/B5D8DCD7.JPG\n",
      "B5D8DCD7\n",
      "Boxes(tensor([[249.7579, 189.1178, 405.0240, 313.1513]], device='cuda:0'))\n",
      "IMAGES_512/9CC29F3D.JPG\n",
      "9CC29F3D\n",
      "Boxes(tensor([[239.2490, 219.8139, 323.4059, 288.1578],\n",
      "        [ 25.6860, 150.5055, 129.7907, 179.3796]], device='cuda:0'))\n",
      "IMAGES_512/BF8CEA13.JPG\n",
      "BF8CEA13\n",
      "Boxes(tensor([[191.4649,  91.9387, 358.8146, 252.5585],\n",
      "        [  6.7224, 239.5724, 209.2274, 381.5751]], device='cuda:0'))\n",
      "IMAGES_512/1EE895CC.JPG\n",
      "1EE895CC\n",
      "Boxes(tensor([[220.3864, 170.5820, 368.4879, 275.5651]], device='cuda:0'))\n",
      "IMAGES_512/9F5045D2.JPG\n",
      "9F5045D2\n",
      "Boxes(tensor([[219.8444, 112.5195, 416.5649, 264.3768]], device='cuda:0'))\n",
      "IMAGES_512/60DDF5E7.JPG\n",
      "60DDF5E7\n",
      "Boxes(tensor([[250.8525, 198.6609, 400.8217, 302.6859],\n",
      "        [409.6323, 269.5594, 507.0652, 383.6450]], device='cuda:0'))\n",
      "IMAGES_512/75A6B048.JPG\n",
      "75A6B048\n",
      "Boxes(tensor([[172.0845, 148.6053, 317.2296, 255.8289]], device='cuda:0'))\n",
      "IMAGES_512/888EA9B7.JPG\n",
      "888EA9B7\n",
      "Boxes(tensor([[206.6664, 161.0253, 414.4406, 376.2944]], device='cuda:0'))\n",
      "IMAGES_512/D3160900.JPG\n",
      "D3160900\n",
      "Boxes(tensor([[246.3129, 194.4995, 341.1846, 320.9785]], device='cuda:0'))\n",
      "IMAGES_512/EED5D90B.JPG\n",
      "EED5D90B\n",
      "Boxes(tensor([[236.0734, 194.9894, 312.9262, 323.6871]], device='cuda:0'))\n",
      "IMAGES_512/A0D50B82.JPG\n",
      "A0D50B82\n",
      "Boxes(tensor([[170.2261, 155.1237, 291.4977, 256.5664]], device='cuda:0'))\n",
      "IMAGES_512/79C96F22.JPG\n",
      "79C96F22\n",
      "Boxes(tensor([[269.7303, 181.4827, 367.2852, 276.3522]], device='cuda:0'))\n",
      "IMAGES_512/1CECDB07.JPG\n",
      "1CECDB07\n",
      "Boxes(tensor([[230.9608, 190.3643, 330.0543, 349.4302],\n",
      "        [192.2641, 169.3243, 245.9134, 259.9445]], device='cuda:0'))\n",
      "IMAGES_512/E8F06072.JPG\n",
      "E8F06072\n",
      "Boxes(tensor([[160.3425, 196.3554, 316.2867, 322.6244]], device='cuda:0'))\n",
      "IMAGES_512/DCE306BC.JPG\n",
      "DCE306BC\n",
      "Boxes(tensor([[208.2542, 190.0890, 337.4534, 310.5636]], device='cuda:0'))\n",
      "IMAGES_512/97EB229A.JPG\n",
      "97EB229A\n",
      "Boxes(tensor([[230.9384, 145.3275, 383.6925, 256.5375],\n",
      "        [221.6776, 285.2310, 255.4947, 349.9536]], device='cuda:0'))\n",
      "IMAGES_512/2984C3D4.JPG\n",
      "2984C3D4\n",
      "Boxes(tensor([[274.9874, 100.8899, 416.2968, 251.7936]], device='cuda:0'))\n",
      "IMAGES_512/776FB83F.JPG\n",
      "776FB83F\n",
      "Boxes(tensor([[256.2346, 218.5571, 329.2003, 333.4578]], device='cuda:0'))\n",
      "IMAGES_512/A869E15C.JPG\n",
      "A869E15C\n",
      "Boxes(tensor([[248.7565, 120.2443, 348.6092, 218.7491]], device='cuda:0'))\n",
      "IMAGES_512/73B0AFC4.JPG\n",
      "73B0AFC4\n",
      "Boxes(tensor([[206.8418, 152.0465, 336.8896, 261.8712]], device='cuda:0'))\n",
      "IMAGES_512/24EF6BA7.JPG\n",
      "24EF6BA7\n",
      "Boxes(tensor([[242.3233, 190.7353, 442.4644, 313.4416]], device='cuda:0'))\n",
      "IMAGES_512/0375AA8B.JPG\n",
      "0375AA8B\n",
      "Boxes(tensor([[219.8818, 168.1888, 408.0325, 320.3036]], device='cuda:0'))\n",
      "IMAGES_512/990A5D79.JPG\n",
      "990A5D79\n",
      "Boxes(tensor([[228.9415, 216.7448, 303.2752, 334.3222],\n",
      "        [336.2529, 185.2116, 400.5913, 240.0975]], device='cuda:0'))\n",
      "IMAGES_512/891C022B.JPG\n",
      "891C022B\n",
      "Boxes(tensor([[126.8372,  65.1020, 338.2025, 271.9407]], device='cuda:0'))\n",
      "IMAGES_512/2DE9B5C0.JPG\n",
      "2DE9B5C0\n",
      "Boxes(tensor([[139.2322, 210.5110, 326.8617, 346.8890]], device='cuda:0'))\n",
      "IMAGES_512/B8286860.JPG\n",
      "B8286860\n",
      "Boxes(tensor([[245.0159, 162.8250, 311.4530, 264.4634]], device='cuda:0'))\n",
      "IMAGES_512/C9465B00.JPG\n",
      "C9465B00\n",
      "Boxes(tensor([[219.1431, 152.3537, 438.5979, 295.4000]], device='cuda:0'))\n",
      "IMAGES_512/1D07E530.JPG\n",
      "1D07E530\n",
      "Boxes(tensor([[234.2780, 124.7383, 327.8772, 281.8262],\n",
      "        [371.5520, 107.4876, 435.3875, 182.3428]], device='cuda:0'))\n",
      "IMAGES_512/EDF475A4.JPG\n",
      "EDF475A4\n",
      "Boxes(tensor([[232.2111, 162.5616, 359.0718, 319.1459]], device='cuda:0'))\n",
      "IMAGES_512/F441D31B.JPG\n",
      "F441D31B\n",
      "Boxes(tensor([[241.5928,  92.5805, 381.9644, 194.9011],\n",
      "        [365.0879, 179.2964, 447.7887, 218.3768]], device='cuda:0'))\n",
      "IMAGES_512/D4C43A12.JPG\n",
      "D4C43A12\n",
      "Boxes(tensor([[295.7365, 229.1904, 431.8893, 354.5551]], device='cuda:0'))\n",
      "IMAGES_512/81CE26B9.JPG\n",
      "81CE26B9\n",
      "Boxes(tensor([[189.8728, 182.1506, 327.8223, 309.9438]], device='cuda:0'))\n",
      "IMAGES_512/7C1D57EB.JPG\n",
      "7C1D57EB\n",
      "Boxes(tensor([[250.3605, 170.7324, 315.3746, 280.6909]], device='cuda:0'))\n",
      "IMAGES_512/8EFEF842.JPG\n",
      "8EFEF842\n",
      "Boxes(tensor([[ 92.1157,  15.2823, 362.2889, 204.3478]], device='cuda:0'))\n",
      "IMAGES_512/D571026D.JPG\n",
      "D571026D\n",
      "Boxes(tensor([[236.4247, 211.1605, 456.0604, 366.7167]], device='cuda:0'))\n",
      "IMAGES_512/AC942E95.JPG\n",
      "AC942E95\n",
      "Boxes(tensor([[202.0258, 169.5312, 304.6622, 274.9358]], device='cuda:0'))\n",
      "IMAGES_512/7B78E337.JPG\n",
      "7B78E337\n",
      "Boxes(tensor([[168.0038, 166.0131, 324.7252, 314.2094]], device='cuda:0'))\n",
      "IMAGES_512/C6D07BF2.JPG\n",
      "C6D07BF2\n",
      "Boxes(tensor([[240.8630, 134.3046, 288.0405, 189.0363]], device='cuda:0'))\n",
      "IMAGES_512/458D398C.JPG\n",
      "458D398C\n",
      "Boxes(tensor([[228.0587, 208.8071, 384.5580, 333.3989]], device='cuda:0'))\n",
      "IMAGES_512/75BA5A4B.JPG\n",
      "75BA5A4B\n",
      "Boxes(tensor([[203.1359, 213.7876, 299.3423, 378.2437]], device='cuda:0'))\n",
      "IMAGES_512/92CDC2FD.JPG\n",
      "92CDC2FD\n",
      "Boxes(tensor([[141.4285, 185.9975, 294.4881, 291.5783]], device='cuda:0'))\n",
      "IMAGES_512/933ED341.JPG\n",
      "933ED341\n",
      "Boxes(tensor([[235.9270, 142.8625, 327.6109, 209.6683]], device='cuda:0'))\n",
      "IMAGES_512/A3EEE0EB.JPG\n",
      "A3EEE0EB\n",
      "Boxes(tensor([[250.8169, 195.7146, 328.4324, 327.6912]], device='cuda:0'))\n",
      "IMAGES_512/7AAB9CCC.JPG\n",
      "7AAB9CCC\n",
      "Boxes(tensor([[170.3691, 115.0359, 281.4142, 250.5082]], device='cuda:0'))\n",
      "IMAGES_512/3062CEB7.JPG\n",
      "3062CEB7\n",
      "Boxes(tensor([[237.6110, 165.5399, 356.5594, 271.6161]], device='cuda:0'))\n",
      "IMAGES_512/200F27AC.JPG\n",
      "200F27AC\n",
      "Boxes(tensor([[187.7977, 237.4011, 265.4407, 331.6005]], device='cuda:0'))\n",
      "IMAGES_512/3F0C134C.JPG\n",
      "3F0C134C\n",
      "Boxes(tensor([[ 93.8815, 118.4187, 380.5844, 326.9150]], device='cuda:0'))\n",
      "IMAGES_512/05C3B07A.JPG\n",
      "05C3B07A\n",
      "Boxes(tensor([[210.7537, 114.5371, 375.1140, 326.6169]], device='cuda:0'))\n",
      "IMAGES_512/15B0C9BA.JPG\n",
      "15B0C9BA\n",
      "Boxes(tensor([[167.8217, 180.7690, 348.0238, 335.7859]], device='cuda:0'))\n",
      "IMAGES_512/223C3F4D.JPG\n",
      "223C3F4D\n",
      "Boxes(tensor([[ 52.7006, 147.1429, 243.5528, 340.9299]], device='cuda:0'))\n",
      "IMAGES_512/DEC0B907.JPG\n",
      "DEC0B907\n",
      "Boxes(tensor([[212.8711, 184.7515, 282.2332, 254.8824]], device='cuda:0'))\n",
      "IMAGES_512/8F2EBF0F.JPG\n",
      "8F2EBF0F\n",
      "Boxes(tensor([[219.8042,  94.5492, 320.5547, 191.6397]], device='cuda:0'))\n",
      "IMAGES_512/331BB897.JPG\n",
      "331BB897\n",
      "Boxes(tensor([[183.7437, 228.2769, 311.8010, 360.0087],\n",
      "        [ 21.7447, 271.0342,  76.5691, 295.8762]], device='cuda:0'))\n",
      "IMAGES_512/BACF93EE.JPG\n",
      "BACF93EE\n",
      "Boxes(tensor([[328.1278, 227.0753, 469.2130, 381.5391],\n",
      "        [283.7743, 267.9540, 333.1097, 340.8719]], device='cuda:0'))\n",
      "IMAGES_512/9FA6CAED.JPG\n",
      "9FA6CAED\n",
      "Boxes(tensor([[339.6651, 151.7039, 450.7027, 273.3902]], device='cuda:0'))\n",
      "IMAGES_512/5E145AC9.JPG\n",
      "5E145AC9\n",
      "Boxes(tensor([[190.2166, 106.5187, 496.4663, 328.0073]], device='cuda:0'))\n",
      "IMAGES_512/9C56AC8C.JPG\n",
      "9C56AC8C\n",
      "Boxes(tensor([[281.4262, 115.9468, 506.4344, 284.7670]], device='cuda:0'))\n",
      "IMAGES_512/EDECAB6E.JPG\n",
      "EDECAB6E\n",
      "Boxes(tensor([[239.4180, 234.0991, 311.8768, 367.9000]], device='cuda:0'))\n",
      "IMAGES_512/82CB3E3A.JPG\n",
      "82CB3E3A\n",
      "Boxes(tensor([[178.6896, 192.1645, 301.7033, 281.5198]], device='cuda:0'))\n",
      "IMAGES_512/06F4BC11.JPG\n",
      "06F4BC11\n",
      "Boxes(tensor([[186.6889, 203.6588, 350.3129, 348.5859]], device='cuda:0'))\n",
      "IMAGES_512/B2485703.JPG\n",
      "B2485703\n",
      "Boxes(tensor([[198.6321, 221.5226, 391.8599, 353.2788]], device='cuda:0'))\n",
      "IMAGES_512/F8B885AF.JPG\n",
      "F8B885AF\n",
      "Boxes(tensor([[242.0092, 198.1647, 338.6183, 361.6425],\n",
      "        [120.5831, 159.7815, 227.4032, 236.2250]], device='cuda:0'))\n",
      "IMAGES_512/08E665D7.JPG\n",
      "08E665D7\n",
      "Boxes(tensor([[204.7067, 174.1109, 320.9007, 351.9702]], device='cuda:0'))\n",
      "IMAGES_512/C11E4C2E.JPG\n",
      "C11E4C2E\n",
      "Boxes(tensor([[226.9955, 212.4424, 327.4409, 370.8025]], device='cuda:0'))\n",
      "IMAGES_512/131A387A.JPG\n",
      "131A387A\n",
      "Boxes(tensor([[209.1822, 223.8430, 287.5872, 346.5619]], device='cuda:0'))\n",
      "IMAGES_512/3C503B27.JPG\n",
      "3C503B27\n",
      "Boxes(tensor([[176.1975, 139.9717, 288.7177, 227.9704]], device='cuda:0'))\n",
      "IMAGES_512/D4AB371E.JPG\n",
      "D4AB371E\n",
      "Boxes(tensor([[255.8931, 215.4061, 323.7383, 290.4016]], device='cuda:0'))\n",
      "IMAGES_512/520D44D7.JPG\n",
      "520D44D7\n",
      "Boxes(tensor([[193.5940, 187.9185, 306.8618, 291.7864]], device='cuda:0'))\n",
      "IMAGES_512/933F859F.JPG\n",
      "933F859F\n",
      "Boxes(tensor([[189.7357, 118.2737, 357.5207, 311.0128]], device='cuda:0'))\n",
      "IMAGES_512/5DC3C252.JPG\n",
      "5DC3C252\n",
      "Boxes(tensor([[219.9485, 198.5054, 381.5982, 321.5226]], device='cuda:0'))\n",
      "IMAGES_512/0698DA77.JPG\n",
      "0698DA77\n",
      "Boxes(tensor([[212.5612, 200.8461, 298.0510, 340.4981]], device='cuda:0'))\n",
      "IMAGES_512/BD3273BF.JPG\n",
      "BD3273BF\n",
      "Boxes(tensor([[145.7523, 139.8914, 359.0511, 301.2081]], device='cuda:0'))\n",
      "IMAGES_512/927C6013.JPG\n",
      "927C6013\n",
      "Boxes(tensor([[167.4823, 117.4309, 309.9094, 233.7886]], device='cuda:0'))\n",
      "IMAGES_512/FD8C7552.JPG\n",
      "FD8C7552\n",
      "Boxes(tensor([[202.7545, 245.6807, 283.4587, 381.8014]], device='cuda:0'))\n",
      "IMAGES_512/DF755BD7.JPG\n",
      "DF755BD7\n",
      "Boxes(tensor([[170.0681,  27.3667, 371.2515, 177.5291]], device='cuda:0'))\n",
      "IMAGES_512/57DEA6A5.JPG\n",
      "57DEA6A5\n",
      "Boxes(tensor([[155.9134, 158.1712, 296.4280, 271.3590]], device='cuda:0'))\n",
      "IMAGES_512/83B8F99D.JPG\n",
      "83B8F99D\n",
      "Boxes(tensor([[218.1353, 119.3939, 358.9811, 234.0695]], device='cuda:0'))\n",
      "IMAGES_512/901976FF.JPG\n",
      "901976FF\n",
      "Boxes(tensor([[116.5026, 152.8193, 339.6251, 303.1465]], device='cuda:0'))\n",
      "IMAGES_512/A41F9BDB.JPG\n",
      "A41F9BDB\n",
      "Boxes(tensor([[210.1457, 226.9213, 347.4673, 317.2448],\n",
      "        [ 32.8129,   9.7017, 372.8806, 219.8249]], device='cuda:0'))\n",
      "IMAGES_512/4C528AA2.JPG\n",
      "4C528AA2\n",
      "Boxes(tensor([[198.8446, 205.8360, 319.4044, 325.9220]], device='cuda:0'))\n",
      "IMAGES_512/8F98C405.JPG\n",
      "8F98C405\n",
      "Boxes(tensor([[206.1579, 119.0389, 412.4697, 285.4669]], device='cuda:0'))\n",
      "IMAGES_512/CCC58426.JPG\n",
      "CCC58426\n",
      "Boxes(tensor([[227.7506, 190.4425, 322.9306, 279.1420],\n",
      "        [385.6999, 245.7492, 510.5148, 381.4265]], device='cuda:0'))\n",
      "IMAGES_512/3EF16ACA.JPG\n",
      "3EF16ACA\n",
      "Boxes(tensor([[226.0178, 127.7229, 384.3691, 254.4908]], device='cuda:0'))\n",
      "IMAGES_512/E88D5FA0.JPG\n",
      "E88D5FA0\n",
      "Boxes(tensor([[246.9696,  45.3726, 349.2773, 180.0503]], device='cuda:0'))\n",
      "IMAGES_512/3442460E.JPG\n",
      "3442460E\n",
      "Boxes(tensor([[162.4677, 185.7216, 298.9684, 312.6144]], device='cuda:0'))\n",
      "IMAGES_512/99DB2AD9.JPG\n",
      "99DB2AD9\n",
      "Boxes(tensor([[240.4741, 141.3263, 407.5653, 283.4176],\n",
      "        [421.5645, 277.2596, 512.0000, 383.2073]], device='cuda:0'))\n",
      "IMAGES_512/11DFABDA.JPG\n",
      "11DFABDA\n",
      "Boxes(tensor([[167.6074, 188.7098, 302.1156, 278.6083]], device='cuda:0'))\n",
      "IMAGES_512/481A4C59.JPG\n",
      "481A4C59\n",
      "Boxes(tensor([[239.0177, 139.0649, 379.5950, 272.6045]], device='cuda:0'))\n",
      "IMAGES_512/8F6F894A.JPG\n",
      "8F6F894A\n",
      "Boxes(tensor([[228.0728, 191.3156, 428.3807, 337.8751]], device='cuda:0'))\n",
      "IMAGES_512/F7245C5F.JPG\n",
      "F7245C5F\n",
      "Boxes(tensor([[335.5770, 180.5101, 486.7281, 340.1461]], device='cuda:0'))\n",
      "IMAGES_512/9E45F484.JPG\n",
      "9E45F484\n",
      "Boxes(tensor([[159.2059, 187.3012, 283.5358, 306.2157]], device='cuda:0'))\n",
      "IMAGES_512/C47E41BD.JPG\n",
      "C47E41BD\n",
      "Boxes(tensor([[161.9337, 152.3304, 345.7101, 384.0000],\n",
      "        [ 44.6276, 133.3481, 153.5255, 207.6970]], device='cuda:0'))\n",
      "IMAGES_512/BA9896A0.JPG\n",
      "BA9896A0\n",
      "Boxes(tensor([[227.1060, 184.1152, 268.7285, 249.4248]], device='cuda:0'))\n",
      "IMAGES_512/8B657522.JPG\n",
      "8B657522\n",
      "Boxes(tensor([[206.1148, 180.4896, 287.5744, 298.7104]], device='cuda:0'))\n",
      "IMAGES_512/CC46FA58.JPG\n",
      "CC46FA58\n",
      "Boxes(tensor([[162.1411, 164.8220, 253.1161, 286.4501]], device='cuda:0'))\n",
      "IMAGES_512/D9D51468.JPG\n",
      "D9D51468\n",
      "Boxes(tensor([[193.8008, 158.0134, 276.7597, 237.1463]], device='cuda:0'))\n",
      "IMAGES_512/8CD48796.JPG\n",
      "8CD48796\n",
      "Boxes(tensor([[164.7832, 178.9924, 311.6580, 295.1826]], device='cuda:0'))\n",
      "IMAGES_512/87878214.JPG\n",
      "87878214\n",
      "Boxes(tensor([[206.8720, 167.3274, 335.8130, 271.6444]], device='cuda:0'))\n",
      "IMAGES_512/75DF976A.JPG\n",
      "75DF976A\n",
      "Boxes(tensor([[162.9711, 154.9961, 318.5760, 378.7246]], device='cuda:0'))\n",
      "IMAGES_512/6F23659E.JPG\n",
      "6F23659E\n",
      "Boxes(tensor([[179.7366, 157.4858, 372.0805, 285.1623]], device='cuda:0'))\n",
      "IMAGES_512/75C730F9.JPG\n",
      "75C730F9\n",
      "Boxes(tensor([[202.2466, 169.5837, 331.3523, 301.4462]], device='cuda:0'))\n",
      "IMAGES_512/C3673FFD.JPG\n",
      "C3673FFD\n",
      "Boxes(tensor([[308.3465, 205.7255, 397.0006, 355.1844]], device='cuda:0'))\n",
      "IMAGES_512/AF75DEFC.JPG\n",
      "AF75DEFC\n",
      "Boxes(tensor([[156.2744, 187.2521, 286.5032, 317.0331]], device='cuda:0'))\n",
      "IMAGES_512/95C64743.JPG\n",
      "95C64743\n",
      "Boxes(tensor([[240.2914, 198.6327, 305.8836, 284.8300]], device='cuda:0'))\n",
      "IMAGES_512/50F03E04.JPG\n",
      "50F03E04\n",
      "Boxes(tensor([[200.4344, 161.7744, 263.5906, 210.3231]], device='cuda:0'))\n",
      "IMAGES_512/D856172A.JPG\n",
      "D856172A\n",
      "Boxes(tensor([[128.2150, 248.3803, 292.4250, 359.7320]], device='cuda:0'))\n",
      "IMAGES_512/F882D454.JPG\n",
      "F882D454\n",
      "Boxes(tensor([[231.5452, 145.5237, 338.5547, 247.2924]], device='cuda:0'))\n",
      "IMAGES_512/01AFEB73.JPG\n",
      "01AFEB73\n",
      "Boxes(tensor([[210.4163, 205.4579, 311.3384, 316.5896]], device='cuda:0'))\n",
      "IMAGES_512/43172D72.JPG\n",
      "43172D72\n",
      "Boxes(tensor([[269.7473, 161.6798, 398.0437, 315.7013]], device='cuda:0'))\n",
      "IMAGES_512/3AF4CE60.JPG\n",
      "3AF4CE60\n",
      "Boxes(tensor([[172.7384, 214.4382, 336.9046, 327.2382]], device='cuda:0'))\n",
      "IMAGES_512/93E4E4CD.JPG\n",
      "93E4E4CD\n",
      "Boxes(tensor([[288.1686, 187.1188, 437.3915, 372.3035]], device='cuda:0'))\n",
      "IMAGES_512/87AB4178.JPG\n",
      "87AB4178\n",
      "Boxes(tensor([[212.6966, 224.8424, 316.9351, 327.6575],\n",
      "        [ 83.6460,   9.4225, 402.1553, 217.1100]], device='cuda:0'))\n",
      "IMAGES_512/203AED9F.JPG\n",
      "203AED9F\n",
      "Boxes(tensor([[225.6825, 191.6889, 315.7114, 307.4772]], device='cuda:0'))\n",
      "IMAGES_512/4085A438.JPG\n",
      "4085A438\n",
      "Boxes(tensor([[331.8316, 194.9164, 504.0469, 314.8184]], device='cuda:0'))\n",
      "IMAGES_512/0A5075A6.JPG\n",
      "0A5075A6\n",
      "Boxes(tensor([[260.2748, 172.5032, 306.9601, 241.6070]], device='cuda:0'))\n",
      "IMAGES_512/866DDC6E.JPG\n",
      "866DDC6E\n",
      "Boxes(tensor([[229.5876, 210.7810, 382.2709, 381.7011]], device='cuda:0'))\n",
      "IMAGES_512/23D7F5B0.JPG\n",
      "23D7F5B0\n",
      "Boxes(tensor([[212.1682,  75.8414, 511.8731, 335.9669]], device='cuda:0'))\n",
      "IMAGES_512/5FAFA97B.JPG\n",
      "5FAFA97B\n",
      "Boxes(tensor([[ 11.2395, 136.3079, 255.5987, 358.8212]], device='cuda:0'))\n",
      "IMAGES_512/7A8C4C8D.JPG\n",
      "7A8C4C8D\n",
      "Boxes(tensor([[213.8520, 210.0279, 349.3245, 318.6565]], device='cuda:0'))\n",
      "IMAGES_512/5391DF72.JPG\n",
      "5391DF72\n",
      "Boxes(tensor([[221.5101, 240.6780, 309.4604, 379.0061]], device='cuda:0'))\n",
      "IMAGES_512/0F8CC6D1.JPG\n",
      "0F8CC6D1\n",
      "Boxes(tensor([[185.1481, 179.2923, 316.4520, 372.0874]], device='cuda:0'))\n",
      "IMAGES_512/A97A739F.JPG\n",
      "A97A739F\n",
      "Boxes(tensor([[226.4464, 190.5435, 325.0650, 350.3535],\n",
      "        [326.3065, 155.9356, 463.3569, 282.2692],\n",
      "        [ 77.9352, 166.0998, 205.8773, 291.1496]], device='cuda:0'))\n",
      "IMAGES_512/ED93100D.JPG\n",
      "ED93100D\n",
      "Boxes(tensor([[243.1790, 196.8514, 363.0407, 380.3339]], device='cuda:0'))\n",
      "IMAGES_512/E8BC806C.JPG\n",
      "E8BC806C\n",
      "Boxes(tensor([[193.6018, 165.8835, 302.6582, 257.9624]], device='cuda:0'))\n",
      "IMAGES_512/09E9A0CB.JPG\n",
      "09E9A0CB\n",
      "Boxes(tensor([[229.8633, 160.9408, 392.0045, 284.7542]], device='cuda:0'))\n",
      "IMAGES_512/BFDC65CD.JPG\n",
      "BFDC65CD\n",
      "Boxes(tensor([[ 87.4024, 216.7919, 238.3517, 345.7282]], device='cuda:0'))\n",
      "IMAGES_512/BB0EC309.JPG\n",
      "BB0EC309\n",
      "Boxes(tensor([[265.7712, 201.3805, 342.8486, 304.9329]], device='cuda:0'))\n",
      "IMAGES_512/F6A43E44.JPG\n",
      "F6A43E44\n",
      "Boxes(tensor([[189.0675, 233.4044, 277.8742, 378.8550]], device='cuda:0'))\n",
      "IMAGES_512/95FE00DA.JPG\n",
      "95FE00DA\n",
      "Boxes(tensor([[130.8951,  12.1396, 374.1440, 250.6358]], device='cuda:0'))\n",
      "IMAGES_512/DEA63D2E.JPG\n",
      "DEA63D2E\n",
      "Boxes(tensor([[243.1676, 198.3494, 346.3394, 338.1911]], device='cuda:0'))\n",
      "IMAGES_512/502CF07D.JPG\n",
      "502CF07D\n",
      "Boxes(tensor([[260.4421, 219.8695, 347.6920, 359.3619]], device='cuda:0'))\n",
      "IMAGES_512/847BF435.JPG\n",
      "847BF435\n",
      "Boxes(tensor([[167.1547, 136.7354, 361.5137, 266.0300],\n",
      "        [133.4157, 278.8515, 212.2253, 376.2565]], device='cuda:0'))\n",
      "IMAGES_512/D1AD3D4F.JPG\n",
      "D1AD3D4F\n",
      "Boxes(tensor([[180.8270,   0.0000, 315.1661,  94.9281]], device='cuda:0'))\n",
      "IMAGES_512/DD86AC55.JPG\n",
      "DD86AC55\n",
      "Boxes(tensor([[223.2677, 113.0986, 393.9884, 259.2294],\n",
      "        [396.3868, 270.4070, 511.0044, 382.7838]], device='cuda:0'))\n",
      "IMAGES_512/15B46713.JPG\n",
      "15B46713\n",
      "Boxes(tensor([[245.5435, 201.2481, 378.8746, 343.3734]], device='cuda:0'))\n",
      "IMAGES_512/50443A61.JPG\n",
      "50443A61\n",
      "Boxes(tensor([[272.7364, 217.4048, 357.7670, 348.0166]], device='cuda:0'))\n",
      "IMAGES_512/FD37B3CF.JPG\n",
      "FD37B3CF\n",
      "Boxes(tensor([[222.0380, 173.8194, 327.4525, 264.1963]], device='cuda:0'))\n",
      "IMAGES_512/FDA39280.JPG\n",
      "FDA39280\n",
      "Boxes(tensor([[189.1247, 170.3648, 304.8104, 362.2534]], device='cuda:0'))\n",
      "IMAGES_512/5026FDA2.JPG\n",
      "5026FDA2\n",
      "Boxes(tensor([[228.6466, 172.5516, 385.7003, 370.5342]], device='cuda:0'))\n",
      "IMAGES_512/BCCAF590.JPG\n",
      "BCCAF590\n",
      "Boxes(tensor([[242.2150, 240.6220, 352.6197, 360.8874]], device='cuda:0'))\n",
      "IMAGES_512/D9D03972.JPG\n",
      "D9D03972\n",
      "Boxes(tensor([[249.3167, 140.2915, 436.5053, 340.0299]], device='cuda:0'))\n",
      "IMAGES_512/97C811ED.JPG\n",
      "97C811ED\n",
      "Boxes(tensor([[116.1606, 149.5298, 222.7685, 250.3226]], device='cuda:0'))\n",
      "IMAGES_512/4BF554FD.JPG\n",
      "4BF554FD\n",
      "Boxes(tensor([[140.2919, 150.7857, 416.8183, 316.2202]], device='cuda:0'))\n",
      "IMAGES_512/B9A2EDF2.JPG\n",
      "B9A2EDF2\n",
      "Boxes(tensor([[227.7060, 133.0829, 374.6780, 267.1258]], device='cuda:0'))\n",
      "IMAGES_512/C2D02E9B.JPG\n",
      "C2D02E9B\n",
      "Boxes(tensor([[243.3084, 159.2736, 381.4563, 351.2031]], device='cuda:0'))\n",
      "IMAGES_512/4AABEB59.JPG\n",
      "4AABEB59\n",
      "Boxes(tensor([[212.1439, 187.8577, 306.9211, 345.3579],\n",
      "        [ 98.1683, 150.8531, 163.8093, 224.8529]], device='cuda:0'))\n",
      "IMAGES_512/4222F575.JPG\n",
      "4222F575\n",
      "Boxes(tensor([[280.5242, 194.2779, 394.2791, 347.1259]], device='cuda:0'))\n",
      "IMAGES_512/13877F3A.JPG\n",
      "13877F3A\n",
      "Boxes(tensor([[197.9765,  90.2411, 349.6284, 248.0809]], device='cuda:0'))\n",
      "IMAGES_512/065AB0EB.JPG\n",
      "065AB0EB\n",
      "Boxes(tensor([[231.9618, 176.5163, 318.3148, 252.7647]], device='cuda:0'))\n",
      "IMAGES_512/9AC788F6.JPG\n",
      "9AC788F6\n",
      "Boxes(tensor([[168.5491, 165.8675, 287.2947, 256.5394]], device='cuda:0'))\n",
      "IMAGES_512/92ACFA0F.JPG\n",
      "92ACFA0F\n",
      "Boxes(tensor([[151.9490, 201.7561, 311.9600, 325.5399]], device='cuda:0'))\n",
      "IMAGES_512/319EDFB1.JPG\n",
      "319EDFB1\n",
      "Boxes(tensor([[213.6621, 162.1312, 394.1378, 357.9829]], device='cuda:0'))\n",
      "IMAGES_512/8E3FDE13.JPG\n",
      "8E3FDE13\n",
      "Boxes(tensor([[226.9341, 217.0318, 322.9335, 377.4302]], device='cuda:0'))\n",
      "IMAGES_512/EE1C1BE1.JPG\n",
      "EE1C1BE1\n",
      "Boxes(tensor([[261.8512, 151.7077, 376.5733, 265.6844]], device='cuda:0'))\n",
      "IMAGES_512/1D6020B9.JPG\n",
      "1D6020B9\n",
      "Boxes(tensor([[245.4500, 189.2103, 395.3243, 293.8261]], device='cuda:0'))\n",
      "IMAGES_512/8E0F1E47.JPG\n",
      "8E0F1E47\n",
      "Boxes(tensor([[212.4122, 201.3272, 346.4644, 332.6702]], device='cuda:0'))\n",
      "IMAGES_512/D932962E.JPG\n",
      "D932962E\n",
      "Boxes(tensor([[168.7105,   0.0000, 433.0360, 202.9607]], device='cuda:0'))\n",
      "IMAGES_512/404AFEBF.JPG\n",
      "404AFEBF\n",
      "Boxes(tensor([[236.5580, 229.4755, 396.4781, 361.2496]], device='cuda:0'))\n",
      "IMAGES_512/EFFFE80F.JPG\n",
      "EFFFE80F\n",
      "Boxes(tensor([[280.2855, 153.5535, 373.2538, 301.9678]], device='cuda:0'))\n",
      "IMAGES_512/F32E8C2C.JPG\n",
      "F32E8C2C\n",
      "Boxes(tensor([[228.8283, 152.6541, 379.6147, 291.1135]], device='cuda:0'))\n",
      "IMAGES_512/A2504759.JPG\n",
      "A2504759\n",
      "Boxes(tensor([[199.9611, 104.5507, 363.9013, 242.8700]], device='cuda:0'))\n",
      "IMAGES_512/91CE5055.JPG\n",
      "91CE5055\n",
      "Boxes(tensor([[251.6996, 202.1136, 305.5145, 273.9368]], device='cuda:0'))\n",
      "IMAGES_512/6DD3ADD5.JPG\n",
      "6DD3ADD5\n",
      "Boxes(tensor([[171.6966, 122.1046, 363.0220, 303.8726]], device='cuda:0'))\n",
      "IMAGES_512/875C064F.JPG\n",
      "875C064F\n",
      "Boxes(tensor([[353.6583, 232.8895, 443.1306, 369.0449]], device='cuda:0'))\n",
      "IMAGES_512/5EA1552D.JPG\n",
      "5EA1552D\n",
      "Boxes(tensor([[210.6089, 189.9561, 292.9562, 259.0532]], device='cuda:0'))\n",
      "IMAGES_512/1A1DCBC5.JPG\n",
      "1A1DCBC5\n",
      "Boxes(tensor([[241.1188, 132.3779, 378.8959, 228.0469]], device='cuda:0'))\n",
      "IMAGES_512/364215F4.JPG\n",
      "364215F4\n",
      "Boxes(tensor([[255.7383, 204.4344, 463.1949, 356.4210],\n",
      "        [ 16.1548, 242.2773,  66.1196, 294.2802]], device='cuda:0'))\n",
      "IMAGES_512/5A9C8DCF.JPG\n",
      "5A9C8DCF\n",
      "Boxes(tensor([[235.6900, 196.1658, 442.1602, 331.0441]], device='cuda:0'))\n",
      "IMAGES_512/2590DF08.JPG\n",
      "2590DF08\n",
      "Boxes(tensor([[267.7796, 123.6153, 348.7938, 226.7704]], device='cuda:0'))\n",
      "IMAGES_512/C734B034.JPG\n",
      "C734B034\n",
      "Boxes(tensor([[252.9802, 199.5086, 419.8507, 331.6335]], device='cuda:0'))\n",
      "IMAGES_512/5B28C326.JPG\n",
      "5B28C326\n",
      "Boxes(tensor([[316.5122,   7.8660, 451.1441, 193.9030]], device='cuda:0'))\n",
      "IMAGES_512/2E3449B1.JPG\n",
      "2E3449B1\n",
      "Boxes(tensor([[231.6393, 169.0600, 378.1405, 282.1736]], device='cuda:0'))\n",
      "IMAGES_512/003B27CF.JPG\n",
      "003B27CF\n",
      "Boxes(tensor([[178.1772, 213.9666, 282.4711, 335.8861]], device='cuda:0'))\n",
      "IMAGES_512/0E1C8C38.JPG\n",
      "0E1C8C38\n",
      "Boxes(tensor([[237.4352, 113.1194, 287.5401, 163.4435]], device='cuda:0'))\n",
      "IMAGES_512/A005FDAF.JPG\n",
      "A005FDAF\n",
      "Boxes(tensor([[223.3429, 121.9207, 308.3833, 249.3203]], device='cuda:0'))\n",
      "IMAGES_512/4A15F40F.JPG\n",
      "4A15F40F\n",
      "Boxes(tensor([[ 64.1150, 156.9132, 336.0724, 316.8420]], device='cuda:0'))\n",
      "IMAGES_512/B039AC45.JPG\n",
      "B039AC45\n",
      "Boxes(tensor([[201.6824, 224.0612, 391.7388, 378.3495],\n",
      "        [187.8197,   1.6151, 294.5755,  84.5416]], device='cuda:0'))\n",
      "IMAGES_512/61FCC126.JPG\n",
      "61FCC126\n",
      "Boxes(tensor([[247.2599, 201.7481, 427.7947, 352.4760]], device='cuda:0'))\n",
      "IMAGES_512/B42ECD0F.JPG\n",
      "B42ECD0F\n",
      "Boxes(tensor([[215.6213,  65.7302, 331.8130, 154.9717]], device='cuda:0'))\n",
      "IMAGES_512/D74149F5.JPG\n",
      "D74149F5\n",
      "Boxes(tensor([[177.7075, 187.1933, 346.3513, 317.7977]], device='cuda:0'))\n",
      "IMAGES_512/13866A5C.JPG\n",
      "13866A5C\n",
      "Boxes(tensor([[246.1315, 135.4935, 320.3343, 205.6273]], device='cuda:0'))\n",
      "IMAGES_512/2DF37390.JPG\n",
      "2DF37390\n",
      "Boxes(tensor([[164.9624, 124.2702, 385.6570, 267.7421]], device='cuda:0'))\n",
      "IMAGES_512/E486BE92.JPG\n",
      "E486BE92\n",
      "Boxes(tensor([[243.6144, 169.8939, 333.7040, 309.1701]], device='cuda:0'))\n",
      "IMAGES_512/58F19C1E.JPG\n",
      "58F19C1E\n",
      "Boxes(tensor([[232.7009, 199.3648, 291.4840, 295.7376]], device='cuda:0'))\n",
      "IMAGES_512/519C31BC.JPG\n",
      "519C31BC\n",
      "Boxes(tensor([[212.7415, 191.5752, 308.7131, 281.3166]], device='cuda:0'))\n",
      "IMAGES_512/E02B5FE8.JPG\n",
      "E02B5FE8\n",
      "Boxes(tensor([[158.5854, 211.7074, 288.7424, 326.5402]], device='cuda:0'))\n",
      "IMAGES_512/01C8BEA0.JPG\n",
      "01C8BEA0\n",
      "Boxes(tensor([[267.7301, 153.9121, 371.1416, 268.1472],\n",
      "        [ 18.4135,  70.4384, 226.7772, 380.9620]], device='cuda:0'))\n",
      "IMAGES_512/06493841.JPG\n",
      "06493841\n",
      "Boxes(tensor([[198.4778, 118.5327, 300.3122, 233.3318]], device='cuda:0'))\n",
      "IMAGES_512/CB502048.JPG\n",
      "CB502048\n",
      "Boxes(tensor([[216.6827, 186.1283, 313.4201, 294.2163]], device='cuda:0'))\n",
      "IMAGES_512/57D0963E.JPG\n",
      "57D0963E\n",
      "Boxes(tensor([[228.6524, 217.4265, 360.1720, 310.6510]], device='cuda:0'))\n",
      "IMAGES_512/3FE8D9D9.JPG\n",
      "3FE8D9D9\n",
      "Boxes(tensor([[279.9980, 250.4459, 367.0200, 382.9610]], device='cuda:0'))\n",
      "IMAGES_512/68B485C3.JPG\n",
      "68B485C3\n",
      "Boxes(tensor([[204.5148, 208.5340, 300.1433, 358.1738]], device='cuda:0'))\n",
      "IMAGES_512/A504E106.JPG\n",
      "A504E106\n",
      "Boxes(tensor([[230.8875, 197.6349, 334.2798, 379.5240]], device='cuda:0'))\n",
      "IMAGES_512/5BB9D8A4.JPG\n",
      "5BB9D8A4\n",
      "Boxes(tensor([[213.0667, 200.4842, 334.6473, 367.5108]], device='cuda:0'))\n",
      "IMAGES_512/7566A78E.JPG\n",
      "7566A78E\n",
      "Boxes(tensor([[209.0892, 141.9308, 315.1645, 296.7828]], device='cuda:0'))\n",
      "IMAGES_512/433F9EDA.JPG\n",
      "433F9EDA\n",
      "Boxes(tensor([[257.0622, 170.8647, 383.5763, 274.0792]], device='cuda:0'))\n",
      "IMAGES_512/D818E9F5.JPG\n",
      "D818E9F5\n",
      "Boxes(tensor([[254.6951, 136.0740, 320.7272, 231.3388]], device='cuda:0'))\n",
      "IMAGES_512/8FD27484.JPG\n",
      "8FD27484\n",
      "Boxes(tensor([[204.6367, 182.0543, 342.6645, 332.8433],\n",
      "        [219.2493, 127.4570, 447.4344, 363.1162]], device='cuda:0'))\n",
      "IMAGES_512/9F0DE5FD.JPG\n",
      "9F0DE5FD\n",
      "Boxes(tensor([[133.8379, 182.7260, 288.9656, 311.4706]], device='cuda:0'))\n",
      "IMAGES_512/42C5146C.JPG\n",
      "42C5146C\n",
      "Boxes(tensor([[132.0721, 128.4944, 338.4788, 280.0791]], device='cuda:0'))\n",
      "IMAGES_512/1B395B9A.JPG\n",
      "1B395B9A\n",
      "Boxes(tensor([[208.6845, 170.9284, 370.8675, 336.0374]], device='cuda:0'))\n",
      "IMAGES_512/5E492B7F.JPG\n",
      "5E492B7F\n",
      "Boxes(tensor([[202.1187, 220.3222, 295.8441, 362.8659]], device='cuda:0'))\n",
      "IMAGES_512/41757A1A.JPG\n",
      "41757A1A\n",
      "Boxes(tensor([[213.5601, 173.6509, 283.5649, 245.2955]], device='cuda:0'))\n",
      "IMAGES_512/D02C15C1.JPG\n",
      "D02C15C1\n",
      "Boxes(tensor([[187.1284, 184.3011, 325.7030, 289.5259]], device='cuda:0'))\n",
      "IMAGES_512/7BA4B9CB.JPG\n",
      "7BA4B9CB\n",
      "Boxes(tensor([[254.5029, 202.8224, 365.1957, 372.0750]], device='cuda:0'))\n",
      "IMAGES_512/F576A894.JPG\n",
      "F576A894\n",
      "Boxes(tensor([[235.3490, 174.9761, 373.7055, 279.5765]], device='cuda:0'))\n",
      "IMAGES_512/1F910E96.JPG\n",
      "1F910E96\n",
      "Boxes(tensor([[136.3687, 130.6234, 294.8318, 238.7856]], device='cuda:0'))\n",
      "IMAGES_512/48CD988B.JPG\n",
      "48CD988B\n",
      "Boxes(tensor([[221.5002, 170.6477, 411.7599, 297.3272]], device='cuda:0'))\n",
      "IMAGES_512/D9B53505.JPG\n",
      "D9B53505\n",
      "Boxes(tensor([[249.9548, 128.4275, 329.8762, 212.8510]], device='cuda:0'))\n",
      "IMAGES_512/DF26FFAE.JPG\n",
      "DF26FFAE\n",
      "Boxes(tensor([[255.8056, 124.8013, 426.4653, 304.3798]], device='cuda:0'))\n",
      "IMAGES_512/20365507.JPG\n",
      "20365507\n",
      "Boxes(tensor([[229.9702, 216.7389, 266.7288, 292.5059]], device='cuda:0'))\n",
      "IMAGES_512/D7BAF558.JPG\n",
      "D7BAF558\n",
      "Boxes(tensor([[201.9996,  53.8173, 423.8393, 210.6326]], device='cuda:0'))\n",
      "IMAGES_512/6C07DF68.JPG\n",
      "6C07DF68\n",
      "Boxes(tensor([[220.8732, 102.8806, 279.9714, 167.9085]], device='cuda:0'))\n",
      "IMAGES_512/A90F2EC7.JPG\n",
      "A90F2EC7\n",
      "Boxes(tensor([[288.0903, 258.6953, 437.7979, 376.5351]], device='cuda:0'))\n",
      "IMAGES_512/D4086865.JPG\n",
      "D4086865\n",
      "Boxes(tensor([[185.2732, 131.3662, 321.8646, 238.6677]], device='cuda:0'))\n",
      "IMAGES_512/2BCA7DD7.JPG\n",
      "2BCA7DD7\n",
      "Boxes(tensor([[ 92.9649, 134.0458, 254.4185, 298.7412]], device='cuda:0'))\n",
      "IMAGES_512/D627C3BD.JPG\n",
      "D627C3BD\n",
      "Boxes(tensor([[172.6499, 182.5136, 324.6534, 279.5604]], device='cuda:0'))\n",
      "IMAGES_512/C6764F86.JPG\n",
      "C6764F86\n",
      "Boxes(tensor([[325.9587, 230.1427, 411.7097, 321.4538]], device='cuda:0'))\n",
      "IMAGES_512/FEB5B3A0.JPG\n",
      "FEB5B3A0\n",
      "Boxes(tensor([[248.6719, 207.5470, 339.8345, 309.9049],\n",
      "        [340.5283, 233.9141, 426.2835, 306.7003]], device='cuda:0'))\n",
      "IMAGES_512/D3BAE027.JPG\n",
      "D3BAE027\n",
      "Boxes(tensor([[219.8269, 158.2210, 387.2144, 319.8019]], device='cuda:0'))\n",
      "IMAGES_512/A209E2F6.JPG\n",
      "A209E2F6\n",
      "Boxes(tensor([[229.7954, 110.6237, 418.6954, 257.9555],\n",
      "        [418.7970, 275.6974, 508.8363, 383.7361]], device='cuda:0'))\n",
      "IMAGES_512/CDCA31C0.JPG\n",
      "CDCA31C0\n",
      "Boxes(tensor([[166.1991,  61.0811, 452.0268, 352.3913]], device='cuda:0'))\n",
      "IMAGES_512/C63812CD.JPG\n",
      "C63812CD\n",
      "Boxes(tensor([[223.5817, 142.6360, 313.7998, 263.2116],\n",
      "        [351.2265,  56.2268, 384.4348,  91.7697]], device='cuda:0'))\n",
      "IMAGES_512/6404737D.JPG\n",
      "6404737D\n",
      "Boxes(tensor([[254.7605, 231.7873, 414.4067, 354.9403]], device='cuda:0'))\n",
      "IMAGES_512/6546259F.JPG\n",
      "6546259F\n",
      "Boxes(tensor([[294.9076, 215.0905, 421.6134, 319.7068]], device='cuda:0'))\n",
      "IMAGES_512/1A431493.JPG\n",
      "1A431493\n",
      "Boxes(tensor([[214.7272, 178.4278, 323.7940, 323.1583]], device='cuda:0'))\n",
      "IMAGES_512/383FC686.JPG\n",
      "383FC686\n",
      "Boxes(tensor([[232.8204, 226.7167, 350.0900, 380.9462]], device='cuda:0'))\n",
      "IMAGES_512/AABDCA94.JPG\n",
      "AABDCA94\n",
      "Boxes(tensor([[159.3765,  66.8090, 441.8383, 376.1688]], device='cuda:0'))\n",
      "IMAGES_512/C2ADBE12.JPG\n",
      "C2ADBE12\n",
      "Boxes(tensor([[151.5354, 152.3581, 273.2537, 252.2715],\n",
      "        [444.6196, 233.1832, 510.6606, 270.7668]], device='cuda:0'))\n",
      "IMAGES_512/C6084234.JPG\n",
      "C6084234\n",
      "Boxes(tensor([[203.0281, 171.7591, 264.2487, 228.8026]], device='cuda:0'))\n",
      "IMAGES_512/0D08F047.JPG\n",
      "0D08F047\n",
      "Boxes(tensor([[160.9268,  76.1875, 363.9088, 251.0813]], device='cuda:0'))\n",
      "IMAGES_512/0B24FE21.JPG\n",
      "0B24FE21\n",
      "Boxes(tensor([[224.8241, 190.9107, 337.9619, 279.2934]], device='cuda:0'))\n",
      "IMAGES_512/7FCE09E5.JPG\n",
      "7FCE09E5\n",
      "Boxes(tensor([[198.1228, 195.5316, 326.9554, 307.8755]], device='cuda:0'))\n",
      "IMAGES_512/C73376CD.JPG\n",
      "C73376CD\n",
      "Boxes(tensor([[203.8307, 147.7320, 304.5357, 257.9098]], device='cuda:0'))\n",
      "IMAGES_512/FE00066C.JPG\n",
      "FE00066C\n",
      "Boxes(tensor([[ 13.0550, 186.8140, 153.1148, 382.2510]], device='cuda:0'))\n",
      "IMAGES_512/17707016.JPG\n",
      "17707016\n",
      "Boxes(tensor([[100.4971, 185.0429, 248.9800, 291.0421]], device='cuda:0'))\n",
      "IMAGES_512/FEB02FBE.JPG\n",
      "FEB02FBE\n",
      "Boxes(tensor([[268.2792, 127.0663, 343.7044, 243.2467]], device='cuda:0'))\n",
      "IMAGES_512/1A9ECD53.JPG\n",
      "1A9ECD53\n",
      "Boxes(tensor([[250.6191, 176.5010, 368.4601, 329.1053]], device='cuda:0'))\n",
      "IMAGES_512/DBE4A039.JPG\n",
      "DBE4A039\n",
      "Boxes(tensor([[224.1877, 196.2635, 327.3647, 354.0137]], device='cuda:0'))\n",
      "IMAGES_512/C47ED374.JPG\n",
      "C47ED374\n",
      "Boxes(tensor([[224.2400, 204.0347, 327.3241, 310.1770]], device='cuda:0'))\n",
      "IMAGES_512/451E5AAB.JPG\n",
      "451E5AAB\n",
      "Boxes(tensor([[209.9001,  50.4418, 291.1667, 179.2746]], device='cuda:0'))\n",
      "IMAGES_512/280C520B.JPG\n",
      "280C520B\n",
      "Boxes(tensor([[252.4813, 163.6405, 336.5922, 284.8512]], device='cuda:0'))\n",
      "IMAGES_512/AB6C3E94.JPG\n",
      "AB6C3E94\n",
      "Boxes(tensor([[279.4038, 219.9447, 418.7402, 337.3925]], device='cuda:0'))\n",
      "IMAGES_512/E8320067.JPG\n",
      "E8320067\n",
      "Boxes(tensor([[179.9426, 141.1641, 303.0461, 278.4839]], device='cuda:0'))\n",
      "IMAGES_512/7BFEFC98.JPG\n",
      "7BFEFC98\n",
      "Boxes(tensor([[234.3320, 176.3661, 359.0095, 292.6922]], device='cuda:0'))\n",
      "IMAGES_512/A01A955C.JPG\n",
      "A01A955C\n",
      "Boxes(tensor([[183.8598, 172.0895, 343.1465, 320.4633]], device='cuda:0'))\n",
      "IMAGES_512/B7C7E892.JPG\n",
      "B7C7E892\n",
      "Boxes(tensor([[173.4165, 178.9980, 356.4748, 304.5090]], device='cuda:0'))\n",
      "IMAGES_512/3A80F344.JPG\n",
      "3A80F344\n",
      "Boxes(tensor([[236.0314, 168.6587, 341.4302, 364.7717]], device='cuda:0'))\n",
      "IMAGES_512/3EABDB36.JPG\n",
      "3EABDB36\n",
      "Boxes(tensor([[218.0118, 216.8631, 403.1909, 357.7634]], device='cuda:0'))\n",
      "IMAGES_512/875EFBC9.JPG\n",
      "875EFBC9\n",
      "Boxes(tensor([[216.7002, 188.6981, 288.4803, 293.0246]], device='cuda:0'))\n",
      "IMAGES_512/55B0D23B.JPG\n",
      "55B0D23B\n",
      "Boxes(tensor([[ 96.0524, 170.7785, 362.6553, 351.5420]], device='cuda:0'))\n",
      "IMAGES_512/17E86C77.JPG\n",
      "17E86C77\n",
      "Boxes(tensor([[165.9837, 181.7135, 333.9633, 323.5674]], device='cuda:0'))\n",
      "IMAGES_512/FD9D272B.JPG\n",
      "FD9D272B\n",
      "Boxes(tensor([[156.6004, 213.8517, 301.7434, 321.4290]], device='cuda:0'))\n",
      "IMAGES_512/61E98DEE.JPG\n",
      "61E98DEE\n",
      "Boxes(tensor([[227.2333, 159.9602, 305.0937, 294.5209]], device='cuda:0'))\n",
      "IMAGES_512/1B3CDCDF.JPG\n",
      "1B3CDCDF\n",
      "Boxes(tensor([[297.9223, 192.1303, 470.3153, 345.4700]], device='cuda:0'))\n",
      "IMAGES_512/1ABA1736.JPG\n",
      "1ABA1736\n",
      "Boxes(tensor([[182.4685, 162.8192, 379.0917, 315.5875]], device='cuda:0'))\n",
      "IMAGES_512/ED7C80BB.JPG\n",
      "ED7C80BB\n",
      "Boxes(tensor([[216.1559, 104.0986, 288.2541, 174.1401]], device='cuda:0'))\n",
      "IMAGES_512/4B5D2917.JPG\n",
      "4B5D2917\n",
      "Boxes(tensor([[243.2560, 196.7430, 343.3815, 328.9865]], device='cuda:0'))\n",
      "IMAGES_512/4C116A0F.JPG\n",
      "4C116A0F\n",
      "Boxes(tensor([[243.6565, 211.7858, 388.0647, 349.8054]], device='cuda:0'))\n",
      "IMAGES_512/86AF26DD.JPG\n",
      "86AF26DD\n",
      "Boxes(tensor([[239.7493, 112.8933, 408.0304, 240.2433]], device='cuda:0'))\n",
      "IMAGES_512/C16F51F5.JPG\n",
      "C16F51F5\n",
      "Boxes(tensor([[204.5218, 171.3389, 325.5201, 342.6410],\n",
      "        [411.0050, 166.4493, 512.0000, 229.9101]], device='cuda:0'))\n",
      "IMAGES_512/2D69831D.JPG\n",
      "2D69831D\n",
      "Boxes(tensor([[239.3623, 139.1254, 334.5269, 278.9355],\n",
      "        [338.2658, 120.0162, 393.4725, 177.0359],\n",
      "        [123.0388, 125.5530, 195.0109, 177.7065]], device='cuda:0'))\n",
      "IMAGES_512/6167E8B3.JPG\n",
      "6167E8B3\n",
      "Boxes(tensor([[141.4799, 122.6378, 269.0659, 276.4412],\n",
      "        [  0.0000,  21.6088, 146.6360, 247.7928]], device='cuda:0'))\n",
      "IMAGES_512/BDF8D43A.JPG\n",
      "BDF8D43A\n",
      "Boxes(tensor([[206.8997, 170.9659, 325.3688, 339.9108]], device='cuda:0'))\n",
      "IMAGES_512/E9145CB9.JPG\n",
      "E9145CB9\n",
      "Boxes(tensor([[288.4251, 152.1087, 442.6974, 266.3254]], device='cuda:0'))\n",
      "IMAGES_512/54792145.JPG\n",
      "54792145\n",
      "Boxes(tensor([[214.0695, 170.9435, 412.6459, 311.5628],\n",
      "        [ 24.3706, 266.6630, 218.1855, 383.5080]], device='cuda:0'))\n",
      "IMAGES_512/E71EF549.JPG\n",
      "E71EF549\n",
      "Boxes(tensor([[215.7748, 124.5723, 304.7258, 219.7957]], device='cuda:0'))\n",
      "IMAGES_512/ADCA8A1D.JPG\n",
      "ADCA8A1D\n",
      "Boxes(tensor([[241.1921, 224.2845, 331.1551, 373.4071]], device='cuda:0'))\n",
      "IMAGES_512/BB2A8043.JPG\n",
      "BB2A8043\n",
      "Boxes(tensor([[197.8785, 145.0577, 366.7090, 263.9290]], device='cuda:0'))\n",
      "IMAGES_512/57D8EFF7.JPG\n",
      "57D8EFF7\n",
      "Boxes(tensor([[221.0040, 225.3686, 302.1909, 359.3604]], device='cuda:0'))\n",
      "IMAGES_512/013999E4.JPG\n",
      "013999E4\n",
      "Boxes(tensor([[220.4359, 134.5168, 363.9838, 243.4241]], device='cuda:0'))\n",
      "IMAGES_512/7D7CF91A.JPG\n",
      "7D7CF91A\n",
      "Boxes(tensor([[175.0311, 136.4571, 266.9189, 268.5583]], device='cuda:0'))\n",
      "IMAGES_512/0BB34BE0.JPG\n",
      "0BB34BE0\n",
      "Boxes(tensor([[225.3725, 129.6133, 414.8487, 258.9845],\n",
      "        [ 27.4026, 227.9937, 215.3029, 383.8608]], device='cuda:0'))\n",
      "IMAGES_512/4E5F6238.JPG\n",
      "4E5F6238\n",
      "Boxes(tensor([[268.3909, 198.2064, 323.6285, 274.8220]], device='cuda:0'))\n",
      "IMAGES_512/BEE49B92.JPG\n",
      "BEE49B92\n",
      "Boxes(tensor([[276.3989, 126.3541, 419.5783, 288.0564]], device='cuda:0'))\n",
      "IMAGES_512/3B08CDB1.JPG\n",
      "3B08CDB1\n",
      "Boxes(tensor([[259.5168, 205.7626, 395.7819, 381.4391]], device='cuda:0'))\n",
      "IMAGES_512/0260F033.JPG\n",
      "0260F033\n",
      "Boxes(tensor([[270.2406, 139.1303, 420.9322, 228.8465],\n",
      "        [279.1751,   0.8783, 353.6816,  96.3734]], device='cuda:0'))\n",
      "IMAGES_512/008876A9.JPG\n",
      "008876A9\n",
      "Boxes(tensor([[275.9033,  92.0631, 426.6388, 199.6546]], device='cuda:0'))\n",
      "IMAGES_512/016117B7.JPG\n",
      "016117B7\n",
      "Boxes(tensor([[304.8413, 121.5535, 447.0314, 289.9231]], device='cuda:0'))\n",
      "IMAGES_512/561327A8.JPG\n",
      "561327A8\n",
      "Boxes(tensor([[200.6698, 227.6337, 303.6298, 298.9900],\n",
      "        [121.6031, 238.6870, 164.2119, 311.6934]], device='cuda:0'))\n",
      "IMAGES_512/7DDC2E3E.JPG\n",
      "7DDC2E3E\n",
      "Boxes(tensor([[333.3257, 116.5480, 446.2614, 222.0427],\n",
      "        [231.7989, 169.8506, 321.6616, 316.6421]], device='cuda:0'))\n",
      "IMAGES_512/3F9CA5E2.JPG\n",
      "3F9CA5E2\n",
      "Boxes(tensor([[256.6154, 161.6334, 365.3773, 318.3869],\n",
      "        [118.4982, 186.6371, 226.6010, 240.4368]], device='cuda:0'))\n",
      "IMAGES_512/52193763.JPG\n",
      "52193763\n",
      "Boxes(tensor([[193.7643, 109.1978, 421.2219, 274.6069]], device='cuda:0'))\n",
      "IMAGES_512/928C8BE0.JPG\n",
      "928C8BE0\n",
      "Boxes(tensor([[175.1574, 148.8042, 308.6339, 277.3084],\n",
      "        [ 77.4928, 154.7071, 163.6356, 242.5191]], device='cuda:0'))\n",
      "IMAGES_512/A65F47D9.JPG\n",
      "A65F47D9\n",
      "Boxes(tensor([[245.7972,  99.7055, 395.4305, 231.2327]], device='cuda:0'))\n",
      "IMAGES_512/63935E8D.JPG\n",
      "63935E8D\n",
      "Boxes(tensor([[249.7063, 148.2930, 333.4668, 288.9081]], device='cuda:0'))\n",
      "IMAGES_512/2DF693B3.JPG\n",
      "2DF693B3\n",
      "Boxes(tensor([[177.2668,  60.7934, 305.7148, 179.6721]], device='cuda:0'))\n",
      "IMAGES_512/81CE5229.JPG\n",
      "81CE5229\n",
      "Boxes(tensor([[226.4138, 250.2906, 298.8297, 334.1828]], device='cuda:0'))\n",
      "IMAGES_512/E92F8A62.JPG\n",
      "E92F8A62\n",
      "Boxes(tensor([[171.9748,  62.7678, 346.7363, 228.9858]], device='cuda:0'))\n",
      "IMAGES_512/E0FFA14F.JPG\n",
      "E0FFA14F\n",
      "Boxes(tensor([[111.5982, 186.7612, 265.4459, 347.7183]], device='cuda:0'))\n",
      "IMAGES_512/8DB19DE8.JPG\n",
      "8DB19DE8\n",
      "Boxes(tensor([[217.6243, 120.5834, 290.6973, 184.8945]], device='cuda:0'))\n",
      "IMAGES_512/E1D2DA9F.JPG\n",
      "E1D2DA9F\n",
      "Boxes(tensor([[111.0088, 144.3620, 300.4570, 299.4605]], device='cuda:0'))\n",
      "IMAGES_512/88FC3BC4.JPG\n",
      "88FC3BC4\n",
      "Boxes(tensor([[309.8420, 199.8755, 402.5208, 303.7354],\n",
      "        [243.4108,  58.3185, 498.3363, 235.4179]], device='cuda:0'))\n",
      "IMAGES_512/261BFD5C.JPG\n",
      "261BFD5C\n",
      "Boxes(tensor([[241.8524, 185.9474, 340.6091, 279.1536]], device='cuda:0'))\n",
      "IMAGES_512/21386B21.JPG\n",
      "21386B21\n",
      "Boxes(tensor([[293.3624, 190.5545, 401.8244, 291.5916]], device='cuda:0'))\n",
      "IMAGES_512/42D6A563.JPG\n",
      "42D6A563\n",
      "Boxes(tensor([[212.8817, 160.5049, 349.1358, 378.4279],\n",
      "        [  0.0000, 161.7229, 162.0682, 383.2403]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "data_result = []\n",
    "for d in testset_dicts:\n",
    "    print(d[\"file_name\"])\n",
    "    print(d[\"image_id\"])\n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    height, width = im.shape[:2]\n",
    "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    print(outputs['instances'].pred_boxes)\n",
    "    result = outputs['instances'].pred_boxes.tensor.to(\"cpu\").numpy()\n",
    "    \n",
    "    if(result.shape[1]!= 4):\n",
    "        assert 1==2\n",
    "    if result.shape[0] > 1:\n",
    "        \n",
    "        result = result[0]\n",
    "    result = result.flatten()\n",
    "    \n",
    "    if len(result) != 4:\n",
    "        print(d[\"file_name\"])\n",
    "        print(result)\n",
    "    final_result = []\n",
    "    final_result.append(d[\"image_id\"])\n",
    "    \n",
    "    for i in range(len(result)):\n",
    "        if i < 2:  \n",
    "            if i%2 == 0:\n",
    "                final_result.append(result[i]/width)\n",
    "            else:\n",
    "                final_result.append(result[i]/height)\n",
    "                \n",
    "        else:\n",
    "            if i%2 == 0:\n",
    "                final_result.append((result[i]-result[i-2])/width)\n",
    "            else:\n",
    "                final_result.append((result[i]-result[i-2])/height)\n",
    "            \n",
    "    data_result.append(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d600dad1",
   "metadata": {
    "papermill": {
     "duration": 0.965143,
     "end_time": "2023-07-10T00:25:34.828915",
     "exception": false,
     "start_time": "2023-07-10T00:25:33.863772",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## To csv for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5646497d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T00:25:36.726151Z",
     "iopub.status.busy": "2023-07-10T00:25:36.725184Z",
     "iopub.status.idle": "2023-07-10T00:25:36.727096Z",
     "shell.execute_reply": "2023-07-10T00:25:36.727641Z",
     "shell.execute_reply.started": "2023-07-07T00:30:52.385477Z"
    },
    "papermill": {
     "duration": 0.947639,
     "end_time": "2023-07-10T00:25:36.727798",
     "exception": false,
     "start_time": "2023-07-10T00:25:35.780159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data_result,columns=train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b0b7433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T00:25:38.625658Z",
     "iopub.status.busy": "2023-07-10T00:25:38.624890Z",
     "iopub.status.idle": "2023-07-10T00:25:38.627997Z",
     "shell.execute_reply": "2023-07-10T00:25:38.628483Z",
     "shell.execute_reply.started": "2023-07-07T00:30:52.387525Z"
    },
    "papermill": {
     "duration": 0.95446,
     "end_time": "2023-07-10T00:25:38.628631",
     "exception": false,
     "start_time": "2023-07-10T00:25:37.674171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['E02ABB6C', 0.3381209969520569, 0.5312279065450033, 0.41056525707244873, 0.4216914176940918], ['9CA35CC5', 0.43175163865089417, 0.6217581828435262, 0.25785699486732483, 0.2640013297398885], ['F5B0AB72', 0.44327613711357117, 0.48815351062350804, 0.15267124772071838, 0.40245209799872506], ['58AE1466', 0.397630900144577, 0.47651441891988117, 0.23480448126792908, 0.4616866906483968], ['B4982B53', 0.18265877664089203, 0.11982391277949016, 0.7297213077545166, 0.8780646324157715], ['387683D3', 0.27577248215675354, 0.3450115919113159, 0.32332322001457214, 0.28455297152201336], ['8F46E061', 0.44337478280067444, 0.39815394083658856, 0.29119452834129333, 0.28261828422546387], ['CF944985', 0.5620678663253784, 0.28947951396306354, 0.32092994451522827, 0.4950382709503174]]\n"
     ]
    }
   ],
   "source": [
    "print(data_result[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e61ad36b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T00:25:40.660381Z",
     "iopub.status.busy": "2023-07-10T00:25:40.659467Z",
     "iopub.status.idle": "2023-07-10T00:25:40.662337Z",
     "shell.execute_reply": "2023-07-10T00:25:40.661829Z",
     "shell.execute_reply.started": "2023-07-07T00:30:52.389443Z"
    },
    "papermill": {
     "duration": 0.954406,
     "end_time": "2023-07-10T00:25:40.662471",
     "exception": false,
     "start_time": "2023-07-10T00:25:39.708065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(data_result)):\n",
    "    if len(data_result[i]) != 5:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a98b46fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T00:25:42.536496Z",
     "iopub.status.busy": "2023-07-10T00:25:42.535517Z",
     "iopub.status.idle": "2023-07-10T00:25:42.537277Z",
     "shell.execute_reply": "2023-07-10T00:25:42.537839Z",
     "shell.execute_reply.started": "2023-07-07T00:30:52.391461Z"
    },
    "papermill": {
     "duration": 0.934817,
     "end_time": "2023-07-10T00:25:42.538001",
     "exception": false,
     "start_time": "2023-07-10T00:25:41.603184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df = result_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d2ee18f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T00:25:44.438600Z",
     "iopub.status.busy": "2023-07-10T00:25:44.437575Z",
     "iopub.status.idle": "2023-07-10T00:25:44.452080Z",
     "shell.execute_reply": "2023-07-10T00:25:44.451531Z",
     "shell.execute_reply.started": "2023-07-07T00:30:52.393481Z"
    },
    "papermill": {
     "duration": 0.950568,
     "end_time": "2023-07-10T00:25:44.452206",
     "exception": false,
     "start_time": "2023-07-10T00:25:43.501638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "result_df.to_csv('result_v26.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61a00393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T00:25:46.354502Z",
     "iopub.status.busy": "2023-07-10T00:25:46.353535Z",
     "iopub.status.idle": "2023-07-10T00:25:46.355448Z",
     "shell.execute_reply": "2023-07-10T00:25:46.355924Z",
     "shell.execute_reply.started": "2023-07-07T00:30:52.397819Z"
    },
    "papermill": {
     "duration": 0.95727,
     "end_time": "2023-07-10T00:25:46.356077",
     "exception": false,
     "start_time": "2023-07-10T00:25:45.398807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/output'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8b198b",
   "metadata": {
    "papermill": {
     "duration": 0.946814,
     "end_time": "2023-07-10T00:25:48.234644",
     "exception": false,
     "start_time": "2023-07-10T00:25:47.287830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Achieved a score of 0.9135 on the public leaderboard."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2881.00458,
   "end_time": "2023-07-10T00:25:52.696046",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-09T23:37:51.691466",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
